[["index.html", "CH22008 Lecture Notes About", " CH22008 Lecture Notes Benjamin J. Morgan 2025-11-14 About These notes accompany the 2025 CH22008 lecture course on Advanced Kinetics. "],["lecture1.html", "Lecture 1 Chemical Kinetics 1.1 Why Study Chemical Kinetics? 1.2 Reaction Rates 1.3 Simple Rate Equations 1.4 Elementary Processes 1.5 Moving Between Concentration and Rate Perspectives 1.6 Integrating Simple Rate Laws 1.7 From Mechanisms to Rate Laws 1.8 Consecutive Reactions 1.9 The Steady-State Approximation", " Lecture 1 Chemical Kinetics 1.1 Why Study Chemical Kinetics? Chemical kinetics describes how reactions happen. While thermodynamics tells us whether a reaction will occur and what the final state will be, kinetics reveals how fast it happens and what steps are involved. For any reaction A \\(\\longrightarrow\\) B, kinetics lets us predict how much B we’ll have after a given time, or how long we need to wait for a desired yield. Beyond this, understanding kinetics helps us control and optimize reactions by changing conditions like temperature and pressure. Figure 1.1: A plot of concentrations of reactant A and product B for a generic reaction A \\(\\longrightarrow\\) B as a function of time. Over time, A is converted to B. How long will it take to obtain 90% yield? Figure 1.2: If we increase the temperature we (usually) expect our reaction to speed up. But by how much? If we increase the reaction temperature by 10 K, how much faster can we reach 90% yield? 1.2 Reaction Rates A core concept in chemical kinetics is the idea of a reaction rate — the speed at which chemical change happens. We express reaction rates mathematically as derivatives of the form \\(\\frac{\\mathrm{d}[\\mathrm{X}]}{\\mathrm{d}t}\\), representing the change in concentration of a species X with time. This rate can be positive (for products being formed) or negative (for reactants being consumed). For any reaction that does not have a 1:1 stoichiometry ratio between all reactants and products, the numerical “rate” will depend on the chemical species we choose to define this. For example, for the reaction \\[\\begin{equation} \\mathrm{A} \\longrightarrow 2\\mathrm{B} \\end{equation}\\] the product, B, is formed at twice the rate that the reactant, A, is consumed. Hence, \\[2\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\] In general, we can define an “overall” reaction rate \\(\\nu\\) that is related to the rates of change of reactants and products by \\[\\nu = \\frac{1}{n_\\mathrm{X}}\\frac{\\mathrm{d}[\\mathrm{X}]}{\\mathrm{d}t}\\] where \\(n_\\mathrm{X}\\) is the stoichiometric coefficient of species \\(X\\) in the reaction equation. 1.3 Simple Rate Equations For many reactions, the rate of reaction is proportional to the concentrations of the reactants, raised to some power; i.e., \\[\\nu = k [\\mathrm{A}]^a [\\mathrm{B}]^b [\\mathrm{C}]^c \\ldots\\] The proportionality constant, \\(k\\), is called the rate constant. The exponents, \\(a\\), \\(b\\), \\(c\\) …, describe the order of the reaction with respect to the reactants A, B, C …. So, for a reaction \\[\\mathrm{A} + \\mathrm{B} \\longrightarrow \\mathrm{C}\\] with rate equation (or “rate law”) \\[\\nu = k[\\mathrm{A}]^2[\\mathrm{B}]\\], we would describe this as being second-order with respect to A, and first-order with respect to B. For rate equations that have the simple form above, we can define an overall order, which is the sum of the individual orders with respect to each of the reactants. In the example above, this reaction would be described as being third-order overall, since \\(a+b = 3\\). Not all reactions follow simple rate laws. For example, the reaction between H2 and Br2 to form HBr has an empirically-determined rate law \\[\\begin{equation} \\nu = k\\frac{[\\mathrm{H}_2][\\mathrm{Br}_2]^\\frac{1}{2}}{1+k^\\prime [\\mathrm{HBr}]/[\\mathrm{Br}_2]} \\tag{1.1} \\end{equation}\\] This rate law is first-order with respect to H2, because \\(\\nu \\propto [\\mathrm{H_2}]\\). But we cannot define an order with respect to Br2, because the overall rate is not simply proportional to \\([\\mathrm{Br}_2]\\) raised to some power. Instead, we would describe the order with respect to Br2 as being undefined. This means the overall order is also undefined, since we cannot simply add the orders with respect to H2 and Br2. 1.4 Elementary Processes Any chemical reaction can be broken down into a sequence of one of more single-step “elementary” processes. For example, for the reaction \\(\\mathrm{H}_2 + \\mathrm{Br}_2 \\longrightarrow 2\\mathrm{HBr}\\), where the empirical rate law is given by (1.1), one sequence of elementary processes that is consistent with this rate law is \\[\\begin{eqnarray} \\mathrm{Br}_2 &amp; \\longrightarrow &amp; \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet \\\\ \\mathrm{Br}^\\bullet + \\mathrm{H}_2 &amp; \\longrightarrow &amp; \\mathrm{H}^\\bullet + \\mathrm{HBr} \\\\ \\mathrm{H}^\\bullet + \\mathrm{Br}_2 &amp; \\longrightarrow &amp; \\mathrm{Br}^\\bullet + \\mathrm{HBr} \\\\ \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet &amp; \\longrightarrow &amp; \\mathrm{Br}_2 \\tag{1.2} \\end{eqnarray}\\] 1.4.1 Molecularity Elementary processes can be classified according to their molecularity — the number of reactant molecules that must come together for a particular reaction step. For example, in reaction mechanism (1.2), the first step involves the dissociation of Br2 to form two Br radicals: \\[\\begin{equation} \\mathrm{Br}_2 \\longrightarrow \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet \\end{equation}\\] This reaction step involves a single reactant molecule, so it is described a unimolecular. The second step involves a Br radical and H2 molecule reacting: \\[\\begin{equation} \\mathrm{Br}^\\bullet + \\mathrm{H}_2 \\longrightarrow \\mathrm{H}^\\bullet + \\mathrm{HBr} \\end{equation}\\] Because two reactant molecules must come together for this step, this is described as a bimolecular process. A process that involves two molecules of the same chemical species, as in the last step of the reaction mechanism above, is also bimolecular: \\[\\begin{equation} \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet \\longrightarrow \\mathrm{Br}_2 \\end{equation}\\] 1.4.2 Rate Laws for Elementary Processes The rate laws for elementary processes directly reflect their molecularity. Unimolecular processes (\\(\\mathrm{A} \\longrightarrow \\mathrm{P}\\)) show first-order kinetics with rate \\(\\nu = k[\\mathrm{A}]\\). Similarly, bimolecular processes show second-order kinetics: for a bimolecular process involving two distinct chemical species (\\(\\mathrm{A} + \\mathrm{B} \\longrightarrow \\mathrm{P}\\)), the process is first-order with respect to each species: \\(\\nu = k[\\mathrm{A}][\\mathrm{B}]\\), while a bimolecular process that involves two molecules of the same chemical species (\\(2\\mathrm{A} \\longrightarrow \\mathrm{P}\\)) is second-order with respect to that species: \\(\\nu = k[\\mathrm{A}]^2\\). Termolecular processes, involving three reactant molecules, show third order kinetics, e.g., \\(\\nu = k[\\mathrm{A}]^2[\\mathrm{B}]\\). In general, termolecular processes are rare, because the probability of three molecules colliding simultaneously with the correct orientation is very small. While termolecular processes can play a role at very high pressure, under more typical reaction conditions, experimental observations of third-order kinetics are often better explained by a complex multistep reaction mechanism. Figure 1.3: Elementary processes always follow simple rate laws, where the order with respect to each reactant reﬂects the molecularity of the process. 1.5 Moving Between Concentration and Rate Perspectives The progression of any chemical reaction can be viewed from two complementary perspectives: the concentration of species as they change over time, \\([\\mathrm{A}]\\), and the instantaneous rates at which these changes occur, \\(\\mathrm{d}[\\mathrm{A}]/\\mathrm{d}t\\). These two perspectives both describe the same underlying chemical process, just viewed through different mathematical lenses. Consider a reactant A being consumed during a reaction. We might track its concentration \\([\\mathrm{A}]\\) as it decreases over time, giving us a curve of concentration versus time. At any point on this curve, we can determine the instantaneous rate of reaction by finding the slope of the tangent line. Mathematically, this is equivalent to computing the derivative of \\([\\mathrm{A}]\\), i.e., \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\). Since we are dealing with the concentration of a reactant, the reaction rate is then the negative of this derivative (since the concentrations of A decreases with time): \\[\\begin{equation} \\nu = -\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} \\tag{1.3} \\end{equation}\\] We can also go the other way from a description of rate to a description of the concentration profile over time. Mathematically we do this by integration, which is the inverse operation to differentiation. By integrating a rate, we effectively sum all the small changes in concentration over some time interval. For example, the change in concentration of A from the start of a reaction at \\(t=0\\) is given by \\[\\begin{equation} [\\mathrm{A}]_t - [\\mathrm{A}]_0 = \\int_0^t -\\nu(t)\\,\\mathrm{d}t \\tag{1.4} \\end{equation}\\] Whether we work in terms of concentrations or rates depends on the question we are trying to answer, what information we have available to us, and whether it is more mathematically convenient to work with one than the other. Figure 1.4: If we know the concentration of a reactant or product as a function of time we can calculate the rate of change of this concentration by differentiation. We can also calculate how concentrations vary in time from rates by the inverse procedure, integration. 1.6 Integrating Simple Rate Laws For simple rate laws of the form \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}]^n\\] we can derive corresponding integrated rate laws by integrating (see CH12002 Lecture 3). 1.6.1 First-Order Reactions For a first-order process \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\), the rate of change of concentration of reactant, A, is given by \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] \\end{equation}\\] To derive the corresponding integrated rate law, we rearrange this to form an integral equation: \\[\\begin{equation} \\int_{[\\mathrm{A}]_0}^{\\mathrm[A]_t} \\frac{\\mathrm{d}[\\mathrm{A}]}{[\\mathrm{A}]}\\,\\mathrm{d}[\\mathrm{A}] = \\int_0^t -k\\,\\mathrm{d}t \\end{equation}\\] where the limits of the integral with respect to concentration of A are between the concentration at time \\(0\\) (\\([\\mathrm{A}]_0\\)) and the concentration at time \\(t\\) (\\([\\mathrm{A}]_t\\)), and the limits of the integral with respect to time are between \\(t=0\\) and \\(t=t\\). Integrating, using the integral \\(\\int \\frac{1}{x}\\,\\mathrm{d}x = \\ln x\\), gives \\[\\begin{equation} \\ln [\\mathrm{A}]_t - \\ln [\\mathrm{A}]_0 = -kt \\end{equation}\\] which can be rearranged as \\[\\begin{equation} [\\mathrm{A}]_t = [\\mathrm{A}]_0\\mathrm{e}^{-kt} \\tag{1.5} \\end{equation}\\] Hence, for a first-order process, the concentration of the reactant decays exponentially with time. Having derived an expression for \\([\\mathrm{A}]_t\\) we can now derive the integrated rate law for the concentration of the product, B, as a function of time. To do so, we use the known stoichoimetry of the reaction: for every molecule of A consumed, one molecule of B is formed, so the total concentration \\([\\mathrm{A}] + [\\mathrm{B}]\\) must be constant. Furthermore, when \\(t=0\\), only A is present, with a concentration \\([\\mathrm{A}]_0\\). So, \\([\\mathrm{A}] + [\\mathrm{B}] = [\\mathrm{A}]_0\\). Substituting in our expression for \\([\\mathrm{A}]\\) (Eqn. (1.5) gives \\[\\begin{eqnarray} [\\mathrm{B}] &amp; = &amp; [\\mathrm{A}]_0 - [\\mathrm{A}]_0\\mathrm{e}^{-kt} \\\\ &amp; = &amp; [\\mathrm{A}]_0\\left(1-\\mathrm{e}^{-kt}\\right) \\end{eqnarray}\\] Hence, for a first-order process, the concentration of the product exponentially approaches a limit of \\([\\mathrm{B}]_t = [\\mathrm{A}]_0\\). Figure 1.5: Concentrations as a function of time for a first-order process \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\). 1.6.2 Second-Order Reactions For a second-order process \\(2\\mathrm{A} \\longrightarrow \\mathrm{B}\\), with overall rate \\(\\nu = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\), the rate of change of concentration of reactant, A, is \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -2k[\\mathrm{A}]^2 \\tag{1.6} \\end{equation}\\] As for first-order reactions, above, we can derive the corresponding integrated rate law for \\([\\mathrm{A}]_t\\) by rearranging Eqn. (1.6) and then integrating: \\[\\begin{equation} \\int_{[\\mathrm{A}]_0}^{\\mathrm[A]_t} \\frac{\\mathrm{d}[\\mathrm{A}]}{[\\mathrm{A}]^2}\\,\\mathrm{d}[\\mathrm{A}] = \\int_0^t -k\\,\\mathrm{d}t \\end{equation}\\] Integrating, using the integral \\(\\int \\frac{1}{x^2}\\,\\mathrm{d}x = -\\frac{1}{x}\\), gives \\[\\begin{equation} \\frac{1}{[\\mathrm{A}]_t} - \\frac{1}{[\\mathrm{A}]_0} = -kt \\end{equation}\\] which can be rearranged as \\[\\begin{equation} [\\mathrm{A}]_t = \\frac{[\\mathrm{A}]_0}{1 + kt[\\mathrm{A}]_0} \\end{equation}\\] To obtain an expression for \\([\\mathrm{B}]_t\\), we again use our knowledge of the reaction stoichiometry and initial conditions: we start with only the reactant A, and at any stage of the reaction, the amount of B formed is equal to half the amount of A consumed. \\[\\begin{equation} [\\mathrm{B}]_t = \\frac{1}{2}\\left([\\mathrm{A}]_0 - [\\mathrm{A}]_t\\right) \\end{equation}\\] And, so \\[\\begin{equation} [\\mathrm{B}]_t = \\frac{[\\mathrm{A}]_0}{2}\\left(1 - \\frac{1}{1+kt[\\mathrm{A}_0]}\\right) \\end{equation}\\] which rearranges to \\[\\begin{equation} [\\mathrm{B}]_t = \\frac{kt[\\mathrm{A}]_0^2}{2(1 + kt[\\mathrm{A}]_0)} \\end{equation}\\] Figure 1.6: Concentrations as a function of time for a second-order process \\(2\\mathrm{A} \\longrightarrow \\mathrm{B}\\). The dashed line shows the sum \\([\\mathrm{A}]_t + [\\mathrm{B}]_t\\). Aside: Why Does Our Second-Order Rate Equation Include a Factor of 2? Let us briefly examine the origin of the factor of 2 on the right-hand side of Eqn. @ref{eq:secondorderdiff}. Writing the rate equation for \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\) in this way is consistent with the convention in Section 1.2, that the overall rate of a reaction is related to the rates of change of specific reactants or products by \\[\\begin{equation} \\nu = \\frac{1}{n_\\mathrm{X}}\\frac{\\mathrm{d}[\\mathrm{X}]}{\\mathrm{d}t} \\tag{1.7} \\end{equation}\\] We can also justify the factor of \\(2\\) by recognising that the stoichiometry of the reaction requires 2 molecules of A to be consumed for every 1 molecule of B formed, and, hence, \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = 2\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} \\end{equation}\\] The factor of 2 in Eqn. (1.6) is somewhat arbitrary though, as it is a consequence of our choice to define the overall rate of reaction as \\(\\nu = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\). If, instead, we define our overall rate as \\(\\nu = \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\) then we would write the rate of change of concentration of A as \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}]^2 \\tag{1.8} \\end{equation}\\] The functional form for \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\) is the same in both cases (Eqns. (1.6) and (1.8). Our choice of how we define our overall rate, however, determines what the rate constant \\(k\\) actually describes. The rate constant in (1.8) is equal to twice the rate constant in (1.6). Upon reflection, it should perhaps not be surprising that the numerical value of our rate constant \\(k\\) depends on how we choose to define the reaction rate. Whichever of these two ways we choose to define our overall rate, the procedure for deriving the second-order intergrated rate law is unchanged, and we end up with the same functional form for the integrated rate law — either with, or without, the factor of 2 carried through the derivation. 1.7 From Mechanisms to Rate Laws The relationship between reaction mechanisms and the time evolution of chemical concentrations depends strongly on the complexity of the reaction scheme. For reactions that consist of a single elementary process, we can usually determine how the concentrations of reactants and products evolve with time through a straightforward two-step process: Write down the rate equations for reactants and products based on the molecularity of the elementary process Directly integrate these rate equations to obtain the corresponding integrated rate laws For example, we have already seen how this works for first-order processes in Section 1.6. For reactions with multistep mechanisms, however, the path from mechanism to time evolution is often more complex. Our starting point is always the reaction mechanism itself—the sequence of elementary processes that describes the complete reaction scheme. From this mechanism, we write differential rate equations for all chemical species that appear, including not only the reactants and products, but also any reaction intermediates. When analysing multistep mechanisms, we typically pursue one or both of two goals: To derive an expression for the overall reaction rate in terms of reactant concentrations only, eliminating any dependence on intermediate concentrations To obtain integrated rate laws that describe how the concentrations of reactants and products vary with time How we approach these goals depends on the nature of the reaction mechanism under consideration. In general, we can analyse complex reaction mechanisms using one of three strategies: 1.7.1 Exact Solutions For some reaction mechanisms, we can derive exact analytical solutions to our coupled differential rate equations. While this approach is the most mathematically satisfying, it is only possible for relatively simple reaction schemes. 1.7.2 Approximate Analytical Solutions More commonly, we can simplify our set of coupled differential equations by applying chemical approximations based on the physical nature of the reaction mechanism. We then solve these simplified equations to obtain analytical solutions that accurately describe the real system within the range of conditions where our approximations hold. This approach often provides valuable chemical insight into the factors controlling reaction rates and time evolution. 1.7.3 Numerical Integration When analytical solutions prove intractable, we can always fall back on numerical methods. By numerically integrating our differential rate equations, we can model how the concentrations of all species—reactants, products, and intermediates—evolve over time. While this approach will always work in principle, it may provide less direct insight into the underlying chemical processes than analytical solutions, even approximate ones. Although numerical integration provides a reliable method of last resort, there is often significant value in pursuing analytical solutions, either exact or approximate. These solutions can reveal fundamental relationships between reaction parameters and chemical behavior that might be obscured in purely numerical results. 1.8 Consecutive Reactions Having examined simple rate laws and elementary processes, we now consider how to analyze reactions that occur in multiple steps. One important class of such reactions are consecutive (or sequential) reactions, where products are formed through a series of steps: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B} \\xrightarrow{k_2} \\mathrm{C}\\] Such reaction sequences are common in both chemical and biochemical systems. For example, the decomposition of many organic compounds proceeds through multiple intermediates, and many metabolic pathways involve sequences of enzyme-catalyzed reactions. 1.8.1 Rate Equations Following our approach from Section 1.2, we can write differential rate equations for each species: \\[\\begin{align} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} &amp;= -k_1[\\mathrm{A}] \\\\ \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} &amp;= +k_1[\\mathrm{A}] - k_2[\\mathrm{B}] \\\\ \\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} &amp;= +k_2[\\mathrm{B}] \\end{align}\\] Note that species B appears both as a product (in the first step) and as a reactant (in the second step). This is characteristic of reaction intermediates. 1.8.2 Integrated Rate Laws We can solve these coupled differential equations sequentially. First, the equation for [A] is a simple first-order decay (see Section 1.6): \\[[\\mathrm{A}] = [\\mathrm{A}]_0\\mathrm{e}^{-k_1t}\\] To solve for [B], we substitute this expression into the second differential equation: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t} - k_2[\\mathrm{B}]\\] Integrating this linear first-order differential equation (see Appendix A) gives: \\[[\\mathrm{B}] = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}(\\mathrm{e}^{-k_1t} - \\mathrm{e}^{-k_2t})\\] Finally, we can find [C] using conservation of mass ([A] + [B] + [C] = [A]₀): \\[[\\mathrm{C}] = [\\mathrm{A}]_0\\left[1 + \\frac{k_1\\mathrm{e}^{-k_2t} - k_2\\mathrm{e}^{-k_1t}}{k_1-k_2}\\right]\\] Figure 1.7: Concentration profiles for a consecutive reaction A → B → C. The intermediate B exhibits a maximum concentration at intermediate times. 1.8.3 Limiting Cases and the Rate-Determining Step The kinetics of consecutive reactions can be simplified when one step is much slower than the other. This slower step becomes rate-determining for the overall reaction. 1.8.3.1 Case 1: \\(k_1 \\ll k_2\\) When the first step is much slower than the second: B is consumed almost as soon as it is formed [B] remains very small throughout the reaction Formation of C follows approximately first-order kinetics: \\[[\\mathrm{C}] \\approx [\\mathrm{A}]_0(1-\\mathrm{e}^{-k_1t})\\] 1.8.3.2 Case 2: \\(k_1 \\gg k_2\\) When the first step is much faster than the second: A is rapidly converted to B B accumulates before slowly converting to C After an initial rapid phase, formation of C follows approximately first-order kinetics: \\[[\\mathrm{C}] \\approx [\\mathrm{A}]_0(1-\\mathrm{e}^{-k_2t})\\] Figure 1.8: Concentration profiles for consecutive reactions in limiting cases. Left: k₁ &lt;&lt; k₂, where the first step is rate-determining. Right: k₁ &gt;&gt; k₂, where the second step is rate-determining. The concept of a rate-determining step is particularly valuable when analyzing complex reaction mechanisms. When one step in a reaction sequence is much slower than the others, it becomes the “bottleneck” that controls the overall reaction rate. This principle helps explain why many complex reactions show simple kinetic behavior—the observed kinetics often reflect just the rate-determining step. 1.9 The Steady-State Approximation When analyzing complex reaction mechanisms, we can often simplify our analysis using the steady-state approximation. This approximation applies to reaction intermediates that are consumed much faster than they are formed, leading to a “steady state” where the rate of change of the intermediate’s concentration is approximately zero. 1.9.1 Basic Principles The steady-state approximation assumes that after a brief initial period, the concentration of a reactive intermediate B reaches a “steady state” where: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} \\approx 0\\] Consider our consecutive reaction mechanism from the previous section: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B} \\xrightarrow{k_2} \\mathrm{C}\\] The rate equations are: \\[\\begin{align} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} &amp;= -k_1[\\mathrm{A}] \\\\ \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} &amp;= k_1[\\mathrm{A}] - k_2[\\mathrm{B}] \\\\ \\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} &amp;= k_2[\\mathrm{B}] \\end{align}\\] When \\(k_2 \\gg k_1\\), B is consumed much faster than it is formed, and we can apply the steady-state approximation: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}] - k_2[\\mathrm{B}] \\approx 0\\] This allows us to solve for \\([\\mathrm{B}]\\): \\[[\\mathrm{B}] \\approx \\frac{k_1}{k_2}[\\mathrm{A}]\\] Substituting this expression into our rate equation for C: \\[\\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = k_2[\\mathrm{B}] = k_1[\\mathrm{A}]\\] From conservation of mass, \\([\\mathrm{A}]_0 = [\\mathrm{A}] + [\\mathrm{B}] + [\\mathrm{C}]\\). Under the condition \\(k_2 \\gg k_1\\), the concentration of B remains small, so \\([\\mathrm{A}]_0 ≈ [\\mathrm{A}] + [\\mathrm{C}]\\). Therefore: \\[\\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = k_1[\\mathrm{A}] = k_1([A]_0 - [C])\\] This first-order differential equation can be directly integrated to give: \\[[\\mathrm{C}] = [\\mathrm{A}]_0(1-\\mathrm{e}^{-k_1t})\\] This is the same result we obtained in our analysis of consecutive reactions in the limit where \\(k_1 \\ll k_2\\). 1.9.2 Validity of the Steady-State Approximation The steady-state approximation simplifies the analysis of complex reaction mechanisms by treating the concentrations of reactive intermediates as constant. While this mathematical convenience makes many problems tractable, we need to understand when the approximation holds and what it reveals about reaction kinetics. A steady state exists when the rates of formation and consumption of the intermediate balance. This requires two conditions: the intermediate must be consumed much faster than it forms, and enough time must have passed for the intermediate to build up to its steady-state concentration. This initial period, where the intermediate concentration increases to its steady-state value, is called the induction period. Consider a reaction with the mechanism: \\[\\mathrm{A} + \\mathrm{B} \\underset{k_{-1}}{\\overset{k1}\\rightleftharpoons} \\mathrm{C} \\overset{k_2}\\rightarrow \\mathrm{D}\\] Reactants A and B combine reversibly to form an intermediate C, which then reacts to form product D. The steady-state approximation assumes \\(\\mathrm{d}[\\mathrm{C}]/\\mathrm{d}t \\approx 0\\) — that is, the concentration of C remains approximately constant as the reaction proceeds. Figure 1.9: Time evolution of concentrations for the reaction mechanism \\(\\mathrm{A} + \\mathrm{B} \\underset{k_1}{\\overset{k1}\\rightleftharpoons} \\mathrm{C} \\overset{k_2}\\longrightarrow \\mathrm{D}\\) where \\(k_2 \\gg k_1\\). Solid lines show the exact concentrations, while the dashed line shows the predicted product concentration \\([\\mathrm{D}]_\\mathrm{SSA}\\) calculated using the steady-state approximation for intermediate C. The approximation overshoots during the initial induction period where [C] is still building up, but describes the reaction progress well once steady state is established. Figure 1.9 compares the steady-state prediction for [D] (dashed line) with the exact concentration profiles (solid lines) when \\(k_2 \\gg k_1\\). During the induction period, the steady-state approximation overestimates the rate of product formation because it assumes C has already reached its steady-state concentration. However, once this period passes, the predicted and actual concentrations align well. These observations suggest several criteria for applying the steady-state approximation to new systems. First, the kinetics must support the basic steady-state assumption, typically requiring \\(k_2 \\gg k_1\\). Second, the timescale of interest must exceed the induction period. Third, any deviations during the induction period should not compromise the analysis. When steady-state predictions match experimental data, they provide evidence for a reaction mechanism involving an intermediate maintained at near-constant concentration during the main reaction phase. "],["lecture2.html", "Lecture 2 Parallel Irreversible Reactions 2.1 Introduction 2.2 Simple First-Order Reactions 2.3 First-Order Parallel Reactions 2.4 Key Features of Parallel Reactions 2.5 Temperature Effects on Selectivity 2.6 Pressure Effects on Selectivity", " Lecture 2 Parallel Irreversible Reactions 2.1 Introduction In many chemical systems, a single reactant can undergo multiple competing reactions simultaneously to form different products. These are called parallel reactions. The simplest example is where a reactant A can form either product B or product C: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B}\\] \\[\\mathrm{A} \\xrightarrow{k_2} \\mathrm{C}\\] Understanding how these parallel reactions proceed and what controls their relative rates is crucial for many practical applications, particularly in synthetic chemistry where we often want to maximize the yield of one product over another. 2.2 Simple First-Order Reactions Let us first consider the case of a single first-order reaction: \\[\\mathrm{A} \\xrightarrow{k} \\mathrm{B}\\] The rate equations are: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}]\\] \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = +k[\\mathrm{A}]\\] Integrating these gives: \\[[\\mathrm{A}] = [\\mathrm{A}]_0\\mathrm{e}^{-kt}\\] And since [B] = [A]0 - [A] (from conservation of mass): \\[[\\mathrm{B}] = [\\mathrm{A}]_0(1-\\mathrm{e}^{-kt})\\] Figure 2.1: Concentrations of reactant, A, and product, B, as a function of time for a reaction \\(\\mathrm{A}\\longrightarrow\\mathrm{B}\\) with first-order kinetics. 2.3 First-Order Parallel Reactions For parallel reactions where both pathways are first-order: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B}\\] \\[\\mathrm{A} \\xrightarrow{k_2} \\mathrm{C}\\] The rate of change of A is now: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(k_1 + k_2)[\\mathrm{A}]\\] Integrating this gives: \\[[\\mathrm{A}] = [\\mathrm{A}]_0\\mathrm{e}^{-(k_1+k_2)t}\\] For product B: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}] = k_1[\\mathrm{A}]_0\\mathrm{e}^{-(k_1+k_2)t}\\] Integrating: \\[[\\mathrm{B}] = \\frac{k_1}{k_1+k_2}[\\mathrm{A}]_0(1-\\mathrm{e}^{-(k_1+k_2)t})\\] Similarly for C: \\[[\\mathrm{C}] = \\frac{k_2}{k_1+k_2}[\\mathrm{A}]_0(1-\\mathrm{e}^{-(k_1+k_2)t})\\] 2.4 Key Features of Parallel Reactions Several important points emerge from these expressions: The formation of both products B and C is controlled by the same overall rate constant (\\(k_1 + k_2\\)) The relative yields of products are determined by the ratio of the rate constants: \\[\\frac{[\\mathrm{B}]}{[\\mathrm{C}]} = \\frac{k_1}{k_2}\\] This ratio is often called the selectivity, S: \\[S = \\frac{k_1}{k_2}\\] Figure 2.2: B and C both form via first-order processes with the same effective rate constant \\(k_1+k_2\\). At any point in time, the ratio \\([\\mathrm{B}]/[\\mathrm{C}]\\) is equal to \\(k_1/k_2\\). 2.5 Temperature Effects on Selectivity How does changing temperature affect the selectivity? Using the Arrhenius equation: \\[k_1 = A_1\\exp\\left(-\\frac{\\Delta E_1}{RT}\\right)\\] \\[k_2 = A_2\\exp\\left(-\\frac{\\Delta E_2}{RT}\\right)\\] Therefore: \\[S = \\frac{k_1}{k_2} = \\frac{A_1}{A_2}\\exp\\left(-\\frac{\\Delta E_1-\\Delta E_2}{RT}\\right)\\] If \\(\\Delta E_1 &gt; \\Delta E_2\\), then (\\(\\Delta E_1 - \\Delta E_2\\)) is positive, and increasing temperature will increase \\(S\\). This can be visualized using an Arrhenius plot (\\(\\ln k\\) vs \\(1/T\\)), where the reaction with the higher activation energy has the steeper slope. Figure 2.3: Arrhenius plot showing the qualitative effect of changing temperature on selectivity between two reactions with different activation energies. Increasing temperature gives a larger increase in rate constant for the reaction with the larger activation energy, \\(\\Delta E\\), and increases selectivity for the product formed via this reaction. 2.6 Pressure Effects on Selectivity The effect of pressure on selectivity depends on the molecularity of the competing reactions: If both reactions have the same molecularity (e.g., both first-order), pressure has no effect on selectivity because k is independent of pressure. For reactions with different molecularity: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B}\\] \\[2\\mathrm{A} \\xrightarrow{k_2} \\mathrm{C}\\] The selectivity becomes pressure-dependent: \\[\\frac{[\\mathrm{B}]}{[\\mathrm{C}]} = \\frac{\\text{rate}_\\mathrm{B}}{\\text{rate}_\\mathrm{C}} = \\frac{k_1[\\mathrm{A}]}{k_2[\\mathrm{A}]^2} = \\frac{k_1}{k_2[\\mathrm{A}]}\\] Following Le Chatelier’s principle, increasing pressure favors the reaction with the higher molecularity. 2.6.1 Example: Decomposition of H2O2 The decomposition of hydrogen peroxide in aqueous solution occurs through two parallel pathways. A unimolecular decomposition: \\[\\begin{equation} \\mathrm{H}_2\\mathrm{O}_2 \\overset{k_1}{\\longrightarrow} \\mathrm{H}_2\\mathrm{O} + \\frac{1}{2}\\mathrm{O}_2 \\end{equation}\\] and a bimolecular process: \\[\\begin{equation} 2\\mathrm{H}_2\\mathrm{O}_2 \\overset{k_2}{\\longrightarrow} 2\\mathrm{H}_2\\mathrm{O} + \\mathrm{O}_2 \\end{equation}\\] The overall rate of H2O2 consumption combines both pathways: \\[\\begin{equation} -\\frac{\\mathrm{d}[\\mathrm{H}_2\\mathrm{O}_2]}{\\mathrm{d}t} = k_1[\\mathrm{H}_2\\mathrm{O}_2] + 2k_2[\\mathrm{H}_2\\mathrm{O}_2]^2 \\end{equation}\\] The factor of 2 in the second term arises from the stoichiometry of the bimolecular process, where each reaction event consumes two H2O2 molecules. The relative contribution of each pathway depends on the concentration of H2O2: \\[\\begin{equation} \\frac{\\text{rate}_1}{\\text{rate}_2} = \\frac{k_1[\\mathrm{H}_2\\mathrm{O}_2]}{2k_2[\\mathrm{H}_2\\mathrm{O}_2]^2} = \\frac{k_1}{2k_2[\\mathrm{H}_2\\mathrm{O}_2]} \\end{equation}\\] This ratio varies inversely with H2O2 concentration. The relative importance of the two pathways therefore depends both on the concentration and on the specific values of the rate constants \\(k_1\\) and \\(k_2\\). "],["lecture3.html", "Lecture 3 Parallel Reversibile Reactions 3.1 Introduction to Parallel Reversible Reactions 3.2 Time Evolution of Product Distributions 3.3 Kinetic vs Thermodynamic Control 3.4 Example: Enolate formation of 2-methylcyclohexanone", " Lecture 3 Parallel Reversibile Reactions 3.1 Introduction to Parallel Reversible Reactions Building on our previous discussion of parallel reactions, we now consider systems where the individual reactions are reversible: \\[\\mathrm{A} \\mathrel{\\mathop{\\rightleftarrows}^{k_1}_{k_{-1}}} \\mathrm{B}\\] \\[\\mathrm{A} \\mathrel{\\mathop{\\rightleftarrows}^{k_2}_{k_{-2}}} \\mathrm{C}\\] For such systems, the rate equations are: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(k_1 + k_2)[\\mathrm{A}] + k_{-1}[\\mathrm{B}] + k_{-2}[\\mathrm{C}]\\] \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = +k_1[\\mathrm{A}] - k_{-1}[\\mathrm{B}]\\] \\[\\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = +k_2[\\mathrm{A}] - k_{-2}[\\mathrm{C}]\\] 3.2 Time Evolution of Product Distributions 3.2.1 Short-Time Behaviour At very short times, when [B] ≈ 0 and [C] ≈ 0, the backward reactions can be neglected and the system behaves similarly to the irreversible case we studied previously. The relative yields of products are determined by the ratio of the forward rate constants: \\[\\frac{[\\mathrm{B}]}{[\\mathrm{C}]} \\approx \\frac{k_1}{k_2}\\] This is often called “kinetic control”, as the product distribution is determined by the relative rates of the forward reactions. 3.2.2 Long-Time Behaviour At long times, the system reaches equilibrium, where: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = \\frac{\\mathrm{d}d[\\mathrm{C}]}{\\mathrm{d}t} = 0\\] At equilibrium: \\[k_1[\\mathrm{A}]_\\mathrm{eq} = k_{-1}[\\mathrm{B}]_\\mathrm{eq}\\] \\[k_2[\\mathrm{A}]_\\mathrm{eq} = k_{-2}[\\mathrm{C}]_\\mathrm{eq}\\] This gives equilibrium constants: \\[K_\\mathrm{AB} = \\frac{[\\mathrm{B}]_\\mathrm{eq}}{[\\mathrm{A}]_\\mathrm{eq}} = \\frac{k_1}{k_{-1}}\\] \\[K_\\mathrm{AC} = \\frac{[\\mathrm{C}]_\\mathrm{eq}}{[\\mathrm{A}]_\\mathrm{eq}} = \\frac{k_2}{k_{-2}}\\] The final product ratio at equilibrium is: \\[\\frac{[\\mathrm{B}]_\\mathrm{eq}}{[\\mathrm{C}]_\\mathrm{eq}} = \\frac{k_1k_{-2}}{k_{-1}k_2}\\] This is called “thermodynamic control”, as the product distribution is determined by the relative thermodynamic stabilities of the products. 3.3 Kinetic vs Thermodynamic Control When thinking about a pair of parallel reactions, we can rationalise a preference for forming either the kinetic or thermodynamic product by considering how the energy of a molecular system changes as reactants transform to products. Figure 3.1: A reaction coordinate diagram showing the free energy profile for a chemical reaction. The reaction coordinate represents the progression through molecular geometric changes (e.g., bonds breaking and forming) as reactants transform into products. The activation energy (\\(\\Delta G_\\mathrm{a}\\)) determines reaction rate, while the reaction free energy (\\(\\Delta G_\\mathrm{r}\\)) determines the position of equilibrium. Figure 3.1 shows an example of a reaction coordinate diagram. A reaction coordinate diagram is a schematic representation of how the free energy of a molecular system changes as a reaction proceeds. The horizontal axis is called the reaction coordinate, and represents the progression of the reaction along a particular reaction pathway—often this corresponds to a specific change in geometry as atoms rearrange and bonds break and form. The vertical axis shows the Gibbs free energy of the system. Two key features of these diagrams help us understand reaction behaviour: The activation energy (\\(\\Delta G_\\mathrm{a}\\)) represents the energy barrier that must be overcome for reaction to occur. This determines reaction rate—lower barriers mean faster reactions. The reaction free energy (\\(\\Delta G_\\mathrm{r}\\)) represents the overall thermodynamic driving force. This determines the position of equilibrium—more negative values mean the products are more favoured at equilibrium. We can expand this concept of a reaction coordinate diagram to the case of parallel reactions by considering a diagram that shows two paths, A → B and A → C. In this composite reaction coordinate diagram, both paths start from the reactant A. One path leads to product B and the other path leads to product C. To understand the competition between kinetic and thermodymamic control, we consider the case where: The reaction A → B has a lower activation energy than the reaction A → C; C is thermodynamically favoured versus B; i.e., \\(\\Delta G(B \\to C) &lt; 0\\). At short times, the concentrations of B and C are small, and relative concentrations of B and C approximately follow the relative rates of the corresponding forward reactions. Because the activation barrier for A → B is smaller than for A → C, B forms more rapidly than C, and [B]/[C] &gt; 1. The kinetic product is therefore B. At long times the kinetic product, B, can convert back to the reactant A, via path B → A, and then convert to C, via path A → C. Eventually we reach an equilibrium distribution of products, where the ratio [B]/[C] at equilibrium depends on the relative free energies of the two competing products. Because \\(\\Delta G(B \\to C) &lt; 0\\), at long times C is favoured (thermodynamic product) and [B]/[C] &lt; 1. Figure 3.2: Reaction coordinate diagram for a pair of parallel reversible reactions: A\\(\\,\\overset{k_1}{\\underset{k_{-1}}\\rightleftharpoons}\\,\\)B and A\\(\\,\\overset{k_2}{\\underset{k_{-2}}\\rightleftharpoons}\\,\\)C, where \\(\\Delta E_1 &lt; \\Delta E_2\\) (i.e., \\(k_1 \\gg k_2\\)) and \\(\\Delta G(\\mathrm{B} \\to \\text{C}) &lt; 0\\). (a) kinetic control: at short times the relative formation of B and C depends only on the relative rates of the forward reactions A → B and A → C. (b) thermodynamic control: at long times the relative formation of B and C depends on the free energy difference between the two products. 3.4 Example: Enolate formation of 2-methylcyclohexanone Thinking about competing products as being preferentially formed under kinetic or thermodynamic control gives us a framework for understanding how our choice of reaction conditions can determine the selectivity of reaction. As an example, consider enolate formation of 2-methylcyclohexanone. Figure 3.3: Under basic conditions, 2-methylcyclohexanone can form two distinct enolates, depending on whether a proton is removed from position 2 (green) or from position 6 (orange). 2-methylcyclohexanone can form two different enolates, depending on whether the base extracts a proton from position 2 or from position 6. In the presence of a strong base, the less substituted enolate (product A) is preferentially formed with high selectivity. While in the presence of a weak base, the more substituted enolate (product B) is preferentially formed with moderate selectivity (see Figure 3.3). Figure 3.4: The selectivity between products A and B product B depends on the strength of the base that reacts with the 2-methylcyclohexanone. We can understand the selectivity of this enolate formation, and why this depends on the strength of the base added, by thinking about the competition between the kinetic and thermodynamic products. The thermodynamic product is the enolate that is thermodynamically more stable. In general, more subtituted alkenes are more stable than less substituted alkenes (see Figure 3.5), so we can expect product B to be the thermodynamic product. Figure 3.5: Negative enthalpies of hydrogenation, \\(-\\Delta H_\\mathrm{hyd}\\), for the series of C6H12 alkenes. The enthalpy of hydrogenation becomes less negative (less exothermic) as the degree of substitution of the alkene increases, indicating an increased stability of the C=C double bond. The kinetic product is the product that forms fastest at the start of the reaction, so to identify the kinetic product, we need to consider the relative rates of forward reactions, \\(k_\\mathrm{A}\\) and \\(k_\\mathrm{B}\\). Because of the methyl group at position 2, the proton at position 2 is sterically hindered, while the proton at position 6 is not. We can therefore expect the proton at position 6 to be removed more easily than the proton at position 2, with product A, therefore, formed faster than product B. Product A is the kinetic product. Figure 3.6: Removing the proton at position 6 gives product A, while removing the proton at position 2 gives product B. The proton at position 2 is more sterically hindered than the proton at position 6, so is harder to remove. Now that we have identified the kinetic product as product A and the thermodynamic product as product B, we can think about why using a strong base gives predominantly product A (kinetic control) but a weak base gives predominantly product B (thermodynamic control). First, let us consider the case of using a strong base. We have already identified that \\(k_\\text{A} &gt; k_\\text{B}\\), by considering which proton is more easily removed. In the presence of a strong base, we can also say that the position of equilibrium for both products ie expected to strongly favour the products, i.e., \\(K_\\mathrm{A} \\gg 1\\) and \\(K_\\mathrm{B} \\gg 1\\). For a reversible reaction the equilibrium constant is equal to the ratio of rate constants for the forward and reverse reactions, so: \\[\\begin{equation} \\frac{k_\\mathrm{A}}{k_{-\\mathrm{A}}} \\gg 1 \\qquad \\frac{k_\\mathrm{B}}{k_{-\\mathrm{B}}} \\gg 1. \\end{equation}\\] Both reverse reactions, B → R and C → R, where R is the reactant, are much slower than the corresponding forward reactions, and so we can treat both reactions as effectively irreversible. At the start of the reaction, product A is formed much more quickly than product B, and the relative amounts of products A and B reflect the different rates of the two forward reactions. Hence, we obtain a very high selectivity for the kinetic product A. We can also analyse the selectivity for product A over product B using a reaction coordinate diagram (Figure 3.7). Because \\(K_\\mathrm{A} \\gg 1\\) and \\(K_\\mathrm{B} \\gg 1\\), the free energies of formation of both products, A and B, are large (because \\(\\Delta G_\\mathrm{r} = -RT \\ln K\\)). This means the barriers for the reverse reactions A → R and B → R are large, and these reverse reactions are very slow, making both reactions effectively irreversible. In addition, the barrier for R → A is lower than the barrier for R → B, so product A will form faster than product B. This combination of faster formation of A than of B and effective irreversibility of both reactions gives us strong selectivity for the kinetic product, A. Figure 3.7: In the presence of a strong base, the position of equilibrium strongly favours both enolates, and both forward reactions are effectively irreversible. The pathway R → A has a lower activation barrier than the pathway R → B, so product A is formed faster than product B, resulting in strong selectivity for product A. In the presence of a weak base, both equilibria are more balanced: \\(K_\\mathrm{A} \\approx 1\\) and \\(K_\\mathrm{B} \\approx 1\\). Again, using the fact that these equiibrium constants are equal to the ratios of rate constants for the forward and reverse reactions, this tells us that \\(k_{-\\mathrm{A}} \\approx k_\\mathrm{A}\\) and \\(k_{-\\mathrm{B}} \\approx k_\\mathrm{B}\\), i.e., both reverse reactions have rates that are approximately equal to the corresponding forward reactions, and are therefore highly reversible. We still have \\(k_\\text{A} &gt; k_\\text{B}\\), and, so, at the start of the reaction product A forms faster than product B. But, because R → A is reversible, A is able to convert back to the reactant and then to form product B. Eventually we end up with a ratio [B]/[A] that reflects the free energy difference between the two products, with preferential formation for the thermodynamic product, B. Figure 3.8: In the presence of a weak base, the position of equilibrium less strongly favours both enolates, and both reactions are effectively reversible. Now the selectivity is determined by the free energy difference between the two products. Because B is more thermodymamically stable than A (because it is the more substituted enolate), we get preferential selectivity for the thermodynamic product B. "],["lecture4.html", "Lecture 4 Numerical Integration 4.1 From Mechanisms to Kinetic Data 4.2 The Role of Integration in Chemical Kinetics 4.3 Principles of Numerical Integration 4.4 Sources of Error 4.5 The Role of Numerical Integration in Chemical Kinetics", " Lecture 4 Numerical Integration 4.1 From Mechanisms to Kinetic Data One reason to study the kinetics of reactions is beacause kinetic data can provide us with information about reaction mechanisms. Often, we start by collecting experimental concentration-time data for some reaction, and using this to deduce an empirical rate law (see CH12002 Lecture 4). Once we have an empirical rate law, this can inform our thinking around possible reaction mechanisms. The rate law may be of the same form as for another reaction where we know the mechanism, and so we propose that our current reaction proceeds by an equivalent mechanism. Or our empirical rate law simply acts as a constraint: any proposed mechanisms must give a theoretical rate law that is consistent with out experimentally deduced rate law. Alternatively, we might start from some hypothetical reaction mechanism: perhaps proposed on the basis of some prior chemical knowledge we have about our specific reaction. From this proposed mechanism, we can predict the shape of concentration-time profiles we would expect in experiments, given that our mechanism is correct, and then compare our predicted concentration-time profiles to those obtained from experiments. If we find good agreement between our predicted concetration-time data and those recorded experimentally then this provides support for our proposed mechanism being correct. If our predicted concentration-time data, however, do not agree with our experimental results — in particular, if the predicted and experimental concentration-time profiles have qualitatively different shapes — then we can reject the proposed mechanism on the basis that it is inconsistent with experiment. 4.2 The Role of Integration in Chemical Kinetics For simple reaction mechanisms, we can often derive analytical expressions for how concentrations change with time. Consider a first-order reaction \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\). The differential rate equation is \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] \\tag{4.1} \\end{equation}\\] and we can solve this by integration to obtain \\[\\begin{equation} [\\mathrm{A}]_t = [\\mathrm{A}]_0\\mathrm{e}^{-kt} \\tag{4.2} \\end{equation}\\] However, for many reaction mechanisms, deriving analytical solutions becomes either extremely difficult or impossible. Consider, for example, the Lindemann mechanism for a unimolecular reaction: \\[\\begin{align*} \\mathrm{A} + \\mathrm{M} &amp;\\rightleftharpoons \\mathrm{A}^* + \\mathrm{M} &amp; k_1,\\, k_{-1} \\\\ \\mathrm{A}^* &amp;\\longrightarrow \\mathrm{P} &amp; k_2 \\end{align*}\\] The corresponding differential rate equations are: \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k_1[\\mathrm{A}][\\mathrm{M}] + k_{-1}[\\mathrm{A}^*][\\mathrm{M}] \\tag{4.3} \\end{equation}\\] \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}^*]}{\\mathrm{d}t} = k_1[\\mathrm{A}][\\mathrm{M}] - k_{-1}[\\mathrm{A}^*][\\mathrm{M}] - k_2[\\mathrm{A}^*] \\tag{4.4} \\end{equation}\\] \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{P}]}{\\mathrm{d}t} = k_2[\\mathrm{A}^*] \\tag{4.5} \\end{equation}\\] While we can make approximations (such as the steady-state approximation) to derive approximate analytical solutions under certain conditions, numerical integration provides a general approach that can be applied to any mechanism, regardless of its complexity. 4.3 Principles of Numerical Integration To understand how numerical integration works, let us return to our simple first-order reaction \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\). The differential rate equations are: \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] \\tag{4.6} \\end{equation}\\] \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = +k[\\mathrm{A}] \\tag{4.7} \\end{equation}\\] The numerical integration approach recognises that these equations tell us the instantaneous rates of change of \\([\\mathrm{A}]\\) and \\([\\mathrm{B}]\\) at any point in time. If we know these rates at time \\(t\\), we can estimate the concentrations a short time later, at \\(t + \\Delta t\\): \\[\\begin{equation} [\\mathrm{A}]_{t+\\Delta t} = [\\mathrm{A}]_t + \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\Delta t \\tag{4.8} \\end{equation}\\] \\[\\begin{equation} [\\mathrm{B}]_{t+\\Delta t} = [\\mathrm{B}]_t + \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\Delta t \\tag{4.9} \\end{equation}\\] where \\(\\Delta t\\) is called the time step. Starting with known initial concentrations at \\(t = 0\\), we can use these equations to “step forward” in time, calculating new concentrations at each step. 4.3.1 A Simple Example Let us work through a specific example. Consider the first-order reaction above with \\(k = 1\\,\\mathrm{s}^{-1}\\) and initial conditions \\([\\mathrm{A}]_0 = 1\\,\\mathrm{M}\\) and \\([\\mathrm{B}]_0 = 0\\,\\mathrm{M}\\). Using a time step \\(\\Delta t = 0.1\\,\\mathrm{s}\\): At \\(t = 0~\\mathrm{s}\\): \\([\\mathrm{A}]_0 = 1~\\mathrm{M}\\) \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(1~\\mathrm{s}^{-1})(1~\\mathrm{M}) = -1~\\mathrm{M}~\\mathrm{s}^{-1}\\) \\([\\mathrm{A}]_{0.1} = 1~\\mathrm{M} + (-1~\\mathrm{M}\\mathrm{s}^{-1})(0.1\\mathrm{s}) = 0.9~\\mathrm{M}\\) Similarly, \\([\\mathrm{B}]_{0.1} = 0~\\mathrm{M} + (1~\\mathrm{M}\\mathrm{s}^{-1})(0.1\\mathrm{s}) = 0.1~\\mathrm{M}\\) At \\(t = 0.1~\\mathrm{s}\\): \\([\\mathrm{A}]_{0.1} = 0.9~\\mathrm{M}\\) \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(1~\\mathrm{s}^{-1})(0.9~\\mathrm{M}) = -0.9~\\mathrm{M}~\\mathrm{s}^{-1}\\) \\([\\mathrm{A}]_{0.2} = 0.9~\\mathrm{M} + (-0.9~\\mathrm{M}\\mathrm{s}^{-1})(0.1\\mathrm{s}) = 0.81~\\mathrm{M}\\) This process continues, giving us approximate values for \\([\\mathrm{A}]_t\\) and \\([\\mathrm{B}]_t\\) at discrete time points. 4.4 Sources of Error The numerical integration method makes one key approximation: it assumes the reaction rates remain constant over each time step. In reality, rates change continuously as concentrations change. This approximation introduces systematic errors that become larger when: The time step \\(\\Delta t\\) is increased Reaction rates change more rapidly within each time step We can improve accuracy by: Using a smaller time step (at the cost of more computational steps) Using more sophisticated algorithms (e.g., Runge-Kutta methods) that better approximate the changing reaction rates 4.5 The Role of Numerical Integration in Chemical Kinetics Numerical integration is an essential tool for modern studies of complex reaction mechanisms. The methods outlined above can handle mechanisms of arbitrary complexity, from simple decomposition reactions through to complex biochemical networks. Where analytical solutions become intractable, numerical methods remain practical and reliable. The accuracy of numerical solutions depends primarily on the chosen time step. While the simple Euler method presented here illustrates the key principles, modern numerical integration routines use more sophisticated algorithms. These “adaptive” methods automatically adjust their time steps based on how rapidly concentrations change. Small time steps maintain accuracy during periods of rapid change, while larger steps efficiently handle slower phases of the reaction. This automatic adaptation makes numerical integration both more reliable and more computationally efficient than fixed-step methods. The real power of numerical integration emerges when comparing theoretical predictions with experimental data. Given a proposed mechanism, we can calculate concentration profiles and compare these directly with measurements. Agreement between calculation and experiment supports the proposed mechanism, while significant discrepancies suggest the mechanism needs revision. This approach proves especially valuable for complex mechanisms where analytical solutions cannot guide our intuition about expected behavior. Beyond testing mechanisms, numerical methods help extract rate constants from experimental data and explore how changing conditions affects reaction outcomes. The principles developed in this chapter underpin much of modern chemical kinetics, complementing the analytical methods examined in earlier lectures. "],["lecture5.html", "Lecture 5 Collision Theory 5.1 Introduction to Kinetic Theories 5.2 Fundamentals of Collision Theory 5.3 From Collisions to Reaction Rates 5.4 Relationship to the Arrhenius Equation 5.5 Limitations of Collision Theory as a Predictive Framework", " Lecture 5 Collision Theory 5.1 Introduction to Kinetic Theories Up to this point, we have focused on describing and interpreting empirical data—either deriving rate laws from experimental data or proposing reaction mechanisms and comparing their predictions against observations. While this approach allows us to understand the shape of concentration–time profiles, it does not explain quantitative differences in reaction rates. Several important questions remain: - For two bimolecular reactions, which would we expect to be faster, and by how much? - Can we predict rate constants \\(k\\) (and how they vary with temperature) without experimental data? While we have discussed the Arrhenius equation, \\(k = A_0\\mathrm{e}^{-\\Delta E/RT}\\), this is an approximate empirical relationship that requires experimental data to determine \\(A_0\\) and \\(\\Delta E\\). To move beyond empirical descriptions, we need microscopic theories that can make quantitative predictions of reaction rates. In this course, we will examine two such theories: Collision Theory (this lecture)—focuses on gas-phase bimolecular reactions, treating molecules as hard spheres Transition State Theory (lectures 6–9)—considers formation of activated complexes for all types of reactions 5.2 Fundamentals of Collision Theory Collision theory provides one of the simplest microscopic models of reaction rates, specifically for gas-phase bimolecular reactions of the form: \\[\\mathrm{A} + \\mathrm{B} \\rightarrow \\mathrm{P}\\] For such reactions, we expect a rate law of the form \\(\\nu = k[\\mathrm{A}][\\mathrm{B}]\\), but what determines the value of \\(k\\)? 5.2.1 Basic Principles and Assumptions Building on the kinetic theory of gases, collision theory makes two key assumptions: Molecules behave as hard spheres Molecules must collide to react The overall reaction rate is then: rate = rate of collisions × fraction of “successful” collisions 5.2.2 Collision Frequency Consider two molecules A and B with radii \\(r_\\mathrm{A}\\) and \\(r_\\mathrm{B}\\) and velocities \\(v_\\mathrm{A}\\) and \\(v_\\mathrm{B}\\). To analyze their collisions, we can adopt the reference frame of molecule B, where: B appears stationary A moves with relative velocity \\(v = v_\\mathrm{B} - v_\\mathrm{A}\\) A collision occurs when the closest distance of approach (the “impact parameter” \\(b\\)) is less than the sum of the molecular radii: \\[b &lt; (r_\\mathrm{A} + r_\\mathrm{B}) = d\\] As molecule A moves through space, it sweeps out a cylindrical volume: Radius = \\(d = (r_\\mathrm{A} + r_\\mathrm{B})\\) Length (per unit time) = \\(v\\) (the relative velocity) Volume (per unit time) = \\(vS = v\\pi d^2\\) The collision frequency per unit volume (\\(Z&#39;\\)) is then: \\[Z&#39; = \\frac{N_\\mathrm{A}N_\\mathrm{B}}{V^2}v\\pi d^2\\] where \\(N_\\mathrm{A}\\) and \\(N_\\mathrm{B}\\) are the numbers of molecules of each species in volume \\(V\\). 5.2.3 Average Relative Velocity The relative velocity between molecules follows the Maxwell-Boltzmann distribution. The average relative velocity is: \\[\\bar{v} = \\left(\\frac{8k_\\mathrm{B}T}{\\pi \\mu}\\right)^\\frac{1}{2}\\] where \\(\\mu\\) is the reduced mass: \\[\\mu = \\frac{m_\\mathrm{A}m_\\mathrm{B}}{m_\\mathrm{A} + m_\\mathrm{B}}\\] Substituting this into our expression for collision frequency: \\[Z&#39; = \\frac{N_\\mathrm{A}N_\\mathrm{B}}{V^2}\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi \\mu}\\right)^\\frac{1}{2}\\] 5.3 From Collisions to Reaction Rates 5.3.1 Successful Collisions Not all collisions lead to reaction. We assume a collision is successful if the relative kinetic energy exceeds a threshold activation energy \\(E_\\mathrm{a}\\). For a Maxwell-Boltzmann distribution, the fraction of collisions with sufficient energy is: \\[P(E \\geq E_\\mathrm{a}) = \\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] This gives a total reaction rate: \\[\\nu = Z&#39; \\times P(E \\geq E_\\mathrm{a}) = \\frac{N_\\mathrm{A}N_\\mathrm{B}}{V^2}\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi \\mu}\\right)^\\frac{1}{2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] This can be written in the familiar form of a second-order rate law: \\[\\begin{equation} \\nu=k[\\mathrm{A}][\\mathrm{B}] \\end{equation}\\] where \\[\\begin{equation} k = \\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi \\mu}\\right)^\\frac{1}{2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\end{equation}\\] 5.3.2 Steric Factors When we compare the reaction rates predicted by collision theory with experimental measurements, we typically find that collision theory overestimates reaction rates, sometimes by several orders of magnitude. This discrepancy arises because our model of molecules as hard spheres is an oversimplification—successful reactions often require specific molecular orientations or more complex interactions than simple collisions. To account for these effects, we introduce an empirical correction factor \\(P\\), called the steric factor, that modifies our expression for the rate constant: \\[\\begin{equation} k = P\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.1} \\end{equation}\\] The steric factor \\(P\\) is defined as the ratio of the experimental pre-exponential factor to the theoretical value predicted by collision theory: \\[\\begin{equation} P = \\frac{A_\\mathrm{exp}}{A_\\mathrm{th}} \\tag{5.2} \\end{equation}\\] Different types of reactions exhibit characteristic ranges of steric factors. Consider these examples: For the hydrogenation of ethene: H2+C2H4\\(\\longrightarrow\\)C2H6 \\(P = 1.7 \\times 10^{-6}\\). This very small steric factor reflects the strict geometric requirements for reaction—the H2 molecule must approach the C=C double bond in a specific orientation for reaction to occur. For the reaction between potassium and bromine: K+Br2\\(\\longrightarrow\\)KBr+Br \\(P = 4.8\\). Here the steric factor is greater than unity, indicating that reactions occur more frequently than predicted by simple collision theory. This enhanced reactivity arises from the “harpoon mechanism”, where electron transfer between K and Br2 creates long-range attractive forces that effectively increase the collision cross-section. 5.4 Relationship to the Arrhenius Equation The rate constant derived from collision theory has a remarkably similar form to the empirical Arrhenius equation. Let us compare them directly: From collision theory: \\[\\begin{equation} k = P\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.3} \\end{equation}\\] The Arrhenius equation: \\[\\begin{equation} k = A_0\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.4} \\end{equation}\\] This comparison provides physical insight into the meaning of the Arrhenius parameters: The activation energy \\(E_\\mathrm{a}\\) in the Arrhenius equation can be interpreted as the minimum relative kinetic energy that colliding molecules must possess for reaction to occur. This threshold energy is needed to overcome the potential energy barrier to reaction. The pre-exponential factor \\(A_0\\) represents a normalized collision frequency. The collision theory expression shows that this frequency depends on: The collision cross-section (\\(\\pi d^2\\)) The average relative velocity of molecules (\\(\\propto \\sqrt{T/\\mu}\\)) A steric factor \\(P\\) that accounts for orientation requirements Therefore, while the Arrhenius equation was originally proposed as an empirical relationship, collision theory provides a theoretical foundation for its functional form and offers molecular-level interpretations of its parameters. However, we should note that this interpretation is strictly valid only for gas-phase bimolecular reactions. For more complex reactions, particularly in solution, the physical meaning of the Arrhenius parameters becomes less clear, and we need more sophisticated theories to understand their molecular basis. 5.5 Limitations of Collision Theory as a Predictive Framework Collision theory works reasonably well for simple molecules but typically overestimates reaction rates for complex molecules. Two key limitations prevent collision theory from serving as a fully predictive framework: The activation energy E\\(\\mathrm{a}\\) appears as an arbitrary “threshold energy” that molecules must possess to react. While we can measure this energy experimentally, the theory provides no insight into how \\(E_\\mathrm{a}\\) varies between different reactions. While we can determine the steric factor \\(P\\) by comparing experimental and theoretical rate constants, we have no quantitative theory to predict its value. This means we cannot predict absolute rate constants for new reactions without experimental data. "],["lecture6.html", "Lecture 6 Transition State Theory 6.1 A Molecular Theory of Reaction Rates 6.2 Basic Principles of Transition State Theory 6.3 Mathematical Development of Transition State Theory 6.4 Relationship to the Arrhenius Equation 6.5 Enthalpy of Activation 6.6 Reconciling Transition State Theory with Collision Theory 6.7 Entropy of Activation", " Lecture 6 Transition State Theory 6.1 A Molecular Theory of Reaction Rates Collision theory explains reaction rates using a simple model of colliding spheres. While this works for some gas-phase reactions, it cannot predict steric factors or explain systematic trends in activation energies. We need a more sophisticated approach. For a reaction A + B → P, molecules must pass over an energy barrier before forming products. The reaction coordinate diagram shows this energy profile, from reactants through to products. The point at the highest point of the energy barrier is called the transition state; at this point the reacting molecules form a specific arrangement called the activated complex1, in which bonds are partially broken and new bonds are starting to form. Transition state theory provides a framework for analyzing this activated complex and using it to predict reaction rates. Figure 6.1: A reaction coordinate diagram for the reaction A + B → P. The energy profile shows the barrier that must be crossed as reactants are converted to products. The peak of this barrier corresponds to the transition state configuration, and the collection of molecules at the transition state form the activated complex, C\\(^\\ddagger\\). 6.2 Basic Principles of Transition State Theory Transition state theory treats the overall reaction A + B → P as occurring in two steps. First, the reactants A and B combine to form the activated complex C\\(^{\\ddagger}\\). This complex can either fall apart back to reactants or go on to form products. The theory makes a key assumption: we can treat the activated complex as being in equilibrium with the reactants, even though C\\(^{\\ddagger}\\) is inherently unstable. We call this a pseudo-equilibrium to reflect this special status. The second step is the conversion of C\\(^{\\ddagger}\\) to products, which we assume occurs with a characteristic rate constant \\(k^{\\ddagger}\\). This is a first-order process — the rate depends only on the concentration of the activated complex: \\[\\nu = \\frac{\\mathrm{d}[\\mathrm{P}]}{\\mathrm{d}t} = k^{\\ddagger}[\\mathrm{C}^{\\ddagger}]\\] We can write the complete process as: \\[\\begin{equation} \\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^{\\ddagger} \\xrightarrow{k^{\\ddagger}} \\mathrm{P} \\tag{6.1} \\end{equation}\\] 6.3 Mathematical Development of Transition State Theory To develop our rate equation, we begin by considering the pseudo-equilibrium between reactants and the activated complex. We can define a pseudo-equilibrium constant: \\[\\begin{equation} K^{\\ddagger} = \\frac{[\\mathrm{C}^{\\ddagger}]c^\\circ}{[\\mathrm{A}][\\mathrm{B}]} \\tag{6.2} \\end{equation}\\] where \\(c^\\circ\\) = 1 mol dm−3 is the standard concentration.2 This allows us to express the concentration of the activated complex in terms of reactant concentrations: \\[\\begin{equation} [\\mathrm{C}^{\\ddagger}] = (K^{\\ddagger}/c^\\circ)[\\mathrm{A}][\\mathrm{B}] \\tag{6.3} \\end{equation}\\] Since we treat the formation of the activated complex as a pseudo-equilibrium, we can apply standard thermodynamic relationships. The equilibrium constant \\(K^{\\ddagger}\\) relates to the activation Gibbs energy through: \\[\\begin{equation} \\Delta G^{\\ddagger} = -RT\\ln(K^{\\ddagger}) \\tag{6.4} \\end{equation}\\] We can then use the standard relationship \\(\\Delta G^\\ddagger = \\Delta H^\\ddagger - T \\Delta S^\\ddagger\\) to separate \\(K^\\ddagger\\) into enthalpic and entropic terms: \\[\\begin{equation} K^{\\ddagger} = \\mathrm{e}^{-\\Delta G^{\\ddagger}/RT} = \\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}\\mathrm{e}^{\\Delta S^{\\ddagger}/R} \\tag{6.5} \\end{equation}\\] From our second assumption, the rate of product formation is proportional to the concentration of the activated complex: \\[\\begin{equation} \\nu = k^{\\ddagger}[\\mathrm{C}^{\\ddagger}] = \\frac{k^{\\ddagger}}{c^{\\circ}}[\\mathrm{A}][\\mathrm{B}]\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT} \\tag{6.6} \\end{equation}\\] This expression is known as the Eyring equation, and has the form of a second-order rate law with rate constant: \\[\\begin{equation} k = \\frac{k^{\\ddagger}}{c^{\\circ}}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT} \\tag{6.7} \\end{equation}\\] 6.4 Relationship to the Arrhenius Equation We can understand how transition state theory connects to experimental observations by comparing the rate constant expression with the Arrhenius equation: From transition state theory: \\[\\begin{equation} k = \\frac{k^{\\ddagger}}{c^{\\circ}}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT} \\tag{6.8} \\end{equation}\\] The Arrhenius equation: \\[\\begin{equation} k = A\\mathrm{e}^{-E_\\mathrm{a}/RT} \\tag{5.4} \\end{equation}\\] This comparison reveals two important correspondences: The activation enthalpy \\(\\Delta H^{\\ddagger}\\) plays a similar role to the Arrhenius activation energy \\(E_\\mathrm{a}\\). The pre-exponential factor \\(A\\) corresponds to \\(\\frac{k^{\\ddagger}}{c^{\\circ}}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\). Like collision theory, transition state theory provides a molecular-level interpretation of the Arrhenius parameters. However, transition state theory offers additional insight by separating the activation barrier into enthalpic (\\(\\Delta H^{\\ddagger}\\)) and entropic (\\(\\Delta S^{\\ddagger}\\)) contributions, helping explain systematic variations in reactivity across related compounds. 6.5 Enthalpy of Activation The enthalpy of activation \\(\\Delta H^{\\ddagger}\\) represents the enthalpic contribution to forming the activated complex. For a simple reaction where C breaks an A–B bond to form B–C, examining what happens at the transition state reveals why this enthalpy change varies systematically between related reactions. In the activated complex, the original A–B bond is almost completely broken, while the new B–C bond has only started to form. This means \\(\\Delta H^{\\ddagger}\\) depends primarily on the strength of the bond being broken. The strength of the bond being formed has much less effect, since this bond is still weak in the transition state. This principle helps explain trends in activation energies for a family of related reactions. Consider these examples involving H and Br: \\[\\begin{align*} \\mathrm{H–H} + \\mathrm{H} &amp;\\longrightarrow \\mathrm{H} + \\mathrm{H–H} &amp; E_\\mathrm{a} &amp;= +39~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{H–H} + \\mathrm{Br} &amp;\\longrightarrow \\mathrm{H} + \\mathrm{H–Br} &amp; E_\\mathrm{a} &amp;= +82~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{Br–H} + \\mathrm{H} &amp;\\longrightarrow \\mathrm{Br} + \\mathrm{H–H} &amp; E_\\mathrm{a} &amp;= +12~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{Br–Br} + \\mathrm{H} &amp;\\longrightarrow \\mathrm{Br} + \\mathrm{Br–H} &amp; E_\\mathrm{a} &amp;= +4~\\mathrm{kJ~mol^{-1}} \\end{align*}\\] To understand these trends, we need to consider the bond dissociation energies: \\[\\begin{align*} \\mathrm{H–H}: &amp; ~E_\\mathrm{d} = +436~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{H–Br}: &amp; ~E_\\mathrm{d} = +366~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{Br–Br}: &amp; ~E_\\mathrm{d} = +193~\\mathrm{kJ~mol^{-1}} \\end{align*}\\] The trends in activation energy can be explained by: The first two reactions involve breaking H–H bonds (highest \\(E_\\mathrm{d}\\)) → highest \\(E_\\mathrm{a}\\) values Between these two: H–H + H forms H–H (more favorable) H–H + Br forms H–Br (less favorable) Therefore \\(E_\\mathrm{a}\\) is lower for H–H + H The remaining reactions follow the trend in bond strength being broken: Breaking H–Br (\\(E_\\mathrm{a} = +12~\\mathrm{kJ~mol^{-1}}\\)) Breaking Br–Br (\\(E_\\mathrm{a} = +4~\\mathrm{kJ~mol^{-1}}\\)) 6.6 Reconciling Transition State Theory with Collision Theory At first glance, Collision theory and transition state theory can seem to give different pictures of activation energy. In collision theory, \\(E_\\mathrm{a}\\) represents a minimum kinetic energy molecules must have to react. In transition state theory, \\(\\Delta H^{\\ddagger}\\) represents the energy needed to distort and partially break bonds bonds in the activated complex. We can connect these views by following the energy through a reactive collision. Initially, the molecules approach with kinetic energy at least equal to \\(E_\\mathrm{a}\\). As they collide, this kinetic energy transforms into potential energy, with the molecular geometry distorting to form the activated complex. Here, the initial kinetic energy has become the energy stored in partially broken and formed bonds — our \\(\\Delta H^{\\ddagger}\\). By energy conservation, these energies must be approximately equal. The two theories thus describe the same process from different perspectives: collision theory focuses on the keinetic energy molecules must have before they collide, while transition state theory considers how this energy is used in making and breaking bonds. 6.7 Entropy of Activation We have seen that transition state theory provides a molecular interpretation of the Arrhenius pre-exponential factor \\(A\\) in terms of an entropy of activation \\(\\Delta S^{\\ddagger}\\). To understand what this entropy term means and what determines its magnitude, we need to think carefully about what entropy means at a molecular level. 6.7.1 Understanding Molecular Entropy While entropy is often simply described as a measure of “disorder”, this description can be misleading. For many chemical reactions, simple arguments based on relative “disorder” fail to predict even qualitative behaviour. This becomes particularly apparent when considering gas-phase reactions: both reactants and products exist as freely moving molecules, so which state is more “disordered”? A more useful framework considers entropy in terms of molecular freedom and statistical likelihood. Systems with greater freedom have higher entropy than more constrained systems, and molecular arrangements that are statistically more likely have higher entropy than less likely arrangements. The spontaneous expansion of an ideal gas illustrates these ideas. An ideal gas expands to fill its container despite no change in internal energy (\\(\\Delta U = 0\\)) or enthalpy (\\(\\Delta H = 0\\), since \\(pV = nRT\\)). This process occurs spontaneously because the expanded state has higher entropy: gas molecules have more freedom to move through a larger volume, and an even distribution throughout the available space is statistically more likely than having all molecules confined to a smaller region. 6.7.2 Entropy of Activation for Bimolecular Reactions For a gas-phase bimolecular reaction, forming the activated complex introduces new constraints on molecular motion: \\[\\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^{\\ddagger}\\] Each molecule in the gas phase has three translational degrees of freedom—the molecules are free to move along the \\(x\\), \\(y\\), and \\(z\\) axes, independently of the motion of the other molecules in the system. The reactants A and B therefore have six translational degrees of freedom between them. When these molecules combine to form the activated complex, however, we have just three translational degrees of freedom, since \\(\\mathrm{C}^{\\ddagger}\\) moves as a single unit through space. This loss of translational freedom corresponds to a decrease in entropy. For gas-phase bimolecular reactions, \\(\\Delta S^{\\ddagger}\\) is therefore always negative, reflecting the increased constraints imposed when forming the activated complex. In our treatment using 2D reaction coordinate diagrams, we represent the transition state as a single point at the peak of the energy barrier. In reality, for a molecular system with many degrees of freedom, the transition state is a dividing surface on the multidimensional potential energy surface. The “activated complex” comprises all molecular configurations on this dividing surface.↩︎ Many basic treatments of transition state theory omit \\(c^{\\circ}\\) since it equals 1 under standard conditions. Including it ensures that \\(K^\\ddagger\\) is correctly defined as dimensionless, and that \\(k\\) has the correct units for a second-order rate constant of dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\).↩︎ "],["lecture7.html", "Lecture 7 Molecular Freedom and Entropy of Activation 7.1 Qualitative Analysis: Atomic and Molecular Reactions 7.2 Thermodynamic Origin of the Steric Factor 7.3 Molecular Degrees of Freedom 7.4 A Simple Example: Atom-Atom Reaction 7.5 Energy Spacings and Entropy 7.6 Towards Quantitative Predictions", " Lecture 7 Molecular Freedom and Entropy of Activation In Lecture 6, we began thinking about the entropy of activation \\(\\Delta S^{\\ddagger}\\) in terms of changes in molecular freedom when forming the activated complex. We can develop this idea to understand systematic variations in the Arrhenius pre-exponential factor between different bimolecular reactions. We begin with a qualitative analysis before examining the molecular details more carefully. 7.1 Qualitative Analysis: Atomic and Molecular Reactions Consider first a bimolecular reaction between two atoms. As discussed in the previous lecture, forming the activated complex reduces the number of translational degrees of freedom from 6 (3 for each atom) to 3. This loss of translational freedom corresponds to a loss of translational entropy, making \\(\\Delta S^{\\ddagger}\\) negative. Now consider a reaction between two diatomic molecules. Each reactant molecule has 3 degrees of translational freedom and 2 degrees of rotational freedom. The activated complex has 3 translational degrees of freedom and 3 rotational degrees of freedom. Forming the activated complex now involves a decrease in the numbers of translational and rotational degrees of freedom. And we, therefore, might expect a larger, more negative, entropy of activation for this reaction than for the simpler case involving two atoms. Figure 7.1: Comparing entropy changes when forming the activated complex. Left: For atomic reactions, forming the activated complex involves only loss of translational entropy. Right: For molecular reactions, forming the activated complex involves loss of both translational and rotational entropy. This additional entropic cost makes \\(\\Delta S^{\\ddagger}\\) more negative for molecular reactions, leading to smaller pre-exponential factors. 7.2 Thermodynamic Origin of the Steric Factor In our analysis of collision theory in Lecture 5, we saw that reactions between more complex molecules typically have smaller steric factors. We interpreted this as reflecting the need for specific molecular orientations during collision. Transition state theory provides a thermodynamic perspective on this observation: in general, we can expect more complex reactant molecules to lose more molecular freedom when forming the activated complex, leading to a more negative \\(\\Delta S^{\\ddagger}\\) and consequently a smaller pre-exponential factor \\(A\\). While this idea, that degree to which we lose translational and rotational degrees of freedom on forming the activated complex, is broadly correct, it is incomplete: we have not considered vibrational degrees of freedom, and we do not have a framework that can predict differences in pre-exponential factor between two molecular reactions. To proceed towards a more quantitative treatment of entropy of activation, we need a more complete accounting of all molecular degrees of freedom in the reactants and activated complex. 7.3 Molecular Degrees of Freedom To analyse molecular freedom systematically, we begin by counting the degrees of freedom available to a molecule containing \\(N\\) atoms. Each atom has three degrees of freedom, corresponding to motion in three dimensions. The total number of atomic degrees of freedom is therefore \\(3N\\). These atomic motions can be combined to give \\(3N\\) molecular degrees of freedom that describe the collective motion of the molecule.3 Molecular degrees of freedom can be classified into three types: Translational motion of the entire molecule through space. Rotation of the molecule about its principal axes. Vibrational motion where atoms move relative to each other. A linear molecule has: 3 translational degrees of freedom. 2 rotational degrees of freedom. \\(3N-5\\) vibrational degrees of freedom. A non-linear molecule has: 3 translational degrees of freedom. 3 rotational degrees of freedom. \\(3N-6\\) vibrational degrees of freedom. 7.4 A Simple Example: Atom-Atom Reaction We can partition \\(\\Delta S^{\\ddagger}\\) into contributions from different degrees of freedom. Consider the simplest case: a reaction between two atoms, A + B, forming an activated complex C‡: \\[\\begin{equation} \\mathrm{A} + \\mathrm{B} \\longrightarrow \\mathrm{C}^{\\ddagger} \\end{equation}\\] Let us count the degrees of freedom for the reactants and activated complex. Reactants (two separate atoms): Each atom can move independently in three-dimensional space, giving 3 translational degrees of freedom per atom. Since we have two atoms, the total translational degrees of freedom is 3 + 3 = 6. Atoms are point masses, so they have no rotational degrees of freedom (rotation requires at least two atoms held at a fixed distance). Similarly, single atoms cannot vibrate. Therefore, the reactants have 6 translational degrees of freedom and nothing else. Activated complex (diatomic species): The activated complex C\\(^\\ddagger\\) is a diatomic species where the two atoms are connected. This single entity moves through space as a unit, giving 3 translational degrees of freedom for the centre of mass of the complex. The complex can rotate about axes perpendicular to the bond connecting the two atoms. For a linear molecule, there are 2 rotational degrees of freedom (rotation about the bond axis itself does not change the molecule’s orientation, so only the two perpendicular axes count). Finally, the two atoms in the complex can move relative to each other along the bond—stretching and compressing. This gives 1 vibrational degree of freedom, which corresponds to motion through the transition state along the reaction coordinate. The total is therefore 3 + 2 + 1 = 6 degrees of freedom. Figure 7.2: Counting degrees of freedom for the reaction A + B \\(\\longrightarrow\\) C\\(^{\\ddagger}\\). The total number of degrees of freedom (trans + rot + vib) is conserved: both reactants and activated complex have 6 degrees of freedom. However, the character of these degrees of freedom changes, with translational motion converted into rotational and vibrational motion. The total number of degrees of freedom is preserved: both the reactants and the activated complex have 6 degrees of freedom. So why is \\(\\Delta S^{\\ddagger} \\neq 0\\)? The answer lies in understanding that different types of molecular motion contribute very differently to entropy. 7.5 Energy Spacings and Entropy Quantum mechanics tells us that the energy levels for molecular motion are quantised. The spacing between these levels varies significantly with the type of motion: \\[\\begin{equation} \\Delta \\epsilon_\\mathrm{trans} \\ll \\Delta \\epsilon_\\mathrm{rot} &lt; \\Delta \\epsilon_\\mathrm{vib} \\end{equation}\\] To understand why this matters for entropy, we need the statistical mechanical foundation provided by Boltzmann’s equation: \\[\\begin{equation} S = k \\ln W \\end{equation}\\] where \\(W\\) represents the number of thermally accessible microstates—the different possible arrangements available to the system at a given energy. This equation tells us that entropy increases with the number of ways energy can be distributed across the available states. The hierarchy of energy spacings directly determines \\(W\\) for each type of motion. When energy levels are closely spaced, there are many thermally accessible states at typical temperatures—many different ways to distribute the available energy across the system, giving large \\(W\\) and hence high entropy. Conversely, when energy levels are widely spaced, only a few low-lying states can be populated, giving few ways to distribute the energy, small \\(W\\), and low entropy. Figure 7.3: Energy level diagrams for different types of molecular motion. Small energy spacing (left) gives many thermally accessible energy levels and many ways to distribute energy, corresponding to high entropy. Large energy spacing (right) gives few thermally accessible energy levels and few ways to distribute energy, corresponding to low entropy. For molecular motion, translational energy levels are narrowly spaced and appear almost continuous. At room temperature, an enormous number of translational states are accessible, giving very high entropy. Rotational energy levels are more widely spaced, with fewer accessible states. Vibrational energy levels are spaced more widely still, with only a few low-lying states thermally accessible at typical temperatures. This leads to the entropy hierarchy: \\[\\begin{equation} S^{\\ddagger}_\\mathrm{trans} \\gg S^{\\ddagger}_\\mathrm{rot} &gt; S^{\\ddagger}_\\mathrm{vib} \\end{equation}\\] Figure 7.4: The hierarchy of energy spacings for translational, rotational, and vibrational motion. The shaded region shows the thermally accessible states at typical temperatures. 7.6 Towards Quantitative Predictions The thermodynamic framework we have developed here provides us with a molecular perspective on the entropy of activation, \\(\\Delta S^{\\ddagger}\\). When reactants come together to form the activated complex, high-entropy molecular degrees of freedom (translation and rotation) are converted into low-entropy degrees of freedom (rotation and vibration), giving an overall negative \\(\\Delta S^{\\ddagger}\\). To make quantitative predictions about pre-exponential factors for specific reactions, we need to estimate these entropy changes numerically. Recall from Lecture 6 that the pre-exponential factor is: \\[\\begin{equation} A = \\frac{k^{\\ddagger}}{c^\\circ} \\exp\\left(\\frac{\\Delta S^{\\ddagger}}{R}\\right) \\end{equation}\\] In Lecture 8, we will estimate both components—the entropy change \\(\\Delta S^{\\ddagger}\\) and the rate constant \\(k^{\\ddagger}\\)—to calculate pre-exponential factors for real reactions. The \\(3N\\) molecular degrees of freedom are constructed as orthogonal linear combinations of the \\(3N\\) atomic degrees of freedom that are consistent with molecular symmetry. The details of this transformation from atomic to molecular degrees of freedom are part of the S2 Group Theory course↩︎ "],["lecture8.html", "Lecture 8 Estimating Pre-exponential Factors 8.1 From Molecular Freedom to Reaction Rates 8.2 The Reaction Coordinate 8.3 The Rate of Barrier Crossing 8.4 Mathematical Development 8.5 Analysis of Molecular Systems 8.6 Applications and Predictive Power 8.7 Connection to Collision Theory 8.8 Unimolecular Reactions 8.9 Limitations in Pre-exponential Factor Estimation", " Lecture 8 Estimating Pre-exponential Factors 8.1 From Molecular Freedom to Reaction Rates In Lecture 7, we examined how molecular degrees of freedom change when forming the activated complex, and how these changes determine the entropy of activation, \\(\\Delta S^\\ddagger\\). We saw that forming the activated complex typically transforms high-entropy translational and rotational degrees of freedom into more constrained rotational and vibrational modes. Let us now develop this molecular-level picture into a quantitative framework for predicting reaction rates. 8.2 The Reaction Coordinate To understand how molecular motion leads to reaction, we must look more carefully at what the reaction coordinate means. Consider a simple atom-transfer reaction A–B + C \\(\\to\\) A + B–C. We can describe the relative positions of these three atoms using two coordinates: the A–B distance (\\(r_\\mathrm{AB}\\)) and the B–C distance (\\(r_\\mathrm{BC}\\)). At the start of the reaction: \\(r_\\mathrm{AB}\\) is small (strong A–B bond) \\(r_\\mathrm{BC}\\) is large (C far from AB) At the end of the reaction: \\(r_\\mathrm{AB}\\) is large (A separated from BC) \\(r_\\mathrm{BC}\\) is small (strong B–C bond) The reaction coordinate traces the lowest-energy path between reactants and products on this two-dimensional potential energy surface. This path must cross a “dividing surface” that separates reactant-like and product-like geometries. The transition state corresponds to the lowest-energy point on this dividing surface, where typically \\(r_\\mathrm{AB}\\) ≈ \\(r_\\mathrm{BC}\\). Figure 8.1: The reaction coordinate for a bimolecular exchange reaction A + BC → AB + C. Left: The two key bond distances that define the reaction coordinate. Right: The potential energy surface as a function of \\(r_{\\mathrm{AB}}\\) and \\(r_{\\mathrm{BC}}\\). The reaction coordinate (pink line) follows the minimum energy pathway from reactants (top-left) through the transition state (saddle point) to products (bottom right). 8.3 The Rate of Barrier Crossing To describe how fast activated complexes convert to products (\\(k^\\ddagger\\)), we need to think carefully about what happens at the transition state. Consider our simple atom-transfer reaction A–B + C \\(\\to\\) A + B–C. At the transition state, we have an activated complex [A\\(\\cdots\\)B\\(\\cdots\\)C]\\(^\\ddagger\\). What happens if we move a small distance along the reaction coordinate? If we move towards reactants, \\(r_\\mathrm{AB}\\) gets smaller and \\(r_\\mathrm{BC}\\) gets larger. If we move towards products, \\(r_\\mathrm{AB}\\) gets larger and \\(r_\\mathrm{BC}\\) gets smaller. This motion through the transition state looks like an asymmetric stretch of our activated complex. By modeling this as a loose molecular vibration, we can derive the expression: \\[k^\\ddagger = \\frac{k_\\mathrm{B}T}{h}\\] where \\(k_\\mathrm{B}\\) is Boltzmann’s constant, \\(h\\) is Planck’s constant, and \\(T\\) is temperature.4 Because this expression accounts for motion along the reaction coordinate, we must take care when counting vibrational modes in the activated complex: we count only \\(3N-7\\) vibrational modes for a non-linear activated complex (one fewer than the usual \\(3N-6\\)), as the reaction coordinate “vibration” is already included in the \\(k^\\ddagger\\) term. Figure 8.2: Motion across the transition state for the reaction A + BC $ o$ AB + C. Left: The molecular configuration at the transition state represents an intermediate geometry between reactants and products. Right: The transition state sits at a saddle point on the potential energy surface. Motion along the reaction coordinate (pink line) corresponds to vibration-like motion through the transition state, with frequency \\(\\nu^\\ddagger = k_\\mathrm{B}T/h\\). 8.4 Mathematical Development The complete transition state theory rate equation can be written as: \\[\\nu = \\frac{k^{\\ddagger}}{c^\\circ}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}[\\mathrm{A}][\\mathrm{B}]\\] Comparison with the Arrhenius equation: \\[\\nu = A\\mathrm{e}^{-E_\\mathrm{a}/RT}[\\mathrm{A}][\\mathrm{B}]\\] reveals that the pre-exponential factor corresponds to: \\[A \\approx \\frac{k^{\\ddagger}}{c^\\circ}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\] By separating the entropy of activation into contributions from different types of molecular motion, we arrive at the complete transition state theory expression: \\[A = \\frac{k_\\mathrm{B}T}{hc^\\circ}\\mathrm{e}^{\\Delta S^{\\ddagger}_\\mathrm{trans}/R}\\mathrm{e}^{\\Delta S^{\\ddagger}_\\mathrm{rot}/R}\\mathrm{e}^{\\Delta S^{\\ddagger,(n-1)}_\\mathrm{vib}/R}\\] where the superscript \\((n-1)\\) on the vibrational entropy term indicates that we consider one fewer vibrational mode than might be expected, since motion along the reaction coordinate is already accounted for in the frequency prefactor \\(\\frac{k_\\mathrm{B}T}{h}\\). This expression is particularly powerful because it allows us to make quantitative predictions of the Arrhenius pre-exponential factor if we can evaluate (or estimate) the changes in translational, rotational, and vibrational entropy when forming the activated complex. For gas-phase reactions, these contributions can be estimated using characteristic values: Translational motion: \\(S^{\\ddagger}_\\mathrm{trans} \\approx 195~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) Rotational modes: \\(S^{\\ddagger}_\\mathrm{rot} \\approx 20~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) Vibrational modes: \\(S^{\\ddagger}_\\mathrm{vib} \\approx 5~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) 8.5 Analysis of Molecular Systems 8.5.1 Atomic Reactions The simplest case to analyse is a reaction between two atoms, A + B. Initially, the system possesses: Three translational degrees of freedom for atom A Three translational degrees of freedom for atom B No rotational or vibrational modes When these atoms combine to form the activated complex [A\\(\\ldots\\)B]\\(^\\ddagger\\), this transforms into: Three translational degrees of freedom (describing motion of the complex as a whole) Two rotational degrees of freedom (the complex can rotate about two axes) One vibrational degree of freedom (corresponding to motion through the transition state) From these changes in molecular freedom, we can calculate the entropy changes systematically. For translational motion, we lose three degrees of freedom when forming the complex, giving: \\[\\Delta S^\\ddagger_\\mathrm{trans} = -3 \\times 195 = -585~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] The activated complex gains two rotational degrees of freedom: \\[\\Delta S^\\ddagger_\\mathrm{rot} = +2 \\times 20 = +40~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] The vibration through the transition state is already accounted for in our \\(k^\\ddagger\\) term, so: \\[\\Delta S^\\ddagger_\\mathrm{vib} = 0 \\times 5 = 0~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] Figure 8.3: Systematic accounting of degrees of freedom changes for the reaction between two atoms. The table format provides a template for organizing similar analyses: count initial degrees of freedom for each reactant, count final degrees of freedom in the activated complex, then calculate the change (Δ) for each type of motion. With these entropy changes calculated, we can now determine the pre-exponential factor: \\[A = 10^{13} \\times \\mathrm{e}^{-3 \\times 195/8.314} \\times \\mathrm{e}^{2 \\times 20/8.314} \\times \\mathrm{e}^{0 \\times 5/8.314} \\times (N_\\mathrm{A} \\times 10^3)~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] \\[= 2 \\times 10^{11}~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] The factor of \\(N_\\mathrm{A}\\) (Avogadro’s number) converts from a per-molecule basis to a per-mole basis, since our rate constant needs to work with concentrations in mol dm\\(^{-3}\\). The factor of \\(10^3\\) converts volumes from m\\(^3\\) to dm\\(^3\\), ensuring our final rate constant has the correct units of dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\). 8.5.2 Polyatomic Systems For a reaction between a diatomic molecule and a four-atom molecule, we must account for additional molecular freedom in both reactants and the activated complex. Let us examine the initial degrees of freedom systematically. For the diatomic molecule (\\(N = 2\\)), being linear, we have: Three translational modes (motion through space) Two rotational modes (rotation about axes perpendicular to the bond) One vibrational mode (\\(3N - 5 = 1\\) for a linear molecule) The four-atom molecule (\\(N = 4\\)), being non-linear, possesses: Three translational modes Three rotational modes Six vibrational modes (\\(3N - 6 = 6\\) for a non-linear molecule) When these molecules combine, they form a six-atom activated complex (\\(N = 6\\)) with: Three translational modes Three rotational modes (non-linear complex) Eleven vibrational modes (\\(3N - 7\\) for a non-linear activated complex, as one vibrational mode corresponds to motion along the reaction coordinate) From these molecular properties, we can determine the entropy changes systematically. For translational motion: Initially: six independent translational modes (three per molecule) Finally: three translational modes in the complex Net loss: three translational degrees of freedom \\[\\Delta S^\\ddagger_\\mathrm{trans} = -3 \\times 195 = -585~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] For rotational motion: Initially: five rotational modes (two from diatomic + three from four-atom molecule) Finally: three rotational modes in the complex Net loss: two rotational degrees of freedom \\[\\Delta S^\\ddagger_\\mathrm{rot} = -2 \\times 20 = -40~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] For vibrational motion: Initially: seven vibrational modes (one from diatomic + six from four-atom molecule) Finally: eleven vibrational modes in the complex Net gain: four vibrational modes \\[\\Delta S^\\ddagger_\\mathrm{vib} = +4 \\times 5 = +20~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] Figure 8.4: Degree of freedom accounting for a reaction between a diatomic molecule (N = 2) and a four-atom molecule (N = 4) forming a six-atom activated complex (N = 6). The activated complex has 12 vibrational modes (3N-6 for a non-linear molecule), but when calculating the pre-exponential factor, we use only 11 modes in the entropy expression because one vibrational mode—motion along the reaction coordinate—is already included in the k\\(^\\ddagger\\) term. With these entropy changes determined, we can calculate the pre-exponential factor: \\[A = 10^{13} \\times \\mathrm{e}^{-3 \\times 195/8.314} \\times \\mathrm{e}^{-2 \\times 20/8.314} \\times \\mathrm{e}^{4 \\times 5/8.314} \\times (N_\\mathrm{A} \\times 10^3)~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] \\[= 1 \\times 10^8~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] As in our atomic example, the factor of \\(N_\\mathrm{A}\\) converts to a per-mole basis, while the factor of \\(10^3\\) handles the conversion from m\\(^3\\) to dm\\(^3\\) units. This more complex example reveals a key feature of molecular reactions: as molecular complexity increases, we typically observe larger decreases in molecular freedom when forming the activated complex. This systematically leads to more negative values of \\(\\Delta S^\\ddagger\\) and correspondingly smaller pre-exponential factors. 8.6 Applications and Predictive Power Despite these limitations, our molecular freedom approach successfully explains systematic trends in experimental pre-exponential factors. Consider these representative reactions: \\[\\mathrm{Br}^\\bullet + \\mathrm{H}_2 \\longrightarrow \\mathrm{HBr} + \\mathrm{H}^\\bullet \\qquad A = 3 \\times 10^{10}~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] \\[\\mathrm{CD}_3^\\bullet + \\mathrm{H}_2 \\longrightarrow \\mathrm{CD}_3\\mathrm{H} + \\mathrm{H}^\\bullet \\qquad A = 3 \\times 10^8~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] \\[\\text{Diels-Alder cycloaddition} \\qquad A = 1 \\times 10^7~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] The systematic decrease in pre-exponential factors reflects three key features: Increasing molecular complexity in the reactants Greater loss of molecular freedom in forming the activated complex Increasingly negative values of \\(\\Delta S^\\ddagger_\\mathrm{rot+vib}\\): +15, -20, and -35 J K\\(^{-1}\\) mol\\(^{-1}\\) respectively Our estimation method correctly predicts both the magnitude and ordering of these pre-exponential factors, giving values of \\(4 \\times 10^9\\), \\(1 \\times 10^8\\), and \\(2 \\times 10^7~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\) respectively. Figure 8.5: Comparison of experimental and estimated pre-exponential factors for representative bimolecular reactions. The systematic decrease in pre-exponential factors reflects increasing molecular complexity and greater loss of molecular freedom when forming the activated complex. The estimated entropy changes (\\(\\Delta S^\\ddagger_\\mathrm{rot+vib}\\)) become increasingly negative, leading to correspondingly smaller pre-exponential factors. Our simple estimation method successfully predicts both the magnitude and ordering of experimental values, with agreement typically within an order of magnitude. 8.7 Connection to Collision Theory This molecular freedom framework finally provides a quantitative explanation for an observation we made in Lecture 5: collision theory’s empirical steric factor \\(P\\) is systematically less than unity for reactions between complex molecules, and decreases as molecular complexity increases. We can now understand why. The steric factor \\(P\\) in collision theory appears as an empirical correction to account for the requirement that molecules must collide with appropriate orientation and alignment. From our transition state theory perspective, these geometric constraints manifest as losses of molecular freedom when forming the activated complex. Reactions between more complex molecules lose more translational and rotational freedom—and may also experience constraints on internal rotations—leading to increasingly negative values of \\(\\Delta S^{\\ddagger}\\) and correspondingly smaller pre-exponential factors. The systematic trends we observe in Figure 8.5 demonstrate this principle: as we move from simple radical reactions (\\(\\Delta S^{\\ddagger}_\\mathrm{rot+vib} = +15~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\)) to more complex cycloadditions (\\(\\Delta S^{\\ddagger}_\\mathrm{rot+vib} = -35~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\)), the pre-exponential factors decrease by over three orders of magnitude. What collision theory attributed to “steric hindrance” is revealed by transition state theory to be the thermodynamic consequence of transforming high-entropy molecular degrees of freedom into low-entropy modes at the transition state. 8.8 Unimolecular Reactions While our analysis thus far has focused on bimolecular reactions, we can apply the same molecular freedom approach to unimolecular processes of the form: \\[\\begin{equation} \\mathrm{A} \\rightleftharpoons \\mathrm{C}^{\\ddagger} \\longrightarrow \\mathrm{P} \\end{equation}\\] Consider first a single atom or simple diatomic molecule. For a single atom, both the reactant and activated complex possess three translational degrees of freedom but no rotational or vibrational modes. A linear diatomic molecule has two rotational degrees of freedom and one vibrational mode, in addition to its translational motion. In either case, our simple counting approach predicts no net change in molecular freedom when forming the activated complex: both reactant and activated complex have the same number of translational, rotational, and vibrational degrees of freedom. This leads to \\(\\Delta S^{\\ddagger} = 0\\) and a predicted pre-exponential factor of:5 \\[\\begin{equation} A = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}= \\frac{k_\\mathrm{B}T}{h} \\approx 10^{13}~\\mathrm{s}^{-1} \\end{equation}\\] However, experimental measurements reveal substantial variations in pre-exponential factors between different unimolecular reactions. These variations arise from changes in internal molecular freedom when forming the activated complex, as illustrated by two contrasting examples. 8.8.1 Ethane Decomposition The thermal decomposition of ethane proceeds via C–C bond cleavage: \\[\\begin{equation} \\mathrm{C}_2\\mathrm{H}_6 \\longrightarrow 2\\mathrm{CH}_3^\\bullet \\end{equation}\\] The experimental pre-exponential factor is \\(A = 2 \\times 10^{16}~\\mathrm{s}^{-1}\\), corresponding to \\(\\Delta S^{\\ddagger} = +63~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\). This large positive entropy of activation arises because forming the transition state weakens the C–C bond, making the activated complex “looser” than the reactant molecule. The weakened C–C bond allows freer internal rotation, while the CH3 groups can undergo enhanced rocking motions. These additional motions correspond to looser, lower-frequency vibrational modes that increase the overall molecular freedom. 8.8.2 The Cope Rearrangement A contrasting example is provided by the Cope rearrangement: \\[\\begin{equation} \\mathrm{CD}_3\\mathrm{H}-\\mathrm{CH}=\\mathrm{CH}-\\mathrm{CH}=\\mathrm{CH}_2 \\longrightarrow \\mathrm{products} \\end{equation}\\] Here, the experimental pre-exponential factor is \\(A = 4 \\times 10^{10}~\\mathrm{s}^{-1}\\), corresponding to \\(\\Delta S^{\\ddagger} = -46~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\). This negative entropy of activation reflects increased constraints in the transition state. While the reactant has three C–C single bonds allowing relatively free internal rotation, the transition state forms a cyclic, delocalised six-membered ring. This ring structure requires a specific planar geometry, constrained by orbital overlap requirements, resulting in the loss of three internal rotational degrees of freedom. The magnitude of \\(\\Delta S^{\\ddagger}\\) suggests each restricted internal rotation contributes approximately \\(-15~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) to the entropy change. This provides a useful estimate for analysing other reactions where internal rotations become restricted in the transition state. These examples reveal how changes in internal molecular freedom can produce significant deviations from our predicted \\(A \\approx 10^{13}~\\mathrm{s}^{-1}\\). While collision theory cannot describe unimolecular reactions, our molecular freedom approach successfully explains systematic variations in pre-exponential factors when we consider how forming the activated complex affects internal molecular motion. This analysis provides both qualitative insight into reaction mechanisms and a framework for making quantitative predictions about reaction rates. 8.9 Limitations in Pre-exponential Factor Estimation While our molecular freedom approach successfully predicts systematic trends in reaction rates, several important approximations underpin these calculations. Understanding these limitations helps us recognise both the power and constraints of our theoretical framework. 8.9.1 Statistical Entropy Approximations Our calculations employ characteristic entropy values for different types of molecular motion: Translational motion: 195 J K\\(^{-1}\\) mol\\(^{-1}\\) Rotational modes: 20 J K\\(^{-1}\\) mol\\(^{-1}\\) Vibrational modes: 5 J K\\(^{-1}\\) mol\\(^{-1}\\) These values represent statistical averages derived from typical molecular behaviour. For more precise predictions, we require detailed quantum mechanical calculations of molecular energy levels, which can determine specific values for \\(S^\\ddagger_\\mathrm{dof}\\) based on the actual energy spacing between quantum states. While such calculations provide greater accuracy, our simpler approach using characteristic values remains valuable for understanding trends in reactivity. 8.9.2 Effects of Molecular Symmetry Molecular symmetry introduces additional complexity beyond simple counting of degrees of freedom. Consider these parallel reactions: \\[\\mathrm{CH}_4 + \\mathrm{Br}^\\bullet \\longrightarrow \\mathrm{HBr} + \\mathrm{CH}_3^\\bullet\\] \\[\\mathrm{CD}_3\\mathrm{H} + \\mathrm{Br}^\\bullet \\longrightarrow \\mathrm{HBr} + \\mathrm{CD}_3^\\bullet\\] Our previous analysis, based purely on counting molecular degrees of freedom, predicts identical pre-exponential factors for both reactions. However, experimental measurements reveal that the CH4 reaction proceeds approximately four times faster than the CD3H reaction. This difference arises from molecular symmetry. In CH4, all four hydrogen atoms are equivalent—the bromine radical can abstract any hydrogen to form the same product. In CD3H, only one hydrogen is available for abstraction. We account for this effect by introducing a statistical factor, \\(l\\), into our transition state theory expression: \\[A = l\\frac{k_\\mathrm{B}T}{hc^\\circ}\\mathrm{e}^{\\Delta S^\\ddagger/RT}\\] Here \\(l\\) represents the number of different chemically plausible products that can be formed when identical atoms in the reactant molecules are labeled. For our example reactions: CH4 reaction: \\(l = 4\\) (four equivalent hydrogens) CD3H reaction: \\(l = 1\\) (single abstractable hydrogen) Figure 8.6: Molecular symmetry affects pre-exponential factors through configurational entropy. Top: In CH\\(_4\\), all four hydrogen atoms (blue) are equivalent, so the bromine radical can abstract any hydrogen to form the same product, giving a statistical factor of \\(l = 4\\). Bottom: In CD\\(_3\\)H, only one hydrogen (blue) is available for abstraction whilst the three deuterium atoms (orange) are not, giving \\(l = 1\\). This symmetry difference results in the CH\\(_4\\) reaction being approximately four times faster than the CD\\(_3\\)H reaction, even though simple degree-of-freedom counting predicts identical rates. 8.9.3 Internal Molecular Motion The treatment of internal molecular motions reveals additional subtlety in our theoretical framework. Consider the ethane molecule (C2H6), which exhibits two distinct types of motion around its C–C bond: C–C stretching vibration: Involves direct compression and extension of the C–C bond Requires significant energy Shows widely spaced quantum energy levels Makes small contributions to vibrational entropy C–C torsional motion: Involves rotation of CH3 groups about the C–C axis Requires much less energy Shows more closely spaced energy levels Makes larger contributions to entropy Figure 8.7: Comparison of energy level spacings for different types of molecular motion in ethane-like molecules. Left: A normal C–C stretching vibration involves compression and extension of the bond, requiring significant energy. The resulting widely spaced quantum energy levels (gray) mean only a few low-lying states (green) are thermally accessible at room temperature, giving low entropy. Right: Internal rotation of CH\\(_3\\) groups about the C–C axis requires much less energy. The resulting closely spaced energy levels mean many states are thermally accessible, giving substantially higher entropy than a normal vibration. When such molecules form activated complexes, two scenarios commonly arise: Restricted internal rotation: Occurs when specific molecular alignments are required Reduces freedom of internal motion Produces more negative \\(\\Delta S^\\ddagger\\) values Leads to lower pre-exponential factors than predicted by simple counting Enhanced internal rotation: Occurs when bond lengthening makes rotation easier Increases freedom of internal motion Produces less negative \\(\\Delta S^\\ddagger\\) values Leads to higher pre-exponential factors than predicted Figure 8.8: The effect of transition state formation on internal rotation determines the sign of entropy contributions. Left: When the transition state requires specific molecular alignment or constrains rotation (indicated by the red barrier), internal rotational freedom is reduced. This produces additional negative contributions to \\(\\Delta S^\\ddagger\\), leading to lower pre-exponential factors than predicted by simple degree-of-freedom counting. Right: When transition state formation weakens a bond, internal rotation becomes freer. The enhanced rotational freedom produces positive contributions to \\(\\Delta S^\\ddagger\\), leading to higher pre-exponential factors. The Diels-Alder cycloaddition provides particularly valuable insight into the limitations of our simple counting approach. Our predictions typically overestimate the experimental pre-exponential factors for these reactions because the transition state requires precise alignment of the diene and dienophile components. This geometric constraint introduces additional restrictions on molecular motion beyond those captured by simple counting of degrees of freedom, leading to more negative \\(\\Delta S^\\ddagger\\) values than predicted. Figure 8.9: The Diels-Alder cycloaddition transition state illustrates why geometric constraints can produce more negative \\(\\Delta S^\\ddagger\\) values than predicted by simple degree-of-freedom counting. Left: The diene reactant possesses internal rotational freedom (rotation arrow). Right: The transition state requires formation of a planar, cyclic six-membered ring structure (shown in red dashes). This geometric constraint restricts the internal rotational freedom present in the reactants, producing additional negative entropy contributions beyond those from simple translational and rotational degree-of-freedom changes. This explains why our estimated pre-exponential factor (2 × 10\\(^7\\) dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\)) slightly overestimates the experimental value (1 × 10\\(^7\\) dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\)). The derivation of this expression for \\(k^\\ddagger\\) requires a statistical mechanical treatment of transition state theory. You will cover statistical mechanics in the third year of your course. A brief overview of the statistical formulation of transition state theory is give in Appendix C.↩︎ Note the absence of the standard concentration factor \\(c^\\circ\\) in this expression, unlike the bimolecular case where \\(A = (k_\\mathrm{B}T/hc^\\circ)\\mathrm{e}^{\\Delta S^\\ddagger/R}\\). For unimolecular reactions, the rate constant has units of s\\(^{-1}\\) rather than dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\), so no concentration term is needed for dimensional consistency.↩︎ "],["lecture9.html", "Lecture 9 Applications of Transition State Theory 9.1 The Eyring Plot 9.2 Effect of Pressure on Rate Coefficients 9.3 Kinetic Isotope Effects", " Lecture 9 Applications of Transition State Theory Throughout our development of transition state theory, we’ve focused on understanding how molecular properties govern reaction rates. While this theoretical framework is elegant, its real power emerges when we link it to experimental observations. Here we examine three key applications: using temperature-dependent kinetic data to determine activation parameters, understanding pressure effects on reaction rates, and interpreting kinetic isotope effects. 9.1 The Eyring Plot The Eyring equation relates reaction rate constants to the activation parameters \\(\\Delta H^{\\ddagger}\\) and \\(\\Delta S^{\\ddagger}\\): \\[k = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}\\] By fitting this equation to experimental rate constant data at different temperatures, it is possible to estimate these activation parameters. The conventional approach to fitting the Eyring equation to experimental \\(k(T)\\) data is to reformulate it as a linear equation. First, we divide both sides by \\(T\\): \\[\\frac{k}{T} = \\frac{k_\\mathrm{B}}{h}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}\\] Taking the natural logarithm gives: \\[\\ln\\left(\\frac{k}{T}\\right) = \\ln\\left(\\frac{k_\\mathrm{B}}{h}\\right) + \\frac{\\Delta S^{\\ddagger}}{R} - \\frac{\\Delta H^{\\ddagger}}{RT}\\] which has the form \\[y = mx + c\\]. Therefore, the Eyring equation predicts that a plot of \\(\\ln(k/T)\\) versus \\(1/T\\) should be approximately linear, and that the model parameters \\(\\Delta H^\\ddagger\\) and \\(\\Delta S^\\ddagger\\) can be estimated from the slope and intercept, respectively,6 via Slope = \\(-\\Delta H^{\\ddagger}/R\\) Intercept = \\(\\ln(k_\\mathrm{B}/h) + \\Delta S^{\\ddagger}/R\\) 9.2 Effect of Pressure on Rate Coefficients For reactions in solution or the solid state, pressure can significantly affect reaction rates. We can understand this through the volume change that occurs when reactants combine to form the activated complex: \\[\\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^{\\ddagger} \\longrightarrow \\mathrm{P}\\] The volume of activation \\(\\Delta V^{\\ddagger}\\) is defined as the difference in partial molar volume between the activated complex and the reactants. Where \\(\\Delta V^{\\ddagger}\\) is negative, the activated complex occupies less volume than the reactants, and increasing pressure shifts the pre-equilibrium towards the activated complex. Since the overall reaction rate is proportional to \\([\\mathrm{C}^{\\ddagger}]\\): \\[\\nu = k^{\\ddagger}[\\mathrm{C}^{\\ddagger}]\\] this leads to an increase in the reaction rate. We can develop this idea quantitatively by considering how pressure affects the Gibbs energy of activation. The enthalpy of activation depends on pressure through: \\[\\Delta H^{\\ddagger} = \\Delta U^{\\ddagger} + p\\Delta V^{\\ddagger}\\] Substituting this into our equation for the rate constant: \\[\\begin{equation} \\ln k = \\ln \\frac{k_\\mathrm{B}T}{h} + \\frac{\\Delta S^{\\ddagger}}{R} - \\frac{\\Delta U^{\\ddagger} + p\\Delta V^{\\ddagger}}{RT} \\tag{9.1} \\end{equation}\\] Differentiating with respect to pressure at constant temperature: \\[\\left(\\frac{\\partial \\ln k}{\\partial p}\\right)_T = -\\frac{\\Delta V^{\\ddagger}}{RT}\\] giving us the prediction that plotting \\(\\ln k\\) versus pressure should be approximately linear with slope \\(-\\Delta V^{\\ddagger}/RT\\). The volume of activation can therefore be determined from experimental measurements of how reaction rates vary with pressure:7 \\[\\Delta V^{\\ddagger} = -RT\\left(\\frac{\\partial \\ln k}{\\partial p}\\right)_T\\] As an example, consider the decomposition of dibutyl peroxide: \\[[(\\mathrm{CH}_3)_3\\mathrm{CCO}_2]_2 \\longrightarrow 2(\\mathrm{CH}_3)_3\\mathrm{CO}^\\bullet\\] Experimental data shows \\(\\Delta V^{\\ddagger} = (5.24 \\pm 0.24) \\times 10^{-6}~\\mathrm{m^3~mol^{-1}}\\). This positive volume of activation tells us that in the transition state the O–O bond has started to break, requiring a larger volume than the initial reactant. 9.3 Kinetic Isotope Effects Many reactions proceed more slowly when hydrogen is replaced by deuterium. Classical theories cannot explain this kinetic isotope effect, as H and D have identical potential energy surfaces. Understanding this difference in reaction rates requires consideration of quantum mechanical zero-point vibrational energy. 9.3.1 Origin of the Kinetic Isotope Effect For a simple harmonic oscillator, the allowed energy levels are given by: \\[\\begin{equation} E_v = \\left(v + \\frac{1}{2}\\right)\\sqrt{\\frac{k}{\\mu}} \\end{equation}\\] where \\(v\\) is the vibrational quantum number, \\(k\\) is the force constant, and \\(\\mu\\) is the reduced mass: \\[\\begin{equation} \\mu = \\frac{m_1m_2}{m_1 + m_2} \\end{equation}\\] For an X–H bond (where X is much heavier than H), \\(\\mu \\approx m_\\mathrm{H}\\). The zero-point energy is then: \\[\\begin{equation} E_\\mathrm{ZPE} \\approx \\frac{1}{2}\\sqrt{\\frac{k}{m_\\mathrm{H}}} \\end{equation}\\] Substituting H with D approximately doubles the reduced mass, giving: \\[\\begin{equation} \\frac{E_\\mathrm{ZPE}(\\mathrm{D})}{E_\\mathrm{ZPE}(\\mathrm{H})} \\approx \\frac{1}{\\sqrt{2}} \\end{equation}\\] This difference in zero-point energy means that C–D bonds start from a lower energy than C–H bonds. If the reaction involves breaking this bond, the activation energy will be higher for the deuterated compound, leading to a slower reaction rate: \\[\\begin{equation} \\frac{k_\\mathrm{H}}{k_\\mathrm{D}} = \\mathrm{e}^{(E_\\mathrm{ZPE}(\\mathrm{H})-E_\\mathrm{ZPE}(\\mathrm{D}))/RT} \\end{equation}\\] For a typical C–H stretching mode: - \\(E_\\mathrm{ZPE}(\\mathrm{C-H}) = 18.0~\\mathrm{kJ~mol^{-1}}\\) - \\(E_\\mathrm{ZPE}(\\mathrm{C-D}) = 13.2~\\mathrm{kJ~mol^{-1}}\\) At room temperature this predicts: \\[\\begin{equation} \\frac{k_\\mathrm{H}}{k_\\mathrm{D}} = \\mathrm{e}^{(18.0-13.2)\\times 10^3/(8.314 \\times 298)} = 6.9 \\end{equation}\\] 9.3.2 Using Kinetic Isotope Effects to Probe Reaction Mechanisms The magnitude of the kinetic isotope effect depends on the extent to which the C–H/D bond is broken in the transition state. Three scenarios are common: When the bond is completely broken in the transition state, we observe the full isotope effect: \\(k_\\mathrm{H}/k_\\mathrm{D} \\approx 7\\) When the bond is partially broken, we find intermediate values: \\(1 &lt; k_\\mathrm{H}/k_\\mathrm{D} &lt; 7\\) When the bond is unaffected, there is no significant isotope effect: \\(k_\\mathrm{H}/k_\\mathrm{D} \\approx 1\\) These patterns make kinetic isotope effects a valuable probe of reaction mechanisms. Consider these contrasting examples: \\[\\begin{equation} \\mathrm{Ph-CH(D)-CH_2Br + EtO^-} \\longrightarrow \\mathrm{products} \\quad k_\\mathrm{H}/k_\\mathrm{D} = 7.8 \\end{equation}\\] \\[\\begin{equation} \\mathrm{Ph-CH_2-CD_2Br + EtO^-} \\longrightarrow \\mathrm{products} \\quad k_\\mathrm{H}/k_\\mathrm{D} = 1.09 \\end{equation}\\] In the first reaction, the large isotope effect (\\(k_\\mathrm{H}/k_\\mathrm{D} = 7.8\\)) indicates that the C–H bond is almost completely broken in the transition state. The negligible isotope effect in the second reaction (\\(k_\\mathrm{H}/k_\\mathrm{D} = 1.09\\)) tells us the C–H bonds are spectators—they remain essentially unchanged as the reaction proceeds. This information helps us understand the detailed molecular changes occurring in the transition state. If the errors in our experimental data, \\(k(T)\\), are normally distributed, then standard least-squares fitting of the linear form of the Eyring equation gives biased estimates for \\(\\Delta H^\\ddagger\\) and \\(\\Delta S^\\ddagger\\) — see, e.g., McCluskey J. Chem. Educ. 2023, 100, 11, 4174–4176. Unbiased estimates of \\(\\Delta H^\\ddagger\\) and \\(\\Delta S^\\ddagger\\) can be obtained by instead fitting the non-linear form of the Eyring equation, using a computer. Because of the exponential dependence on \\(\\Delta H^\\ddagger\\) and \\(\\Delta S^\\ddagger\\), direct fitting of the non-linear Eyring equation can be numerically unstable. This can be ameliorated by fitting the linear form of the equation first, to obtain approximate (biased) estimates of the activation parameters, and then using these as starting guesses to fit the non-linear form.↩︎ Again, least-squares fitting of (9.1) gives a biased estimate of \\(\\Delta V^\\ddagger\\), while direct fitting of the non-linear equation \\(k = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^\\frac{\\Delta S^\\ddagger}{R}\\mathrm{e}^\\frac{-\\Delta U^\\ddagger}{RT}\\mathrm{e}^\\frac{p\\Delta V^\\ddagger}{RT}\\) gives an unbiased estimate.↩︎ "],["integrating-factor.html", "A Integrating Factor Method for Consecutive Reactions", " A Integrating Factor Method for Consecutive Reactions In analyzing consecutive reactions, we encounter the following differential equation for the intermediate species B: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t} - k_2[\\mathrm{B}]\\] This is a first-order linear differential equation of the form: \\[\\frac{\\mathrm{d}y}{\\mathrm{d}t} + P(t)y = Q(t)\\] where \\(y = [\\mathrm{B}]\\), \\(P(t) = k_2\\), and \\(Q(t) = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t}\\). The integrating factor method involves multiplying both sides by \\(\\mathrm{e}^{\\int P(t)\\mathrm{d}t}\\). Here: \\[\\int P(t)\\mathrm{d}t = \\int k_2\\mathrm{d}t = k_2t\\] So our integrating factor is \\(\\mathrm{e}^{k_2t}\\). Multiplying both sides of our original equation: \\[\\mathrm{e}^{k_2t}\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} + k_2[\\mathrm{B}]\\mathrm{e}^{k_2t} = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t}\\mathrm{e}^{k_2t}\\] The left side is now the derivative of \\([\\mathrm{B}]\\mathrm{e}^{k_2t}\\): \\[\\frac{\\mathrm{d}}{\\mathrm{d}t}([\\mathrm{B}]\\mathrm{e}^{k_2t}) = k_1[\\mathrm{A}]_0\\mathrm{e}^{(k_2-k_1)t}\\] Integrating both sides: \\[[\\mathrm{B}]\\mathrm{e}^{k_2t} = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}\\mathrm{e}^{(k_2-k_1)t} + C\\] Solving for [B]: \\[[\\mathrm{B}] = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}\\mathrm{e}^{-k_1t} + C\\mathrm{e}^{-k_2t}\\] Using the initial condition [B]₀ = 0 at t = 0: \\[0 = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1} + C\\] Therefore: \\[C = -\\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}\\] And our final solution is: \\[[\\mathrm{B}] = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}(\\mathrm{e}^{-k_1t} - \\mathrm{e}^{-k_2t})\\] This method of solution is generally applicable to first-order linear differential equations that arise in chemical kinetics. "],["appendix-activation.html", "B The Relationship Between \\(\\Delta H^\\ddagger\\) and the \\(E_\\mathrm{a}\\) B.1 Temperature Dependence of Rate Constants B.2 Effect of Reaction Molecularity", " B The Relationship Between \\(\\Delta H^\\ddagger\\) and the \\(E_\\mathrm{a}\\) In Section 6.4, we identified a correspondence between the transition state theory rate equation and the Arrhenius equation. The enthalpy of activation \\(\\Delta H^\\ddagger\\) and the Arrhenius activation energy \\(E_\\mathrm{a}\\) play similar roles in these equations, but they are not identical quantities. Here we examine their precise relationship. B.1 Temperature Dependence of Rate Constants The Arrhenius equation defines the temperature dependence of rate constants empirically: \\[\\begin{equation} k = A\\mathrm{e}^{-E_\\mathrm{a}/RT} \\tag{5.4} \\end{equation}\\] Taking logarithms: \\[\\begin{equation} \\ln k = \\ln A - \\frac{E_\\mathrm{a}}{RT} \\tag{B.1} \\end{equation}\\] Differentiating with respect to temperature8 \\[\\begin{equation} \\frac{\\mathrm{d}\\ln k}{\\mathrm{d}T} = \\frac{E_\\mathrm{a}}{RT^2} \\tag{B.2} \\end{equation}\\] This equation can be considered a formal definition of the Arrhenius activation energy. For a bimolecular reaction, the thermodynamic form of the transition state theory rate equation is: \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{hc^\\circ}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\mathrm{e}^{-\\Delta H^\\ddagger/RT} \\tag{B.3} \\end{equation}\\] Taking logarithms: \\[\\begin{equation} \\ln k = \\ln\\left(\\frac{k_\\mathrm{B}T}{hc^\\circ}\\right) + \\frac{\\Delta S^\\ddagger}{R} - \\frac{\\Delta H^\\ddagger}{RT} \\tag{B.4} \\end{equation}\\] For an ideal gas, \\(\\frac{1}{c^\\circ} = \\frac{V}{N} = \\frac{RT}{p}\\), and we can rewrite our equation as \\[\\begin{equation} \\ln k = \\ln\\left(\\frac{k_\\mathrm{B}T}{h}\\right) + \\ln\\left(\\frac{RT}{p}\\right) + \\frac{\\Delta S^\\ddagger}{R} - \\frac{\\Delta H^\\ddagger}{RT} \\tag{B.5} \\end{equation}\\] Differentiating with respect to temperature gives,9 \\[\\begin{equation} \\frac{\\mathrm{d}\\ln k}{\\mathrm{d}T} = \\frac{1}{T} + \\frac{1}{T} + \\frac{\\Delta H^\\ddagger}{RT^2} \\tag{B.6} \\end{equation}\\] Comparing equations (B.2) and (B.6) we find: \\[\\begin{equation} E_\\mathrm{a} = \\Delta H^\\ddagger + 2RT \\tag{B.7} \\end{equation}\\] B.2 Effect of Reaction Molecularity The derivation above is for a bimolecular reaction. For a unimolecular reaction, the same procedure gives a different relationship between \\(E_\\mathrm{a}\\) and \\(\\Delta H^\\ddagger\\): \\[\\begin{equation} E_\\mathrm{a} = \\Delta H^\\ddagger + RT \\tag{B.8} \\end{equation}\\] The difference arises because the unimolecular TST rate equation is \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\mathrm{e}^{-\\Delta H^\\ddagger/RT} \\tag{B.9} \\end{equation}\\] with no \\(1/c^\\circ\\) term in the prefactor, and we lose the corresponding factor of \\(RT\\) when we evaluate \\(\\mathrm{d} \\ln k / \\mathrm{T}\\). Similarly, the TST rate equation for a termolecular reaction is \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h{c^\\circ}^2}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\mathrm{e}^{-\\Delta H^\\ddagger/RT} \\tag{B.10} \\end{equation}\\] and \\[\\begin{equation} E_\\mathrm{a} = \\Delta H^\\ddagger + 3RT \\tag{B.11} \\end{equation}\\] where \\(2RT\\) comes from the squared concentration factor in the rate equation. At room temperature, \\(RT \\approx 2.5\\) kJ mol\\(^{-1}\\). The difference between \\(E_\\mathrm{a}\\) and \\(\\Delta H^\\ddagger\\) therefore ranges from about 2.5 kJ mol\\(^{-1}\\) for unimolecular reactions to 7.5 kJ mol\\(^{-1}\\) for termolecular processes. While these differences are relatively small compared to typical activation energies, they become important when comparing activation parameters determined using different methods or analysing temperature-dependent kinetic data over wide temperature ranges. \\(\\frac{\\mathrm{d}}{\\mathrm{d}x}\\frac{a}{x} = -\\frac{a}{x^2}\\).↩︎ \\(\\frac{\\mathrm{d}}{\\mathrm{d}x}\\ln ax = \\frac{1}{x}\\).↩︎ "],["appendix-statistical-tst.html", "C Statistical Foundations of Transition State Theory C.1 The Boltzmann Factor and Probability Distributions C.2 Molecular Partition Functions C.3 System Partition Functions C.4 Connection to Chemical Equilibrium C.5 The Statistical Rate Equation C.6 Molecular Degrees of Freedom", " C Statistical Foundations of Transition State Theory C.1 The Boltzmann Factor and Probability Distributions Statistical mechanics connects molecular-level properties to measurable thermodynamic quantities. The foundation of this connection lies in understanding how energy and temperature determine the distribution of molecular states in thermal equilibrium. C.1.1 The Boltzmann Factor When a system is in thermal equilibrium at temperature \\(T\\), the probability of finding it in a particular microstate \\(i\\) with energy \\(E_i\\) follows a specific mathematical form: \\[P_i \\propto e^{-\\beta E_i}\\] where \\(\\beta = \\frac{1}{k_\\mathrm{B}T}\\), and \\(k_\\mathrm{B}\\) is Boltzmann’s constant. The Boltzmann factor determines the relative probabilities of molecular energy states in thermal equilibrium. At high temperatures, the exponential term becomes less sensitive to energy differences, resulting in more uniform probability distributions across energy states. As temperature decreases, the probability becomes more strongly concentrated in the lowest energy states. C.1.2 Properties of Probability Distributions The Boltzmann factor gives relative probabilities between states. To construct a complete probability distribution, we need three mathematical conditions: Non-negativity: Probabilities cannot be negative \\[P_i \\geq 0 \\quad \\text{for all } i\\] Normalization: Total probability must equal one \\[\\sum_i P_i = 1\\] Additivity: For independent events, probabilities add \\[P(i \\text{ or } j) = P_i + P_j\\] The exponential form of the Boltzmann factor ensures non-negativity and additivity. Meeting the normalization condition requires introducing an additional factor. C.1.3 The Partition Function Converting the Boltzmann factor proportionality into a proper probability distribution requires a normalization constant \\(Z\\), called the partition function: \\[P_i = \\frac{1}{Z}e^{-\\beta E_i}\\] The normalization condition determines \\(Z\\): \\[1 = \\sum_i P_i = \\sum_i \\frac{1}{Z}e^{-\\beta E_i}\\] Therefore: \\[Z = \\sum_i e^{-\\beta E_i}\\] This sum encompasses all system microstates, each weighted by its Boltzmann factor. The partition function contains the essential statistical information needed to calculate thermodynamic properties. C.1.4 Example: A Two-State System Consider a molecular system with two possible states: Ground state: \\(E_1 = 0\\) Excited state: \\(E_2 = \\epsilon\\) The partition function is: \\[Z = e^{-\\beta \\cdot 0} + e^{-\\beta \\epsilon} = 1 + e^{-\\beta \\epsilon}\\] The probability of the excited state becomes: \\[P_2 = \\frac{e^{-\\beta \\epsilon}}{1 + e^{-\\beta \\epsilon}}\\] This basic example illustrates key features that appear in transition state theory: molecules populate multiple energy states, with relative populations determined by energy differences and temperature. C.2 Molecular Partition Functions The partition function for a single molecule encompasses all possible quantum states available to that molecule. For a molecule with discrete energy levels \\(E_i\\), the molecular partition function \\(q\\) takes the form: \\[q = \\sum_i g_i e^{-\\beta E_i}\\] where \\(g_i\\) represents the degeneracy of state \\(i\\). For polyatomic molecules, the total energy can be separated into contributions from different types of molecular motion: \\[E = E_\\mathrm{trans} + E_\\mathrm{rot} + E_\\mathrm{vib} + E_\\mathrm{elec}\\] When these motions are independent, the molecular partition function factorises: \\[q = q_\\mathrm{trans}q_\\mathrm{rot}q_\\mathrm{vib}q_\\mathrm{elec}\\] C.3 System Partition Functions For a system containing \\(N\\) identical molecules, the total partition function \\(Q\\) must account for the indistinguishability of quantum particles. For a gas of non-interacting molecules: \\[Q = \\frac{q^N}{N!}\\] The factor \\(N!\\) prevents overcounting of states that differ only by exchanging identical particles. C.4 Connection to Chemical Equilibrium Consider a chemical equilibrium: \\[\\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}\\] The equilibrium constant \\(K\\) can be expressed in terms of partition functions. For an ideal gas mixture: \\[K = \\frac{Q_\\mathrm{C}}{Q_\\mathrm{A}Q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right)^{\\Delta n}\\] where \\(\\Delta n\\) represents the change in the number of gas molecules, and \\(p^{\\circ}\\) is the standard pressure. Substituting the system partition functions: \\[K = \\frac{q_\\mathrm{C}}{q_\\mathrm{A}q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right)^{\\Delta n}e^{-\\Delta E_0/k_\\mathrm{B}T}\\] where \\(\\Delta E_0\\) represents the energy difference between the ground states of products and reactants. This expression reveals how molecular properties determine equilibrium constants: The ratio of partition functions captures entropic contributions The exponential term accounts for energetic differences The pressure term ensures correct dimensionality for gas-phase reactions C.5 The Statistical Rate Equation C.5.1 Reaction Flux Through the Transition State Consider a reaction where reactants A and B combine to form products via an activated complex C\\(^\\ddagger\\): \\[\\begin{equation} \\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^\\ddagger \\longrightarrow \\mathrm{P} \\end{equation}\\] The central assumption of transition state theory is that reactants and the activated complex maintain a state of pseudo-equilibrium. This equilibrium can be expressed using partition functions: \\[\\begin{equation} \\frac{[\\mathrm{C}^\\ddagger]}{[\\mathrm{A}][\\mathrm{B}]} = \\frac{Q_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right) \\end{equation}\\] C.5.2 Motion Along the Reaction Coordinate The partition function for the activated complex, \\(Q_{\\mathrm{C}^\\ddagger}\\), requires careful consideration. One degree of freedom corresponds to motion along the reaction coordinate—the path leading from reactants to products through the transition state. This motion differs fundamentally from typical molecular vibrations because it is unbounded: once the system passes through the transition state, it proceeds to products. We therefore separate the partition function for the activated complex into two parts: \\[\\begin{equation} Q_{\\mathrm{C}^\\ddagger} = Q^\\prime_{\\mathrm{C}^\\ddagger}q_\\mathrm{rc} \\end{equation}\\] where \\(Q^\\prime_{\\mathrm{C}^\\ddagger}\\) excludes the reaction coordinate and \\(q_\\mathrm{rc}\\) represents the contribution from motion along the reaction coordinate. C.5.3 Rate of Barrier Crossing Motion along the reaction coordinate at the transition state resembles a very loose vibrational mode. Consider a harmonic oscillator with frequency \\(\\nu\\). The quantum mechanical partition function for this oscillator is: \\[\\begin{equation} q_\\mathrm{vib} = \\frac{e^{-h\\nu/2k_\\mathrm{B}T}}{1 - e^{-h\\nu/k_\\mathrm{B}T}} \\end{equation}\\] As the frequency approaches zero, corresponding to free motion along the reaction coordinate, this becomes: \\[\\begin{equation} \\lim_{\\nu \\to 0} q_\\mathrm{vib} = \\lim_{\\nu \\to 0} \\frac{e^{-h\\nu/2k_\\mathrm{B}T}}{1 - e^{-h\\nu/k_\\mathrm{B}T}} = \\frac{k_\\mathrm{B}T}{h\\nu} \\end{equation}\\] The rate constant for passage through the transition state equals this frequency multiplied by the probability of finding the system at the transition state. The frequency factor \\(\\nu\\) cancels with the \\(1/\\nu\\) from the partition function, yielding the characteristic \\(k_\\mathrm{B}T/h\\) factor in the rate equation. C.5.4 The Statistical Rate Equation Combining these results gives the fundamental equation of transition state theory: \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h}\\frac{Q^\\prime_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right)e^{-\\Delta E_0/k_\\mathrm{B}T} \\end{equation}\\] or, equivalently \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h}\\frac{1}{c^\\circ}\\frac{Q^\\prime_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}}e^{-\\Delta E_0/k_\\mathrm{B}T} \\end{equation}\\] This equation shows how molecular properties—encoded in the partition functions—determine reaction rates. The pre-exponential factor \\(\\frac{k_\\mathrm{B}T}{h}\\) emerges naturally from treating the reaction coordinate as a very loose vibration. C.6 Molecular Degrees of Freedom For a polyatomic molecule, the partition function factorises into contributions from different types of motion: \\[\\begin{equation} q = q_\\mathrm{trans}q_\\mathrm{rot}q_\\mathrm{vib} \\end{equation}\\] The entropic contribution to the rate constant depends on the ratio of partition functions: \\[\\begin{equation} \\frac{Q^\\prime_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}} = \\exp(\\Delta S^\\ddagger/R) \\end{equation}\\] Changes in molecular freedom when forming the activated complex directly affect this ratio. For each type of motion: \\[\\begin{equation} q_\\mathrm{trans} \\approx \\left(\\frac{2\\pi mk_\\mathrm{B}T}{h^2}\\right)^{3/2}V \\end{equation}\\] \\[\\begin{equation} q_\\mathrm{rot} \\approx \\frac{8\\pi^2Ik_\\mathrm{B}T}{h^2} \\end{equation}\\] \\[\\begin{equation} q_\\mathrm{vib} \\approx \\exp(-h\\nu/2k_\\mathrm{B}T) \\end{equation}\\] Taking logarithms gives characteristic entropy contributions: Translation: \\(S_\\mathrm{trans} \\approx 195~\\mathrm{J~K^{-1}~mol^{-1}}\\) Rotation: \\(S_\\mathrm{rot} \\approx 20~\\mathrm{J~K^{-1}~mol^{-1}}\\) Vibration: \\(S_\\mathrm{vib} \\approx 5~\\mathrm{J~K^{-1}~mol^{-1}}\\) For a bimolecular reaction, forming the activated complex typically: Reduces translational degrees of freedom by 3 Reduces rotational degrees of freedom Increases vibrational degrees of freedom The total entropy change can be estimated by counting these changes: \\[\\begin{equation} \\Delta S^\\ddagger \\approx n_\\mathrm{t}\\Delta S_\\mathrm{trans} + n_\\mathrm{r}\\Delta S_\\mathrm{rot} + n_\\mathrm{v}\\Delta S_\\mathrm{vib} \\end{equation}\\] where \\(n_\\mathrm{t}\\), \\(n_\\mathrm{r}\\), and \\(n_\\mathrm{v}\\) represent the changes in the number of translational, rotational, and vibrational degrees of freedom. This statistical mechanical treatment provides the theoretical basis for the thermodynamic analysis of molecular freedom developed in the main lectures. "],["the-mathematical-origin-of-the-boltzmann-distribution.html", "D The Mathematical Origin of the Boltzmann Distribution D.1 Introduction D.2 Setting Up the Problem D.3 The Most Probable Distribution D.4 Finding the Maximum D.5 The Boltzmann Distribution D.6 Physical Interpretation", " D The Mathematical Origin of the Boltzmann Distribution D.1 Introduction The Boltzmann distribution is a cornerstone of statistical mechanics, describing how molecules distribute themselves among available energy states at thermal equilibrium. While we often simply quote the result that the probability of finding a molecule in a state with energy \\(\\epsilon\\) is proportional to \\(e^{-\\epsilon/k_\\mathrm{B}T}\\), understanding where this expression comes from provides deep insight into the connection between microscopic molecular behaviour and macroscopic thermodynamic properties. D.2 Setting Up the Problem Consider a large collection of \\(N\\) molecules that can exchange energy with a heat reservoir at temperature \\(T\\). Each molecule can occupy different energy states, where: \\(\\epsilon_i\\) is the energy of state \\(i\\) \\(n_i\\) is the number of molecules in state \\(i\\) Two fundamental constraints govern how these molecules can be distributed among the available states: Conservation of molecules (constant \\(N\\)): \\[\\begin{equation} N = \\sum_i n_i \\tag{D.1} \\end{equation}\\] Conservation of energy (constant \\(E\\)): \\[\\begin{equation} E = \\sum_i n_i\\epsilon_i \\tag{D.2} \\end{equation}\\] D.3 The Most Probable Distribution Many different arrangements of molecules could satisfy these constraints. However, some arrangements are more likely than others. To find the most probable distribution, we need to: Calculate how many different ways each distribution can be achieved Find the distribution that maximises this number while satisfying our constraints D.3.1 Counting Molecular Arrangements For a given set of occupation numbers \\({n_i}\\), the number of distinct ways to arrange \\(N\\) molecules among the available states is: \\[\\begin{equation} W = \\frac{N!}{\\prod_i n_i!} \\tag{D.3} \\end{equation}\\] This is analogous to the number of ways of dealing cards into piles, where \\(n_i\\) represents the number of cards in pile \\(i\\). D.3.2 Mathematical Treatment Working with \\(W\\) directly is challenging because factorials of large numbers are involved. Taking the natural logarithm simplifies our mathematics while preserving the maximum (since \\(\\ln\\) is a monotonic function): \\[\\begin{equation} \\ln W = \\ln N! - \\sum_i \\ln n_i! \\tag{D.4} \\end{equation}\\] For large numbers, we can use Stirling’s approximation: \\(\\ln n! \\approx n\\ln n - n\\). This gives: \\[\\begin{equation} \\ln W = N\\ln N - N - \\sum_i (n_i\\ln n_i - n_i) \\tag{D.5} \\end{equation}\\] D.4 Finding the Maximum To find the most probable distribution, we need to maximize \\(\\ln W\\) subject to our constraints on total number (Eqn. (D.1)) and energy (Eqn. (D.2)). This is a constrained optimization problem perfectly suited for the method of Lagrange multipliers. We introduce two Lagrange multipliers, \\(\\alpha\\) and \\(\\beta\\), and set up the variation: \\[\\begin{equation} \\delta\\left[\\ln W - \\alpha\\left(\\sum_i n_i - N\\right) - \\beta\\left(\\sum_i n_i\\epsilon_i - E\\right)\\right] = 0 \\tag{D.6} \\end{equation}\\] Taking the variation with respect to each \\(n_i\\) gives: \\[\\begin{equation} -\\ln n_i - 1 - \\alpha - \\beta\\epsilon_i = 0 \\tag{D.7} \\end{equation}\\] Solving for \\(n_i\\): \\[\\begin{equation} n_i = e^{-1-\\alpha}e^{-\\beta\\epsilon_i} \\tag{D.8} \\end{equation}\\] D.5 The Boltzmann Distribution Dividing by \\(N\\) gives the probability of finding a molecule in state \\(i\\): \\[\\begin{equation} P_i = \\frac{n_i}{N} = \\frac{1}{Z}e^{-\\beta\\epsilon_i} \\tag{D.9} \\end{equation}\\] where \\(Z = Ne^{1+\\alpha}\\) is called the partition function and ensures that probabilities sum to 1. D.6 Physical Interpretation The Lagrange multiplier \\(\\beta\\) acquires physical meaning by considering energy exchange with the heat reservoir. Detailed analysis shows that \\(\\beta = 1/k_\\mathrm{B}T\\), where \\(k_\\mathrm{B}\\) is Boltzmann’s constant and \\(T\\) is the temperature This gives us the familiar form of the Boltzmann distribution: \\[\\begin{equation} P_i = \\frac{1}{Z}e^{-\\epsilon_i/k_\\mathrm{B}T} \\tag{D.10} \\end{equation}\\] This remarkable result shows that the probability of finding a molecule in a particular energy state depends only on: The energy of that state The temperature of the system A normalisation factor (the partition function) The exponential form emerges naturally from maximising the number of possible molecular arrangements while maintaining constant energy—we didn’t need to assume it. This mathematical derivation reveals the deep connection between molecular-level disorder and macroscopic thermodynamic properties. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
