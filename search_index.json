[["index.html", "CH22008 Lecture Notes About", " CH22008 Lecture Notes Benjamin J. Morgan 2025-11-21 About These notes accompany the 2025 CH22008 lecture course on Advanced Kinetics. "],["lecture1.html", "Lecture 1 Chemical Kinetics 1.1 Why Study Chemical Kinetics? 1.2 Reaction Rates 1.3 Simple Rate Equations 1.4 Elementary Processes 1.5 Moving Between Concentration and Rate Perspectives 1.6 Integrating Simple Rate Laws 1.7 From Mechanisms to Rate Laws 1.8 Consecutive Reactions 1.9 The Steady-State Approximation", " Lecture 1 Chemical Kinetics 1.1 Why Study Chemical Kinetics? Chemical kinetics describes how reactions happen. While thermodynamics tells us whether a reaction will occur and what the final state will be, kinetics reveals how fast it happens and what steps are involved. For any reaction A \\(\\longrightarrow\\) B, kinetics lets us predict how much B we’ll have after a given time, or how long we need to wait for a desired yield. Beyond this, understanding kinetics helps us control and optimize reactions by changing conditions like temperature and pressure. Figure 1.1: A plot of concentrations of reactant A and product B for a generic reaction A \\(\\longrightarrow\\) B as a function of time. Over time, A is converted to B. How long will it take to obtain 90% yield? Figure 1.2: If we increase the temperature we (usually) expect our reaction to speed up. But by how much? If we increase the reaction temperature by 10 K, how much faster can we reach 90% yield? 1.2 Reaction Rates A core concept in chemical kinetics is the idea of a reaction rate — the speed at which chemical change happens. We express reaction rates mathematically as derivatives of the form \\(\\frac{\\mathrm{d}[\\mathrm{X}]}{\\mathrm{d}t}\\), representing the change in concentration of a species X with time. This rate can be positive (for products being formed) or negative (for reactants being consumed). For any reaction that does not have a 1:1 stoichiometry ratio between all reactants and products, the numerical “rate” will depend on the chemical species we choose to define this. For example, for the reaction \\[\\begin{equation} \\mathrm{A} \\longrightarrow 2\\mathrm{B} \\end{equation}\\] the product, B, is formed at twice the rate that the reactant, A, is consumed. Hence, \\[2\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\] In general, we can define an “overall” reaction rate \\(\\nu\\) that is related to the rates of change of reactants and products by \\[\\nu = \\frac{1}{n_\\mathrm{X}}\\frac{\\mathrm{d}[\\mathrm{X}]}{\\mathrm{d}t}\\] where \\(n_\\mathrm{X}\\) is the stoichiometric coefficient of species \\(X\\) in the reaction equation. 1.3 Simple Rate Equations For many reactions, the rate of reaction is proportional to the concentrations of the reactants, raised to some power; i.e., \\[\\nu = k [\\mathrm{A}]^a [\\mathrm{B}]^b [\\mathrm{C}]^c \\ldots\\] The proportionality constant, \\(k\\), is called the rate constant. The exponents, \\(a\\), \\(b\\), \\(c\\) …, describe the order of the reaction with respect to the reactants A, B, C …. So, for a reaction \\[\\mathrm{A} + \\mathrm{B} \\longrightarrow \\mathrm{C}\\] with rate equation (or “rate law”) \\[\\nu = k[\\mathrm{A}]^2[\\mathrm{B}]\\], we would describe this as being second-order with respect to A, and first-order with respect to B. For rate equations that have the simple form above, we can define an overall order, which is the sum of the individual orders with respect to each of the reactants. In the example above, this reaction would be described as being third-order overall, since \\(a+b = 3\\). Not all reactions follow simple rate laws. For example, the reaction between H2 and Br2 to form HBr has an empirically-determined rate law \\[\\begin{equation} \\nu = k\\frac{[\\mathrm{H}_2][\\mathrm{Br}_2]^\\frac{1}{2}}{1+k^\\prime [\\mathrm{HBr}]/[\\mathrm{Br}_2]} \\tag{1.1} \\end{equation}\\] This rate law is first-order with respect to H2, because \\(\\nu \\propto [\\mathrm{H_2}]\\). But we cannot define an order with respect to Br2, because the overall rate is not simply proportional to \\([\\mathrm{Br}_2]\\) raised to some power. Instead, we would describe the order with respect to Br2 as being undefined. This means the overall order is also undefined, since we cannot simply add the orders with respect to H2 and Br2. 1.4 Elementary Processes Any chemical reaction can be broken down into a sequence of one of more single-step “elementary” processes. For example, for the reaction \\(\\mathrm{H}_2 + \\mathrm{Br}_2 \\longrightarrow 2\\mathrm{HBr}\\), where the empirical rate law is given by (1.1), one sequence of elementary processes that is consistent with this rate law is \\[\\begin{eqnarray} \\mathrm{Br}_2 &amp; \\longrightarrow &amp; \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet \\\\ \\mathrm{Br}^\\bullet + \\mathrm{H}_2 &amp; \\longrightarrow &amp; \\mathrm{H}^\\bullet + \\mathrm{HBr} \\\\ \\mathrm{H}^\\bullet + \\mathrm{Br}_2 &amp; \\longrightarrow &amp; \\mathrm{Br}^\\bullet + \\mathrm{HBr} \\\\ \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet &amp; \\longrightarrow &amp; \\mathrm{Br}_2 \\tag{1.2} \\end{eqnarray}\\] 1.4.1 Molecularity Elementary processes can be classified according to their molecularity — the number of reactant molecules that must come together for a particular reaction step. For example, in reaction mechanism (1.2), the first step involves the dissociation of Br2 to form two Br radicals: \\[\\begin{equation} \\mathrm{Br}_2 \\longrightarrow \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet \\end{equation}\\] This reaction step involves a single reactant molecule, so it is described a unimolecular. The second step involves a Br radical and H2 molecule reacting: \\[\\begin{equation} \\mathrm{Br}^\\bullet + \\mathrm{H}_2 \\longrightarrow \\mathrm{H}^\\bullet + \\mathrm{HBr} \\end{equation}\\] Because two reactant molecules must come together for this step, this is described as a bimolecular process. A process that involves two molecules of the same chemical species, as in the last step of the reaction mechanism above, is also bimolecular: \\[\\begin{equation} \\mathrm{Br}^\\bullet + \\mathrm{Br}^\\bullet \\longrightarrow \\mathrm{Br}_2 \\end{equation}\\] 1.4.2 Rate Laws for Elementary Processes The rate laws for elementary processes directly reflect their molecularity. Unimolecular processes (\\(\\mathrm{A} \\longrightarrow \\mathrm{P}\\)) show first-order kinetics with rate \\(\\nu = k[\\mathrm{A}]\\). Similarly, bimolecular processes show second-order kinetics: for a bimolecular process involving two distinct chemical species (\\(\\mathrm{A} + \\mathrm{B} \\longrightarrow \\mathrm{P}\\)), the process is first-order with respect to each species: \\(\\nu = k[\\mathrm{A}][\\mathrm{B}]\\), while a bimolecular process that involves two molecules of the same chemical species (\\(2\\mathrm{A} \\longrightarrow \\mathrm{P}\\)) is second-order with respect to that species: \\(\\nu = k[\\mathrm{A}]^2\\). Termolecular processes, involving three reactant molecules, show third order kinetics, e.g., \\(\\nu = k[\\mathrm{A}]^2[\\mathrm{B}]\\). In general, termolecular processes are rare, because the probability of three molecules colliding simultaneously with the correct orientation is very small. While termolecular processes can play a role at very high pressure, under more typical reaction conditions, experimental observations of third-order kinetics are often better explained by a complex multistep reaction mechanism. Figure 1.3: Elementary processes always follow simple rate laws, where the order with respect to each reactant reﬂects the molecularity of the process. 1.5 Moving Between Concentration and Rate Perspectives The progression of any chemical reaction can be viewed from two complementary perspectives: the concentration of species as they change over time, \\([\\mathrm{A}]\\), and the instantaneous rates at which these changes occur, \\(\\mathrm{d}[\\mathrm{A}]/\\mathrm{d}t\\). These two perspectives both describe the same underlying chemical process, just viewed through different mathematical lenses. Consider a reactant A being consumed during a reaction. We might track its concentration \\([\\mathrm{A}]\\) as it decreases over time, giving us a curve of concentration versus time. At any point on this curve, we can determine the instantaneous rate of reaction by finding the slope of the tangent line. Mathematically, this is equivalent to computing the derivative of \\([\\mathrm{A}]\\), i.e., \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\). Since we are dealing with the concentration of a reactant, the reaction rate is then the negative of this derivative (since the concentrations of A decreases with time): \\[\\begin{equation} \\nu = -\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} \\tag{1.3} \\end{equation}\\] We can also go the other way from a description of rate to a description of the concentration profile over time. Mathematically we do this by integration, which is the inverse operation to differentiation. By integrating a rate, we effectively sum all the small changes in concentration over some time interval. For example, the change in concentration of A from the start of a reaction at \\(t=0\\) is given by \\[\\begin{equation} [\\mathrm{A}]_t - [\\mathrm{A}]_0 = \\int_0^t -\\nu(t)\\,\\mathrm{d}t \\tag{1.4} \\end{equation}\\] Whether we work in terms of concentrations or rates depends on the question we are trying to answer, what information we have available to us, and whether it is more mathematically convenient to work with one than the other. Figure 1.4: If we know the concentration of a reactant or product as a function of time we can calculate the rate of change of this concentration by differentiation. We can also calculate how concentrations vary in time from rates by the inverse procedure, integration. 1.6 Integrating Simple Rate Laws For simple rate laws of the form \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}]^n\\] we can derive corresponding integrated rate laws by integrating (see CH12002 Lecture 3). 1.6.1 First-Order Reactions For a first-order process \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\), the rate of change of concentration of reactant, A, is given by \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] \\end{equation}\\] To derive the corresponding integrated rate law, we rearrange this to form an integral equation: \\[\\begin{equation} \\int_{[\\mathrm{A}]_0}^{\\mathrm[A]_t} \\frac{\\mathrm{d}[\\mathrm{A}]}{[\\mathrm{A}]}\\,\\mathrm{d}[\\mathrm{A}] = \\int_0^t -k\\,\\mathrm{d}t \\end{equation}\\] where the limits of the integral with respect to concentration of A are between the concentration at time \\(0\\) (\\([\\mathrm{A}]_0\\)) and the concentration at time \\(t\\) (\\([\\mathrm{A}]_t\\)), and the limits of the integral with respect to time are between \\(t=0\\) and \\(t=t\\). Integrating, using the integral \\(\\int \\frac{1}{x}\\,\\mathrm{d}x = \\ln x\\), gives \\[\\begin{equation} \\ln [\\mathrm{A}]_t - \\ln [\\mathrm{A}]_0 = -kt \\end{equation}\\] which can be rearranged as \\[\\begin{equation} [\\mathrm{A}]_t = [\\mathrm{A}]_0\\mathrm{e}^{-kt} \\tag{1.5} \\end{equation}\\] Hence, for a first-order process, the concentration of the reactant decays exponentially with time. Having derived an expression for \\([\\mathrm{A}]_t\\) we can now derive the integrated rate law for the concentration of the product, B, as a function of time. To do so, we use the known stoichoimetry of the reaction: for every molecule of A consumed, one molecule of B is formed, so the total concentration \\([\\mathrm{A}] + [\\mathrm{B}]\\) must be constant. Furthermore, when \\(t=0\\), only A is present, with a concentration \\([\\mathrm{A}]_0\\). So, \\([\\mathrm{A}] + [\\mathrm{B}] = [\\mathrm{A}]_0\\). Substituting in our expression for \\([\\mathrm{A}]\\) (Eqn. (1.5) gives \\[\\begin{eqnarray} [\\mathrm{B}] &amp; = &amp; [\\mathrm{A}]_0 - [\\mathrm{A}]_0\\mathrm{e}^{-kt} \\\\ &amp; = &amp; [\\mathrm{A}]_0\\left(1-\\mathrm{e}^{-kt}\\right) \\end{eqnarray}\\] Hence, for a first-order process, the concentration of the product exponentially approaches a limit of \\([\\mathrm{B}]_t = [\\mathrm{A}]_0\\). Figure 1.5: Concentrations as a function of time for a first-order process \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\). 1.6.2 Second-Order Reactions For a second-order process \\(2\\mathrm{A} \\longrightarrow \\mathrm{B}\\), with overall rate \\(\\nu = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\), the rate of change of concentration of reactant, A, is \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -2k[\\mathrm{A}]^2 \\tag{1.6} \\end{equation}\\] As for first-order reactions, above, we can derive the corresponding integrated rate law for \\([\\mathrm{A}]_t\\) by rearranging Eqn. (1.6) and then integrating: \\[\\begin{equation} \\int_{[\\mathrm{A}]_0}^{\\mathrm[A]_t} \\frac{\\mathrm{d}[\\mathrm{A}]}{[\\mathrm{A}]^2}\\,\\mathrm{d}[\\mathrm{A}] = \\int_0^t -k\\,\\mathrm{d}t \\end{equation}\\] Integrating, using the integral \\(\\int \\frac{1}{x^2}\\,\\mathrm{d}x = -\\frac{1}{x}\\), gives \\[\\begin{equation} \\frac{1}{[\\mathrm{A}]_t} - \\frac{1}{[\\mathrm{A}]_0} = -kt \\end{equation}\\] which can be rearranged as \\[\\begin{equation} [\\mathrm{A}]_t = \\frac{[\\mathrm{A}]_0}{1 + kt[\\mathrm{A}]_0} \\end{equation}\\] To obtain an expression for \\([\\mathrm{B}]_t\\), we again use our knowledge of the reaction stoichiometry and initial conditions: we start with only the reactant A, and at any stage of the reaction, the amount of B formed is equal to half the amount of A consumed. \\[\\begin{equation} [\\mathrm{B}]_t = \\frac{1}{2}\\left([\\mathrm{A}]_0 - [\\mathrm{A}]_t\\right) \\end{equation}\\] And, so \\[\\begin{equation} [\\mathrm{B}]_t = \\frac{[\\mathrm{A}]_0}{2}\\left(1 - \\frac{1}{1+kt[\\mathrm{A}_0]}\\right) \\end{equation}\\] which rearranges to \\[\\begin{equation} [\\mathrm{B}]_t = \\frac{kt[\\mathrm{A}]_0^2}{2(1 + kt[\\mathrm{A}]_0)} \\end{equation}\\] Figure 1.6: Concentrations as a function of time for a second-order process \\(2\\mathrm{A} \\longrightarrow \\mathrm{B}\\). The dashed line shows the sum \\([\\mathrm{A}]_t + [\\mathrm{B}]_t\\). Aside: Why Does Our Second-Order Rate Equation Include a Factor of 2? Let us briefly examine the origin of the factor of 2 on the right-hand side of Eqn. @ref{eq:secondorderdiff}. Writing the rate equation for \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\) in this way is consistent with the convention in Section 1.2, that the overall rate of a reaction is related to the rates of change of specific reactants or products by \\[\\begin{equation} \\nu = \\frac{1}{n_\\mathrm{X}}\\frac{\\mathrm{d}[\\mathrm{X}]}{\\mathrm{d}t} \\tag{1.7} \\end{equation}\\] We can also justify the factor of \\(2\\) by recognising that the stoichiometry of the reaction requires 2 molecules of A to be consumed for every 1 molecule of B formed, and, hence, \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = 2\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} \\end{equation}\\] The factor of 2 in Eqn. (1.6) is somewhat arbitrary though, as it is a consequence of our choice to define the overall rate of reaction as \\(\\nu = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\). If, instead, we define our overall rate as \\(\\nu = \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\) then we would write the rate of change of concentration of A as \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}]^2 \\tag{1.8} \\end{equation}\\] The functional form for \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\) is the same in both cases (Eqns. (1.6) and (1.8). Our choice of how we define our overall rate, however, determines what the rate constant \\(k\\) actually describes. The rate constant in (1.8) is equal to twice the rate constant in (1.6). Upon reflection, it should perhaps not be surprising that the numerical value of our rate constant \\(k\\) depends on how we choose to define the reaction rate. Whichever of these two ways we choose to define our overall rate, the procedure for deriving the second-order intergrated rate law is unchanged, and we end up with the same functional form for the integrated rate law — either with, or without, the factor of 2 carried through the derivation. 1.7 From Mechanisms to Rate Laws The relationship between reaction mechanisms and the time evolution of chemical concentrations depends strongly on the complexity of the reaction scheme. For reactions that consist of a single elementary process, we can usually determine how the concentrations of reactants and products evolve with time through a straightforward two-step process: Write down the rate equations for reactants and products based on the molecularity of the elementary process Directly integrate these rate equations to obtain the corresponding integrated rate laws For example, we have already seen how this works for first-order processes in Section 1.6. For reactions with multistep mechanisms, however, the path from mechanism to time evolution is often more complex. Our starting point is always the reaction mechanism itself—the sequence of elementary processes that describes the complete reaction scheme. From this mechanism, we write differential rate equations for all chemical species that appear, including not only the reactants and products, but also any reaction intermediates. When analysing multistep mechanisms, we typically pursue one or both of two goals: To derive an expression for the overall reaction rate in terms of reactant concentrations only, eliminating any dependence on intermediate concentrations To obtain integrated rate laws that describe how the concentrations of reactants and products vary with time How we approach these goals depends on the nature of the reaction mechanism under consideration. In general, we can analyse complex reaction mechanisms using one of three strategies: 1.7.1 Exact Solutions For some reaction mechanisms, we can derive exact analytical solutions to our coupled differential rate equations. While this approach is the most mathematically satisfying, it is only possible for relatively simple reaction schemes. 1.7.2 Approximate Analytical Solutions More commonly, we can simplify our set of coupled differential equations by applying chemical approximations based on the physical nature of the reaction mechanism. We then solve these simplified equations to obtain analytical solutions that accurately describe the real system within the range of conditions where our approximations hold. This approach often provides valuable chemical insight into the factors controlling reaction rates and time evolution. 1.7.3 Numerical Integration When analytical solutions prove intractable, we can always fall back on numerical methods. By numerically integrating our differential rate equations, we can model how the concentrations of all species—reactants, products, and intermediates—evolve over time. While this approach will always work in principle, it may provide less direct insight into the underlying chemical processes than analytical solutions, even approximate ones. Although numerical integration provides a reliable method of last resort, there is often significant value in pursuing analytical solutions, either exact or approximate. These solutions can reveal fundamental relationships between reaction parameters and chemical behavior that might be obscured in purely numerical results. 1.8 Consecutive Reactions Having examined simple rate laws and elementary processes, we now consider how to analyze reactions that occur in multiple steps. One important class of such reactions are consecutive (or sequential) reactions, where products are formed through a series of steps: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B} \\xrightarrow{k_2} \\mathrm{C}\\] Such reaction sequences are common in both chemical and biochemical systems. For example, the decomposition of many organic compounds proceeds through multiple intermediates, and many metabolic pathways involve sequences of enzyme-catalyzed reactions. 1.8.1 Rate Equations Following our approach from Section 1.2, we can write differential rate equations for each species: \\[\\begin{align} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} &amp;= -k_1[\\mathrm{A}] \\\\ \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} &amp;= +k_1[\\mathrm{A}] - k_2[\\mathrm{B}] \\\\ \\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} &amp;= +k_2[\\mathrm{B}] \\end{align}\\] Note that species B appears both as a product (in the first step) and as a reactant (in the second step). This is characteristic of reaction intermediates. 1.8.2 Integrated Rate Laws We can solve these coupled differential equations sequentially. First, the equation for [A] is a simple first-order decay (see Section 1.6): \\[[\\mathrm{A}] = [\\mathrm{A}]_0\\mathrm{e}^{-k_1t}\\] To solve for [B], we substitute this expression into the second differential equation: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t} - k_2[\\mathrm{B}]\\] Integrating this linear first-order differential equation (see Appendix A) gives: \\[[\\mathrm{B}] = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}(\\mathrm{e}^{-k_1t} - \\mathrm{e}^{-k_2t})\\] Finally, we can find [C] using conservation of mass ([A] + [B] + [C] = [A]₀): \\[[\\mathrm{C}] = [\\mathrm{A}]_0\\left[1 + \\frac{k_1\\mathrm{e}^{-k_2t} - k_2\\mathrm{e}^{-k_1t}}{k_1-k_2}\\right]\\] Figure 1.7: Concentration profiles for a consecutive reaction A → B → C. The intermediate B exhibits a maximum concentration at intermediate times. 1.8.3 Limiting Cases and the Rate-Determining Step The kinetics of consecutive reactions can be simplified when one step is much slower than the other. This slower step becomes rate-determining for the overall reaction. 1.8.3.1 Case 1: \\(k_1 \\ll k_2\\) When the first step is much slower than the second: B is consumed almost as soon as it is formed [B] remains very small throughout the reaction Formation of C follows approximately first-order kinetics: \\[[\\mathrm{C}] \\approx [\\mathrm{A}]_0(1-\\mathrm{e}^{-k_1t})\\] 1.8.3.2 Case 2: \\(k_1 \\gg k_2\\) When the first step is much faster than the second: A is rapidly converted to B B accumulates before slowly converting to C After an initial rapid phase, formation of C follows approximately first-order kinetics: \\[[\\mathrm{C}] \\approx [\\mathrm{A}]_0(1-\\mathrm{e}^{-k_2t})\\] Figure 1.8: Concentration profiles for consecutive reactions in limiting cases. Left: k₁ &lt;&lt; k₂, where the first step is rate-determining. Right: k₁ &gt;&gt; k₂, where the second step is rate-determining. The concept of a rate-determining step is particularly valuable when analyzing complex reaction mechanisms. When one step in a reaction sequence is much slower than the others, it becomes the “bottleneck” that controls the overall reaction rate. This principle helps explain why many complex reactions show simple kinetic behavior—the observed kinetics often reflect just the rate-determining step. 1.9 The Steady-State Approximation When analyzing complex reaction mechanisms, we can often simplify our analysis using the steady-state approximation. This approximation applies to reaction intermediates that are consumed much faster than they are formed, leading to a “steady state” where the rate of change of the intermediate’s concentration is approximately zero. 1.9.1 Basic Principles The steady-state approximation assumes that after a brief initial period, the concentration of a reactive intermediate B reaches a “steady state” where: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} \\approx 0\\] Consider our consecutive reaction mechanism from the previous section: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B} \\xrightarrow{k_2} \\mathrm{C}\\] The rate equations are: \\[\\begin{align} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} &amp;= -k_1[\\mathrm{A}] \\\\ \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} &amp;= k_1[\\mathrm{A}] - k_2[\\mathrm{B}] \\\\ \\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} &amp;= k_2[\\mathrm{B}] \\end{align}\\] When \\(k_2 \\gg k_1\\), B is consumed much faster than it is formed, and we can apply the steady-state approximation: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}] - k_2[\\mathrm{B}] \\approx 0\\] This allows us to solve for \\([\\mathrm{B}]\\): \\[[\\mathrm{B}] \\approx \\frac{k_1}{k_2}[\\mathrm{A}]\\] Substituting this expression into our rate equation for C: \\[\\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = k_2[\\mathrm{B}] = k_1[\\mathrm{A}]\\] From conservation of mass, \\([\\mathrm{A}]_0 = [\\mathrm{A}] + [\\mathrm{B}] + [\\mathrm{C}]\\). Under the condition \\(k_2 \\gg k_1\\), the concentration of B remains small, so \\([\\mathrm{A}]_0 ≈ [\\mathrm{A}] + [\\mathrm{C}]\\). Therefore: \\[\\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = k_1[\\mathrm{A}] = k_1([A]_0 - [C])\\] This first-order differential equation can be directly integrated to give: \\[[\\mathrm{C}] = [\\mathrm{A}]_0(1-\\mathrm{e}^{-k_1t})\\] This is the same result we obtained in our analysis of consecutive reactions in the limit where \\(k_1 \\ll k_2\\). 1.9.2 Validity of the Steady-State Approximation The steady-state approximation simplifies the analysis of complex reaction mechanisms by treating the concentrations of reactive intermediates as constant. While this mathematical convenience makes many problems tractable, we need to understand when the approximation holds and what it reveals about reaction kinetics. A steady state exists when the rates of formation and consumption of the intermediate balance. This requires two conditions: the intermediate must be consumed much faster than it forms, and enough time must have passed for the intermediate to build up to its steady-state concentration. This initial period, where the intermediate concentration increases to its steady-state value, is called the induction period. Consider a reaction with the mechanism: \\[\\mathrm{A} + \\mathrm{B} \\underset{k_{-1}}{\\overset{k1}\\rightleftharpoons} \\mathrm{C} \\overset{k_2}\\rightarrow \\mathrm{D}\\] Reactants A and B combine reversibly to form an intermediate C, which then reacts to form product D. The steady-state approximation assumes \\(\\mathrm{d}[\\mathrm{C}]/\\mathrm{d}t \\approx 0\\) — that is, the concentration of C remains approximately constant as the reaction proceeds. Figure 1.9: Time evolution of concentrations for the reaction mechanism \\(\\mathrm{A} + \\mathrm{B} \\underset{k_1}{\\overset{k1}\\rightleftharpoons} \\mathrm{C} \\overset{k_2}\\longrightarrow \\mathrm{D}\\) where \\(k_2 \\gg k_1\\). Solid lines show the exact concentrations, while the dashed line shows the predicted product concentration \\([\\mathrm{D}]_\\mathrm{SSA}\\) calculated using the steady-state approximation for intermediate C. The approximation overshoots during the initial induction period where [C] is still building up, but describes the reaction progress well once steady state is established. Figure 1.9 compares the steady-state prediction for [D] (dashed line) with the exact concentration profiles (solid lines) when \\(k_2 \\gg k_1\\). During the induction period, the steady-state approximation overestimates the rate of product formation because it assumes C has already reached its steady-state concentration. However, once this period passes, the predicted and actual concentrations align well. These observations suggest several criteria for applying the steady-state approximation to new systems. First, the kinetics must support the basic steady-state assumption, typically requiring \\(k_2 \\gg k_1\\). Second, the timescale of interest must exceed the induction period. Third, any deviations during the induction period should not compromise the analysis. When steady-state predictions match experimental data, they provide evidence for a reaction mechanism involving an intermediate maintained at near-constant concentration during the main reaction phase. "],["lecture2.html", "Lecture 2 Parallel Irreversible Reactions 2.1 Introduction 2.2 Simple First-Order Reactions 2.3 First-Order Parallel Reactions 2.4 Key Features of Parallel Reactions 2.5 Temperature Effects on Selectivity 2.6 Pressure Effects on Selectivity", " Lecture 2 Parallel Irreversible Reactions 2.1 Introduction In many chemical systems, a single reactant can undergo multiple competing reactions simultaneously to form different products. These are called parallel reactions. The simplest example is where a reactant A can form either product B or product C: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B}\\] \\[\\mathrm{A} \\xrightarrow{k_2} \\mathrm{C}\\] Understanding how these parallel reactions proceed and what controls their relative rates is crucial for many practical applications, particularly in synthetic chemistry where we often want to maximize the yield of one product over another. 2.2 Simple First-Order Reactions Let us first consider the case of a single first-order reaction: \\[\\mathrm{A} \\xrightarrow{k} \\mathrm{B}\\] The rate equations are: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}]\\] \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = +k[\\mathrm{A}]\\] Integrating these gives: \\[[\\mathrm{A}] = [\\mathrm{A}]_0\\mathrm{e}^{-kt}\\] And since [B] = [A]0 - [A] (from conservation of mass): \\[[\\mathrm{B}] = [\\mathrm{A}]_0(1-\\mathrm{e}^{-kt})\\] Figure 2.1: Concentrations of reactant, A, and product, B, as a function of time for a reaction \\(\\mathrm{A}\\longrightarrow\\mathrm{B}\\) with first-order kinetics. 2.3 First-Order Parallel Reactions For parallel reactions where both pathways are first-order: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B}\\] \\[\\mathrm{A} \\xrightarrow{k_2} \\mathrm{C}\\] The rate of change of A is now: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(k_1 + k_2)[\\mathrm{A}]\\] Integrating this gives: \\[[\\mathrm{A}] = [\\mathrm{A}]_0\\mathrm{e}^{-(k_1+k_2)t}\\] For product B: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}] = k_1[\\mathrm{A}]_0\\mathrm{e}^{-(k_1+k_2)t}\\] Integrating: \\[[\\mathrm{B}] = \\frac{k_1}{k_1+k_2}[\\mathrm{A}]_0(1-\\mathrm{e}^{-(k_1+k_2)t})\\] Similarly for C: \\[[\\mathrm{C}] = \\frac{k_2}{k_1+k_2}[\\mathrm{A}]_0(1-\\mathrm{e}^{-(k_1+k_2)t})\\] 2.4 Key Features of Parallel Reactions Several important points emerge from these expressions: The formation of both products B and C is controlled by the same overall rate constant (\\(k_1 + k_2\\)) The relative yields of products are determined by the ratio of the rate constants: \\[\\frac{[\\mathrm{B}]}{[\\mathrm{C}]} = \\frac{k_1}{k_2}\\] This ratio is often called the selectivity, S: \\[S = \\frac{k_1}{k_2}\\] Figure 2.2: B and C both form via first-order processes with the same effective rate constant \\(k_1+k_2\\). At any point in time, the ratio \\([\\mathrm{B}]/[\\mathrm{C}]\\) is equal to \\(k_1/k_2\\). 2.5 Temperature Effects on Selectivity How does changing temperature affect the selectivity? Using the Arrhenius equation: \\[k_1 = A_1\\exp\\left(-\\frac{\\Delta E_1}{RT}\\right)\\] \\[k_2 = A_2\\exp\\left(-\\frac{\\Delta E_2}{RT}\\right)\\] Therefore: \\[S = \\frac{k_1}{k_2} = \\frac{A_1}{A_2}\\exp\\left(-\\frac{\\Delta E_1-\\Delta E_2}{RT}\\right)\\] If \\(\\Delta E_1 &gt; \\Delta E_2\\), then (\\(\\Delta E_1 - \\Delta E_2\\)) is positive, and increasing temperature will increase \\(S\\). This can be visualized using an Arrhenius plot (\\(\\ln k\\) vs \\(1/T\\)), where the reaction with the higher activation energy has the steeper slope. Figure 2.3: Arrhenius plot showing the qualitative effect of changing temperature on selectivity between two reactions with different activation energies. Increasing temperature gives a larger increase in rate constant for the reaction with the larger activation energy, \\(\\Delta E\\), and increases selectivity for the product formed via this reaction. 2.6 Pressure Effects on Selectivity The effect of pressure on selectivity depends on the molecularity of the competing reactions: If both reactions have the same molecularity (e.g., both first-order), pressure has no effect on selectivity because k is independent of pressure. For reactions with different molecularity: \\[\\mathrm{A} \\xrightarrow{k_1} \\mathrm{B}\\] \\[2\\mathrm{A} \\xrightarrow{k_2} \\mathrm{C}\\] The selectivity becomes pressure-dependent: \\[\\frac{[\\mathrm{B}]}{[\\mathrm{C}]} = \\frac{\\text{rate}_\\mathrm{B}}{\\text{rate}_\\mathrm{C}} = \\frac{k_1[\\mathrm{A}]}{k_2[\\mathrm{A}]^2} = \\frac{k_1}{k_2[\\mathrm{A}]}\\] Following Le Chatelier’s principle, increasing pressure favors the reaction with the higher molecularity. 2.6.1 Example: Decomposition of H2O2 The decomposition of hydrogen peroxide in aqueous solution occurs through two parallel pathways. A unimolecular decomposition: \\[\\begin{equation} \\mathrm{H}_2\\mathrm{O}_2 \\overset{k_1}{\\longrightarrow} \\mathrm{H}_2\\mathrm{O} + \\frac{1}{2}\\mathrm{O}_2 \\end{equation}\\] and a bimolecular process: \\[\\begin{equation} 2\\mathrm{H}_2\\mathrm{O}_2 \\overset{k_2}{\\longrightarrow} 2\\mathrm{H}_2\\mathrm{O} + \\mathrm{O}_2 \\end{equation}\\] The overall rate of H2O2 consumption combines both pathways: \\[\\begin{equation} -\\frac{\\mathrm{d}[\\mathrm{H}_2\\mathrm{O}_2]}{\\mathrm{d}t} = k_1[\\mathrm{H}_2\\mathrm{O}_2] + 2k_2[\\mathrm{H}_2\\mathrm{O}_2]^2 \\end{equation}\\] The factor of 2 in the second term arises from the stoichiometry of the bimolecular process, where each reaction event consumes two H2O2 molecules. The relative contribution of each pathway depends on the concentration of H2O2: \\[\\begin{equation} \\frac{\\text{rate}_1}{\\text{rate}_2} = \\frac{k_1[\\mathrm{H}_2\\mathrm{O}_2]}{2k_2[\\mathrm{H}_2\\mathrm{O}_2]^2} = \\frac{k_1}{2k_2[\\mathrm{H}_2\\mathrm{O}_2]} \\end{equation}\\] This ratio varies inversely with H2O2 concentration. The relative importance of the two pathways therefore depends both on the concentration and on the specific values of the rate constants \\(k_1\\) and \\(k_2\\). "],["lecture3.html", "Lecture 3 Parallel Reversibile Reactions 3.1 Introduction to Parallel Reversible Reactions 3.2 Time Evolution of Product Distributions 3.3 Kinetic vs Thermodynamic Control 3.4 Example: Enolate formation of 2-methylcyclohexanone", " Lecture 3 Parallel Reversibile Reactions 3.1 Introduction to Parallel Reversible Reactions Building on our previous discussion of parallel reactions, we now consider systems where the individual reactions are reversible: \\[\\mathrm{A} \\mathrel{\\mathop{\\rightleftarrows}^{k_1}_{k_{-1}}} \\mathrm{B}\\] \\[\\mathrm{A} \\mathrel{\\mathop{\\rightleftarrows}^{k_2}_{k_{-2}}} \\mathrm{C}\\] For such systems, the rate equations are: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(k_1 + k_2)[\\mathrm{A}] + k_{-1}[\\mathrm{B}] + k_{-2}[\\mathrm{C}]\\] \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = +k_1[\\mathrm{A}] - k_{-1}[\\mathrm{B}]\\] \\[\\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = +k_2[\\mathrm{A}] - k_{-2}[\\mathrm{C}]\\] 3.2 Time Evolution of Product Distributions 3.2.1 Short-Time Behaviour At very short times, when [B] ≈ 0 and [C] ≈ 0, the backward reactions can be neglected and the system behaves similarly to the irreversible case we studied previously. The relative yields of products are determined by the ratio of the forward rate constants: \\[\\frac{[\\mathrm{B}]}{[\\mathrm{C}]} \\approx \\frac{k_1}{k_2}\\] This is often called “kinetic control”, as the product distribution is determined by the relative rates of the forward reactions. 3.2.2 Long-Time Behaviour At long times, the system reaches equilibrium, where: \\[\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = \\frac{\\mathrm{d}d[\\mathrm{C}]}{\\mathrm{d}t} = 0\\] At equilibrium: \\[k_1[\\mathrm{A}]_\\mathrm{eq} = k_{-1}[\\mathrm{B}]_\\mathrm{eq}\\] \\[k_2[\\mathrm{A}]_\\mathrm{eq} = k_{-2}[\\mathrm{C}]_\\mathrm{eq}\\] This gives equilibrium constants: \\[K_\\mathrm{AB} = \\frac{[\\mathrm{B}]_\\mathrm{eq}}{[\\mathrm{A}]_\\mathrm{eq}} = \\frac{k_1}{k_{-1}}\\] \\[K_\\mathrm{AC} = \\frac{[\\mathrm{C}]_\\mathrm{eq}}{[\\mathrm{A}]_\\mathrm{eq}} = \\frac{k_2}{k_{-2}}\\] The final product ratio at equilibrium is: \\[\\frac{[\\mathrm{B}]_\\mathrm{eq}}{[\\mathrm{C}]_\\mathrm{eq}} = \\frac{k_1k_{-2}}{k_{-1}k_2}\\] This is called “thermodynamic control”, as the product distribution is determined by the relative thermodynamic stabilities of the products. 3.3 Kinetic vs Thermodynamic Control When thinking about a pair of parallel reactions, we can rationalise a preference for forming either the kinetic or thermodynamic product by considering how the energy of a molecular system changes as reactants transform to products. Figure 3.1: A reaction coordinate diagram showing the free energy profile for a chemical reaction. The reaction coordinate represents the progression through molecular geometric changes (e.g., bonds breaking and forming) as reactants transform into products. The activation energy (\\(\\Delta G_\\mathrm{a}\\)) determines reaction rate, while the reaction free energy (\\(\\Delta G_\\mathrm{r}\\)) determines the position of equilibrium. Figure 3.1 shows an example of a reaction coordinate diagram. A reaction coordinate diagram is a schematic representation of how the free energy of a molecular system changes as a reaction proceeds. The horizontal axis is called the reaction coordinate, and represents the progression of the reaction along a particular reaction pathway—often this corresponds to a specific change in geometry as atoms rearrange and bonds break and form. The vertical axis shows the Gibbs free energy of the system. Two key features of these diagrams help us understand reaction behaviour: The activation energy (\\(\\Delta G_\\mathrm{a}\\)) represents the energy barrier that must be overcome for reaction to occur. This determines reaction rate—lower barriers mean faster reactions. The reaction free energy (\\(\\Delta G_\\mathrm{r}\\)) represents the overall thermodynamic driving force. This determines the position of equilibrium—more negative values mean the products are more favoured at equilibrium. We can expand this concept of a reaction coordinate diagram to the case of parallel reactions by considering a diagram that shows two paths, A → B and A → C. In this composite reaction coordinate diagram, both paths start from the reactant A. One path leads to product B and the other path leads to product C. To understand the competition between kinetic and thermodymamic control, we consider the case where: The reaction A → B has a lower activation energy than the reaction A → C; C is thermodynamically favoured versus B; i.e., \\(\\Delta G(B \\to C) &lt; 0\\). At short times, the concentrations of B and C are small, and relative concentrations of B and C approximately follow the relative rates of the corresponding forward reactions. Because the activation barrier for A → B is smaller than for A → C, B forms more rapidly than C, and [B]/[C] &gt; 1. The kinetic product is therefore B. At long times the kinetic product, B, can convert back to the reactant A, via path B → A, and then convert to C, via path A → C. Eventually we reach an equilibrium distribution of products, where the ratio [B]/[C] at equilibrium depends on the relative free energies of the two competing products. Because \\(\\Delta G(B \\to C) &lt; 0\\), at long times C is favoured (thermodynamic product) and [B]/[C] &lt; 1. Figure 3.2: Reaction coordinate diagram for a pair of parallel reversible reactions: A\\(\\,\\overset{k_1}{\\underset{k_{-1}}\\rightleftharpoons}\\,\\)B and A\\(\\,\\overset{k_2}{\\underset{k_{-2}}\\rightleftharpoons}\\,\\)C, where \\(\\Delta E_1 &lt; \\Delta E_2\\) (i.e., \\(k_1 \\gg k_2\\)) and \\(\\Delta G(\\mathrm{B} \\to \\text{C}) &lt; 0\\). (a) kinetic control: at short times the relative formation of B and C depends only on the relative rates of the forward reactions A → B and A → C. (b) thermodynamic control: at long times the relative formation of B and C depends on the free energy difference between the two products. 3.4 Example: Enolate formation of 2-methylcyclohexanone Thinking about competing products as being preferentially formed under kinetic or thermodynamic control gives us a framework for understanding how our choice of reaction conditions can determine the selectivity of reaction. As an example, consider enolate formation of 2-methylcyclohexanone. Figure 3.3: Under basic conditions, 2-methylcyclohexanone can form two distinct enolates, depending on whether a proton is removed from position 2 (green) or from position 6 (orange). 2-methylcyclohexanone can form two different enolates, depending on whether the base extracts a proton from position 2 or from position 6. In the presence of a strong base, the less substituted enolate (product A) is preferentially formed with high selectivity. While in the presence of a weak base, the more substituted enolate (product B) is preferentially formed with moderate selectivity (see Figure 3.3). Figure 3.4: The selectivity between products A and B product B depends on the strength of the base that reacts with the 2-methylcyclohexanone. We can understand the selectivity of this enolate formation, and why this depends on the strength of the base added, by thinking about the competition between the kinetic and thermodynamic products. The thermodynamic product is the enolate that is thermodynamically more stable. In general, more subtituted alkenes are more stable than less substituted alkenes (see Figure 3.5), so we can expect product B to be the thermodynamic product. Figure 3.5: Negative enthalpies of hydrogenation, \\(-\\Delta H_\\mathrm{hyd}\\), for the series of C6H12 alkenes. The enthalpy of hydrogenation becomes less negative (less exothermic) as the degree of substitution of the alkene increases, indicating an increased stability of the C=C double bond. The kinetic product is the product that forms fastest at the start of the reaction, so to identify the kinetic product, we need to consider the relative rates of forward reactions, \\(k_\\mathrm{A}\\) and \\(k_\\mathrm{B}\\). Because of the methyl group at position 2, the proton at position 2 is sterically hindered, while the proton at position 6 is not. We can therefore expect the proton at position 6 to be removed more easily than the proton at position 2, with product A, therefore, formed faster than product B. Product A is the kinetic product. Figure 3.6: Removing the proton at position 6 gives product A, while removing the proton at position 2 gives product B. The proton at position 2 is more sterically hindered than the proton at position 6, so is harder to remove. Now that we have identified the kinetic product as product A and the thermodynamic product as product B, we can think about why using a strong base gives predominantly product A (kinetic control) but a weak base gives predominantly product B (thermodynamic control). First, let us consider the case of using a strong base. We have already identified that \\(k_\\text{A} &gt; k_\\text{B}\\), by considering which proton is more easily removed. In the presence of a strong base, we can also say that the position of equilibrium for both products ie expected to strongly favour the products, i.e., \\(K_\\mathrm{A} \\gg 1\\) and \\(K_\\mathrm{B} \\gg 1\\). For a reversible reaction the equilibrium constant is equal to the ratio of rate constants for the forward and reverse reactions, so: \\[\\begin{equation} \\frac{k_\\mathrm{A}}{k_{-\\mathrm{A}}} \\gg 1 \\qquad \\frac{k_\\mathrm{B}}{k_{-\\mathrm{B}}} \\gg 1. \\end{equation}\\] Both reverse reactions, B → R and C → R, where R is the reactant, are much slower than the corresponding forward reactions, and so we can treat both reactions as effectively irreversible. At the start of the reaction, product A is formed much more quickly than product B, and the relative amounts of products A and B reflect the different rates of the two forward reactions. Hence, we obtain a very high selectivity for the kinetic product A. We can also analyse the selectivity for product A over product B using a reaction coordinate diagram (Figure 3.7). Because \\(K_\\mathrm{A} \\gg 1\\) and \\(K_\\mathrm{B} \\gg 1\\), the free energies of formation of both products, A and B, are large (because \\(\\Delta G_\\mathrm{r} = -RT \\ln K\\)). This means the barriers for the reverse reactions A → R and B → R are large, and these reverse reactions are very slow, making both reactions effectively irreversible. In addition, the barrier for R → A is lower than the barrier for R → B, so product A will form faster than product B. This combination of faster formation of A than of B and effective irreversibility of both reactions gives us strong selectivity for the kinetic product, A. Figure 3.7: In the presence of a strong base, the position of equilibrium strongly favours both enolates, and both forward reactions are effectively irreversible. The pathway R → A has a lower activation barrier than the pathway R → B, so product A is formed faster than product B, resulting in strong selectivity for product A. In the presence of a weak base, both equilibria are more balanced: \\(K_\\mathrm{A} \\approx 1\\) and \\(K_\\mathrm{B} \\approx 1\\). Again, using the fact that these equiibrium constants are equal to the ratios of rate constants for the forward and reverse reactions, this tells us that \\(k_{-\\mathrm{A}} \\approx k_\\mathrm{A}\\) and \\(k_{-\\mathrm{B}} \\approx k_\\mathrm{B}\\), i.e., both reverse reactions have rates that are approximately equal to the corresponding forward reactions, and are therefore highly reversible. We still have \\(k_\\text{A} &gt; k_\\text{B}\\), and, so, at the start of the reaction product A forms faster than product B. But, because R → A is reversible, A is able to convert back to the reactant and then to form product B. Eventually we end up with a ratio [B]/[A] that reflects the free energy difference between the two products, with preferential formation for the thermodynamic product, B. Figure 3.8: In the presence of a weak base, the position of equilibrium less strongly favours both enolates, and both reactions are effectively reversible. Now the selectivity is determined by the free energy difference between the two products. Because B is more thermodymamically stable than A (because it is the more substituted enolate), we get preferential selectivity for the thermodynamic product B. "],["lecture4.html", "Lecture 4 Numerical Integration 4.1 From Mechanisms to Kinetic Data 4.2 The Role of Integration in Chemical Kinetics 4.3 Principles of Numerical Integration 4.4 Sources of Error 4.5 The Role of Numerical Integration in Chemical Kinetics", " Lecture 4 Numerical Integration 4.1 From Mechanisms to Kinetic Data One reason to study the kinetics of reactions is beacause kinetic data can provide us with information about reaction mechanisms. Often, we start by collecting experimental concentration-time data for some reaction, and using this to deduce an empirical rate law (see CH12002 Lecture 4). Once we have an empirical rate law, this can inform our thinking around possible reaction mechanisms. The rate law may be of the same form as for another reaction where we know the mechanism, and so we propose that our current reaction proceeds by an equivalent mechanism. Or our empirical rate law simply acts as a constraint: any proposed mechanisms must give a theoretical rate law that is consistent with out experimentally deduced rate law. Alternatively, we might start from some hypothetical reaction mechanism: perhaps proposed on the basis of some prior chemical knowledge we have about our specific reaction. From this proposed mechanism, we can predict the shape of concentration-time profiles we would expect in experiments, given that our mechanism is correct, and then compare our predicted concentration-time profiles to those obtained from experiments. If we find good agreement between our predicted concetration-time data and those recorded experimentally then this provides support for our proposed mechanism being correct. If our predicted concentration-time data, however, do not agree with our experimental results — in particular, if the predicted and experimental concentration-time profiles have qualitatively different shapes — then we can reject the proposed mechanism on the basis that it is inconsistent with experiment. 4.2 The Role of Integration in Chemical Kinetics For simple reaction mechanisms, we can often derive analytical expressions for how concentrations change with time. Consider a first-order reaction \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\). The differential rate equation is \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] \\tag{4.1} \\end{equation}\\] and we can solve this by integration to obtain \\[\\begin{equation} [\\mathrm{A}]_t = [\\mathrm{A}]_0\\mathrm{e}^{-kt} \\tag{4.2} \\end{equation}\\] However, for many reaction mechanisms, deriving analytical solutions becomes either extremely difficult or impossible. Consider, for example, the Lindemann mechanism for a unimolecular reaction: \\[\\begin{align*} \\mathrm{A} + \\mathrm{M} &amp;\\rightleftharpoons \\mathrm{A}^* + \\mathrm{M} &amp; k_1,\\, k_{-1} \\\\ \\mathrm{A}^* &amp;\\longrightarrow \\mathrm{P} &amp; k_2 \\end{align*}\\] The corresponding differential rate equations are: \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k_1[\\mathrm{A}][\\mathrm{M}] + k_{-1}[\\mathrm{A}^*][\\mathrm{M}] \\tag{4.3} \\end{equation}\\] \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}^*]}{\\mathrm{d}t} = k_1[\\mathrm{A}][\\mathrm{M}] - k_{-1}[\\mathrm{A}^*][\\mathrm{M}] - k_2[\\mathrm{A}^*] \\tag{4.4} \\end{equation}\\] \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{P}]}{\\mathrm{d}t} = k_2[\\mathrm{A}^*] \\tag{4.5} \\end{equation}\\] While we can make approximations (such as the steady-state approximation) to derive approximate analytical solutions under certain conditions, numerical integration provides a general approach that can be applied to any mechanism, regardless of its complexity. 4.3 Principles of Numerical Integration To understand how numerical integration works, let us return to our simple first-order reaction \\(\\mathrm{A} \\longrightarrow \\mathrm{B}\\). The differential rate equations are: \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] \\tag{4.6} \\end{equation}\\] \\[\\begin{equation} \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = +k[\\mathrm{A}] \\tag{4.7} \\end{equation}\\] The numerical integration approach recognises that these equations tell us the instantaneous rates of change of \\([\\mathrm{A}]\\) and \\([\\mathrm{B}]\\) at any point in time. If we know these rates at time \\(t\\), we can estimate the concentrations a short time later, at \\(t + \\Delta t\\): \\[\\begin{equation} [\\mathrm{A}]_{t+\\Delta t} = [\\mathrm{A}]_t + \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t}\\Delta t \\tag{4.8} \\end{equation}\\] \\[\\begin{equation} [\\mathrm{B}]_{t+\\Delta t} = [\\mathrm{B}]_t + \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t}\\Delta t \\tag{4.9} \\end{equation}\\] where \\(\\Delta t\\) is called the time step. Starting with known initial concentrations at \\(t = 0\\), we can use these equations to “step forward” in time, calculating new concentrations at each step. 4.3.1 A Simple Example Let us work through a specific example. Consider the first-order reaction above with \\(k = 1\\,\\mathrm{s}^{-1}\\) and initial conditions \\([\\mathrm{A}]_0 = 1\\,\\mathrm{M}\\) and \\([\\mathrm{B}]_0 = 0\\,\\mathrm{M}\\). Using a time step \\(\\Delta t = 0.1\\,\\mathrm{s}\\): At \\(t = 0~\\mathrm{s}\\): \\([\\mathrm{A}]_0 = 1~\\mathrm{M}\\) \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(1~\\mathrm{s}^{-1})(1~\\mathrm{M}) = -1~\\mathrm{M}~\\mathrm{s}^{-1}\\) \\([\\mathrm{A}]_{0.1} = 1~\\mathrm{M} + (-1~\\mathrm{M}\\mathrm{s}^{-1})(0.1\\mathrm{s}) = 0.9~\\mathrm{M}\\) Similarly, \\([\\mathrm{B}]_{0.1} = 0~\\mathrm{M} + (1~\\mathrm{M}\\mathrm{s}^{-1})(0.1\\mathrm{s}) = 0.1~\\mathrm{M}\\) At \\(t = 0.1~\\mathrm{s}\\): \\([\\mathrm{A}]_{0.1} = 0.9~\\mathrm{M}\\) \\(\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -(1~\\mathrm{s}^{-1})(0.9~\\mathrm{M}) = -0.9~\\mathrm{M}~\\mathrm{s}^{-1}\\) \\([\\mathrm{A}]_{0.2} = 0.9~\\mathrm{M} + (-0.9~\\mathrm{M}\\mathrm{s}^{-1})(0.1\\mathrm{s}) = 0.81~\\mathrm{M}\\) This process continues, giving us approximate values for \\([\\mathrm{A}]_t\\) and \\([\\mathrm{B}]_t\\) at discrete time points. 4.4 Sources of Error The numerical integration method makes one key approximation: it assumes the reaction rates remain constant over each time step. In reality, rates change continuously as concentrations change. This approximation introduces systematic errors that become larger when: The time step \\(\\Delta t\\) is increased Reaction rates change more rapidly within each time step We can improve accuracy by: Using a smaller time step (at the cost of more computational steps) Using more sophisticated algorithms (e.g., Runge-Kutta methods) that better approximate the changing reaction rates 4.5 The Role of Numerical Integration in Chemical Kinetics Numerical integration is an essential tool for modern studies of complex reaction mechanisms. The methods outlined above can handle mechanisms of arbitrary complexity, from simple decomposition reactions through to complex biochemical networks. Where analytical solutions become intractable, numerical methods remain practical and reliable. The accuracy of numerical solutions depends primarily on the chosen time step. While the simple Euler method presented here illustrates the key principles, modern numerical integration routines use more sophisticated algorithms. These “adaptive” methods automatically adjust their time steps based on how rapidly concentrations change. Small time steps maintain accuracy during periods of rapid change, while larger steps efficiently handle slower phases of the reaction. This automatic adaptation makes numerical integration both more reliable and more computationally efficient than fixed-step methods. The real power of numerical integration emerges when comparing theoretical predictions with experimental data. Given a proposed mechanism, we can calculate concentration profiles and compare these directly with measurements. Agreement between calculation and experiment supports the proposed mechanism, while significant discrepancies suggest the mechanism needs revision. This approach proves especially valuable for complex mechanisms where analytical solutions cannot guide our intuition about expected behavior. Beyond testing mechanisms, numerical methods help extract rate constants from experimental data and explore how changing conditions affects reaction outcomes. The principles developed in this chapter underpin much of modern chemical kinetics, complementing the analytical methods examined in earlier lectures. "],["lecture5.html", "Lecture 5 Collision Theory 5.1 Introduction to Kinetic Theories 5.2 Fundamentals of Collision Theory 5.3 From Collisions to Reaction Rates 5.4 Relationship to the Arrhenius Equation 5.5 Limitations of Collision Theory as a Predictive Framework", " Lecture 5 Collision Theory 5.1 Introduction to Kinetic Theories Up to this point, we have focused on describing and interpreting empirical data—either deriving rate laws from experimental data or proposing reaction mechanisms and comparing their predictions against observations. While this approach allows us to understand the shape of concentration–time profiles, it does not explain quantitative differences in reaction rates. Several important questions remain: - For two bimolecular reactions, which would we expect to be faster, and by how much? - Can we predict rate constants \\(k\\) (and how they vary with temperature) without experimental data? While we have discussed the Arrhenius equation, \\(k = A_0\\mathrm{e}^{-\\Delta E/RT}\\), this is an approximate empirical relationship that requires experimental data to determine \\(A_0\\) and \\(\\Delta E\\). To move beyond empirical descriptions, we need microscopic theories that can make quantitative predictions of reaction rates. In this course, we will examine two such theories: Collision Theory (this lecture)—focuses on gas-phase bimolecular reactions, treating molecules as hard spheres Transition State Theory (lectures 6–9)—considers formation of activated complexes for all types of reactions 5.2 Fundamentals of Collision Theory Collision theory provides one of the simplest microscopic models of reaction rates, specifically for gas-phase bimolecular reactions of the form: \\[\\mathrm{A} + \\mathrm{B} \\rightarrow \\mathrm{P}\\] For such reactions, we expect a rate law of the form \\(\\nu = k[\\mathrm{A}][\\mathrm{B}]\\), but what determines the value of \\(k\\)? 5.2.1 Basic Principles and Assumptions Building on the kinetic theory of gases, collision theory makes two key assumptions: Molecules behave as hard spheres Molecules must collide to react The overall reaction rate is then: rate = rate of collisions × fraction of “successful” collisions 5.2.2 Collision Frequency To determine the rate of collisions, we need to calculate how often molecules A and B encounter each other in the gas phase. Consider two molecules with radii \\(r_\\mathrm{A}\\) and \\(r_\\mathrm{B}\\) moving with velocities \\(v_\\mathrm{A}\\) and \\(v_\\mathrm{B}\\). We can simplify this problem by working in the reference frame of molecule A, where A appears stationary and B molecules move with the relative velocity \\(v = |v_\\mathrm{B} - v_\\mathrm{A}|\\). A collision occurs when the centres of the two molecules come within a distance \\(d = r_\\mathrm{A} + r_\\mathrm{B}\\) of each other. As shown in Figure 5.1, molecule A (green) can be thought of as sitting at the centre of a cylindrical “target zone”. Any molecule B (orange) whose centre lies within this cylinder will collide with A. Figure 5.1: Collision geometry in the reference frame of molecule A. Molecule A (teal) sits at the centre of a cylindrical volume of radius \\(d = r_\\mathrm{A} + r_\\mathrm{B}\\) (shown as dashed outline). As time progresses by \\(t\\), this cylinder extends by length \\(v \\times t\\), where \\(v\\) is the relative velocity. Molecules B (orange) with centres inside this cylinder will collide with A; those outside will not. The dimensions of this collision cylinder are: Radius = \\(d = (r_\\mathrm{A} + r_\\mathrm{B})\\) Cross-sectional area = \\(S = \\pi d^2\\) Length swept in time \\(t\\) = \\(vt\\) (where \\(v\\) is the relative velocity) Volume swept in time \\(t\\) = \\(vt \\times \\pi d^2\\) The volume swept per unit time is therefore \\(v\\pi d^2\\). Any molecule B whose centre lies within this volume will collide with molecule A. If there are \\(N_\\mathrm{B}\\) molecules of B in total volume \\(V\\), the number of B molecules per unit volume is \\(N_\\mathrm{B}/V\\), and the number of collisions that one molecule A makes per unit time is: \\[\\frac{N_\\mathrm{B}}{V}v\\pi d^2\\] To find the total collision frequency per unit volume, we multiply by the concentration of A molecules. This gives the collision frequency per unit volume (\\(Z&#39;\\)): \\[Z&#39; = \\frac{N_\\mathrm{A}N_\\mathrm{B}}{V^2}v\\pi d^2\\] where \\(N_\\mathrm{A}\\) and \\(N_\\mathrm{B}\\) are the total numbers of molecules of each species in volume \\(V\\). 5.2.3 Average Relative Velocity In our expression for collision frequency, we used the relative velocity \\(v\\) between molecules A and B. However, in a gas at temperature \\(T\\), molecules have a distribution of velocities—not all molecules move at the same speed. To calculate the collision frequency, we need the average relative velocity. From the kinetic theory of gases, the average relative velocity between molecules A and B depends on both temperature and the reduced mass of the colliding pair. The reduced mass \\(\\mu\\) is defined as: \\[\\mu = \\frac{m_\\mathrm{A}m_\\mathrm{B}}{m_\\mathrm{A} + m_\\mathrm{B}}\\] The average relative velocity is then: \\[\\langle v \\rangle = \\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\] This expression shows that: Lighter molecules (smaller \\(\\mu\\)) move faster on average and collide more frequently Higher temperatures increase molecular speeds and collision rates The velocity increases with the square root of temperature Substituting this average velocity into our collision frequency expression gives: \\[Z&#39; = \\frac{N_\\mathrm{A}N_\\mathrm{B}}{V^2}\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\] This is the collision frequency per unit volume for molecules A and B in a gas at temperature \\(T\\). 5.3 From Collisions to Reaction Rates 5.3.1 Energetic Requirements for Reaction Not every collision between molecules A and B leads to reaction. The collision frequency \\(Z&#39;\\) tells us how often molecules encounter each other, but only a fraction of these collisions have sufficient energy to overcome the activation barrier and form products. In collision theory, we assume that molecules must possess a minimum relative kinetic energy \\(E_\\mathrm{a}\\) (the activation energy) for reaction to occur. This threshold energy is needed to break bonds and rearrange atoms during the collision. The question then becomes: what fraction of molecular collisions have relative kinetic energy greater than or equal to \\(E_\\mathrm{a}\\)? The answer comes from the Maxwell-Boltzmann distribution of molecular speeds. In a gas at temperature \\(T\\), the relative kinetic energies of colliding molecules follow a probability distribution that depends on temperature, as shown in Figure 5.2. Figure 5.2: Maxwell-Boltzmann distribution of relative kinetic energies for molecular collisions at two temperatures. The shaded regions show the fraction of collisions with energy \\(E \\geq E_\\mathrm{a}\\). At higher temperature (orange, 600 K), the distribution broadens and shifts to higher energies, increasing the fraction of collisions with sufficient energy to react. The fraction of successful collisions is given by \\(P(E \\geq E_\\mathrm{a}) = \\exp(-E_\\mathrm{a}/RT)\\). The figure shows two key features: Temperature dependence: At higher temperature (orange curve, 600 K), the distribution is broader and shifted to higher energies compared to lower temperature (blue curve, 300 K). This means a larger fraction of collisions have energy exceeding \\(E_\\mathrm{a}\\). Exponential tail: The shaded region represents collisions with \\(E \\geq E_\\mathrm{a}\\). The fraction of collisions in this high-energy tail follows directly from the kinetic theory of gases :1 \\[P(E \\geq E_\\mathrm{a}) = \\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] 5.3.2 The Complete Rate Expression Combining the collision frequency with the probability that a collision has sufficient energy, we obtain: \\[\\text{rate} = Z&#39; \\times P(E \\geq E_\\mathrm{a})\\] Substituting our expressions for \\(Z&#39;\\) and \\(P(E \\geq E_\\mathrm{a})\\) gives: \\[\\text{rate} = \\frac{N_\\mathrm{A}N_\\mathrm{B}}{V^2}\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] To express this in the familiar form of a rate law, we convert from numbers of molecules to concentrations. The concentration of A is \\([\\mathrm{A}] = N_\\mathrm{A}/V\\) and similarly \\([\\mathrm{B}] = N_\\mathrm{B}/V\\), giving: \\[\\text{rate} = \\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)[\\mathrm{A}][\\mathrm{B}]\\] This has exactly the form we expect for a bimolecular elementary reaction: \\[\\begin{equation} \\text{rate} = k[\\mathrm{A}][\\mathrm{B}] \\end{equation}\\] where the rate is first-order with respect to A, first-order with respect to B, and second-order overall. The rate constant predicted by collision theory is: \\[\\begin{equation} k = \\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.1} \\end{equation}\\] This expression shows how collision theory connects the macroscopic rate constant to microscopic molecular properties: the collision cross-section (\\(\\pi d^2\\)), the molecular masses (through \\(\\mu\\)), the temperature, and the activation energy. 5.3.3 The Steric Factor Our collision theory expression predicts that the rate constant should be: \\[k = \\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] When we compare this theoretical prediction with experimental measurements, we find a systematic discrepancy: collision theory typically overestimates reaction rates, sometimes by several orders of magnitude. This tells us that our model of molecules as hard spheres is too simple—there is something missing from our picture of how molecules react. To account for this discrepancy, we introduce an empirical correction factor \\(P\\), called the steric factor. The steric factor is defined as the ratio of the experimentally measured pre-exponential factor to the theoretical value predicted by collision theory: \\[\\begin{equation} P = \\frac{A_\\mathrm{exp}}{A_\\mathrm{th}} \\tag{5.2} \\end{equation}\\] where \\(A_\\mathrm{exp}\\) comes from fitting the Arrhenius equation to experimental data, and \\(A_\\mathrm{th} = \\pi d^2\\sqrt{8k_\\mathrm{B}T/(\\pi\\mu)}\\) is the pre-exponential factor predicted by collision theory. By including the steric factor, we obtain a revised expression for the rate constant, \\(k\\): \\[\\begin{equation} k = P\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.3} \\end{equation}\\] Table 5.1 shows experimental pre-exponential factors, collision theory predictions, and the resulting steric factors for several representative reactions. Table 5.1: Comparison of experimental and theoretical pre-exponential factors for representative bimolecular gas-phase reactions. The steric factor \\(P = A_\\mathrm{exp}/A_\\mathrm{th}\\) quantifies how much collision theory overestimates (\\(P &lt; 1\\)) or underestimates (\\(P &gt; 1\\)) the reaction rate. Reaction \\(A_\\mathrm{exp}\\) / 10\\(^{11}\\) dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\) \\(A_\\mathrm{th}\\) / 10\\(^{11}\\) dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\) \\(P\\) K + Br\\(_2\\) \\(\\rightarrow\\) KBr + Br 10 2.1 4.8 CH\\(_3\\) + CH\\(_3\\) \\(\\rightarrow\\) C\\(_2\\)H\\(_6\\) 0.24 1.1 0.22 2NOCl \\(\\rightarrow\\) 2NO + Cl\\(_2\\) 0.094 0.59 0.16 H\\(_2\\) + C\\(_2\\)H\\(_4\\) \\(\\rightarrow\\) C\\(_2\\)H\\(_6\\) 1.24 \\(\\times\\) 10\\(^{-5}\\) 7.3 1.7 \\(\\times\\) 10\\(^{-6}\\) The data in Table 5.1 show two key features. First, for most reactions, collision theory overestimates the reaction rate. The reaction 2NOCl → 2NO + Cl2 has \\(P = 0.16\\), meaning the experimental rate is only about one-sixth of the collision theory prediction. Second, the steric factor decreases systematically as molecular complexity increases. For methyl radical combination we find \\(P = 0.22\\), while for the hydrogenation of ethene, $P = 1.7 ^{-6}—a difference of five orders of magnitude. 5.3.4 Physical Interpretation We can interpret these observations in terms of molecular orientation requirements. For a reaction to occur, it is not sufficient for the reactants to have sufficient relative kinetic energy—molecules must also come together in specific orientations. The steric factor \\(P\\) can be interpreted as representing how likely it is that a collision occurs with a geometry suitable for reaction. This interpretation explains why collision theory typically overestimates reaction rates: most collisions, even those with sufficient energy, involve unsuitable orientations. With this interpretation of the steric factor, we can understand the systematic decrease in \\(P\\) with molecular complexity as reflecting increasingly stringent geometric constraints. For larger, more complex molecules, only a small fraction of all possible collision orientations have the correct geometry for reaction. The hydrogenation of ethene provides an extreme example: H2 must approach the C=C electron density in a specific orientation and cannot react if blocked by the CH2 end-groups, leading to \\(P = 1.7 \\times 10^{-6}\\). Figure 5.3: Geometric constraints in the hydrogenation of ethene. H\\(_2\\) (green) must approach the C=C double bond from above (arrow shows allowed approach) to react. Approach from the side is blocked by the CH\\(_2\\) groups, preventing reaction even if the collision has sufficient energy. This stringent geometric requirement leads to \\(P = 1.7 \\times 10^{-6}\\). While this general principle explains the data where \\(P &lt; 1\\), the K + Br2 reaction appears to contradict our conceptual model. Here, \\(P = 4.8\\)—reactions occur more frequently than collision theory predicts. This enhanced reactivity arises from the “harpoon mechanism”: during the approach of K and Br2, an electron can transfer from potassium to bromine at relatively large separation, creating K+ and Br2− ions. The resulting electrostatic attraction pulls the reactants together and effectively increases the collision cross-section beyond what we would predict from hard-sphere radii. This demonstrates that our simple hard-sphere model can fail in both directions—it can underestimate rates when long-range forces are important, just as it typically overestimates rates when orientation constraints matter. Figure 5.4: The harpoon mechanism in the K + Br\\(_2\\) reaction. During approach, an electron transfers from potassium to bromine at relatively large separation, creating K\\(^+\\) and Br\\(_2^-\\) ions. The resulting electrostatic attraction increases the effective collision cross-section beyond what hard-sphere radii predict. 5.4 Relationship to the Arrhenius Equation The rate constant derived from collision theory has a similar form to the empirical Arrhenius equation. From collision theory: \\[\\begin{equation} k = P\\pi d^2\\left(\\frac{8k_\\mathrm{B}T}{\\pi\\mu}\\right)^{1/2}\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.4} \\end{equation}\\] The Arrhenius equation: \\[\\begin{equation} k = A_0\\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right) \\tag{5.5} \\end{equation}\\] This comparison provides physical insight into the meaning of the Arrhenius parameters: The activation energy \\(E_\\mathrm{a}\\) in the Arrhenius equation can be interpreted as the minimum relative kinetic energy that colliding molecules must possess for reaction to occur. This threshold energy is needed to overcome the potential energy barrier to reaction. The pre-exponential factor \\(A_0\\) represents a normalized collision frequency. The collision theory expression shows that this frequency depends on: The collision cross-section (\\(\\pi d^2\\)) The average relative velocity of molecules (\\(\\propto \\sqrt{T/\\mu}\\)) A steric factor \\(P\\) that accounts for orientation requirements Therefore, while the Arrhenius equation was originally proposed as an empirical relationship, collision theory provides a theoretical foundation for its functional form and offers molecular-level interpretations of its parameters. However, we should note that this interpretation is strictly valid only for gas-phase bimolecular reactions. For more complex reactions, particularly in solution, the physical meaning of the Arrhenius parameters becomes less clear, and we need more sophisticated theories to understand their molecular basis. 5.5 Limitations of Collision Theory as a Predictive Framework Collision theory works reasonably well for simple molecules but typically overestimates reaction rates for complex molecules. Two key limitations prevent collision theory from serving as a fully predictive framework: The activation energy E\\(\\mathrm{a}\\) appears as an arbitrary “threshold energy” that molecules must possess to react. While we can measure this energy experimentally, the theory provides no insight into how \\(E_\\mathrm{a}\\) varies between different reactions. While we can determine the steric factor \\(P\\) by comparing experimental and theoretical rate constants, we have no quantitative theory to predict its value. This means we cannot predict absolute rate constants for new reactions without experimental data. The derivation of this result from the Maxwell-Boltzmann distribution is given in Appendix B.↩︎ "],["lecture6.html", "Lecture 6 Transition State Theory 6.1 A Molecular Theory of Reaction Rates 6.2 Basic Principles of Transition State Theory 6.3 Mathematical Development of Transition State Theory 6.4 Relationship to the Arrhenius Equation 6.5 Enthalpy of Activation 6.6 Reconciling Transition State Theory with Collision Theory 6.7 Entropy of Activation", " Lecture 6 Transition State Theory 6.1 A Molecular Theory of Reaction Rates Collision theory explains reaction rates using a simple model of colliding spheres. While this works for some gas-phase reactions, it cannot predict steric factors or explain systematic trends in activation energies. We need a more sophisticated approach. For a reaction A + B → P, molecules must pass over an energy barrier before forming products. The reaction coordinate diagram shows this energy profile, from reactants through to products. The point at the highest point of the energy barrier is called the transition state; at this point the reacting molecules form a specific arrangement called the activated complex2, in which bonds are partially broken and new bonds are starting to form. Transition state theory provides a framework for analyzing this activated complex and using it to predict reaction rates. Figure 6.1: A reaction coordinate diagram for the reaction A + B → P. The energy profile shows the barrier that must be crossed as reactants are converted to products. The peak of this barrier corresponds to the transition state configuration, and the collection of molecules at the transition state form the activated complex, C\\(^\\ddagger\\). 6.2 Basic Principles of Transition State Theory Transition state theory treats the overall reaction A + B → P as occurring in two steps. First, the reactants A and B combine to form the activated complex C\\(^{\\ddagger}\\). This complex can either fall apart back to reactants or go on to form products. The theory makes a key assumption: we can treat the activated complex as being in equilibrium with the reactants, even though C\\(^{\\ddagger}\\) is inherently unstable. We call this a pseudo-equilibrium to reflect this special status. The second step is the conversion of C\\(^{\\ddagger}\\) to products, which we assume occurs with a characteristic rate constant \\(k^{\\ddagger}\\). This is a first-order process — the rate depends only on the concentration of the activated complex: \\[\\nu = \\frac{\\mathrm{d}[\\mathrm{P}]}{\\mathrm{d}t} = k^{\\ddagger}[\\mathrm{C}^{\\ddagger}]\\] We can write the complete process as: \\[\\begin{equation} \\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^{\\ddagger} \\xrightarrow{k^{\\ddagger}} \\mathrm{P} \\tag{6.1} \\end{equation}\\] 6.3 Mathematical Development of Transition State Theory To develop our rate equation, we begin by considering the pseudo-equilibrium between reactants and the activated complex. We can define a pseudo-equilibrium constant: \\[\\begin{equation} K^{\\ddagger} = \\frac{[\\mathrm{C}^{\\ddagger}]c^\\circ}{[\\mathrm{A}][\\mathrm{B}]} \\tag{6.2} \\end{equation}\\] where \\(c^\\circ\\) = 1 mol dm−3 is the standard concentration.3 This allows us to express the concentration of the activated complex in terms of reactant concentrations: \\[\\begin{equation} [\\mathrm{C}^{\\ddagger}] = (K^{\\ddagger}/c^\\circ)[\\mathrm{A}][\\mathrm{B}] \\tag{6.3} \\end{equation}\\] Since we treat the formation of the activated complex as a pseudo-equilibrium, we can apply standard thermodynamic relationships. The equilibrium constant \\(K^{\\ddagger}\\) relates to the activation Gibbs energy through: \\[\\begin{equation} \\Delta G^{\\ddagger} = -RT\\ln(K^{\\ddagger}) \\tag{6.4} \\end{equation}\\] We can then use the standard relationship \\(\\Delta G^\\ddagger = \\Delta H^\\ddagger - T \\Delta S^\\ddagger\\) to separate \\(K^\\ddagger\\) into enthalpic and entropic terms: \\[\\begin{equation} K^{\\ddagger} = \\mathrm{e}^{-\\Delta G^{\\ddagger}/RT} = \\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}\\mathrm{e}^{\\Delta S^{\\ddagger}/R} \\tag{6.5} \\end{equation}\\] From our second assumption, the rate of product formation is proportional to the concentration of the activated complex: \\[\\begin{equation} \\nu = k^{\\ddagger}[\\mathrm{C}^{\\ddagger}] = \\frac{k^{\\ddagger}}{c^{\\circ}}[\\mathrm{A}][\\mathrm{B}]\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT} \\tag{6.6} \\end{equation}\\] This expression is known as the Eyring equation, and has the form of a second-order rate law with rate constant: \\[\\begin{equation} k = \\frac{k^{\\ddagger}}{c^{\\circ}}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT} \\tag{6.7} \\end{equation}\\] 6.4 Relationship to the Arrhenius Equation We can understand how transition state theory connects to experimental observations by comparing the rate constant expression with the Arrhenius equation: From transition state theory: \\[\\begin{equation} k = \\frac{k^{\\ddagger}}{c^{\\circ}}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT} \\tag{6.8} \\end{equation}\\] The Arrhenius equation: \\[\\begin{equation} k = A\\mathrm{e}^{-E_\\mathrm{a}/RT} \\tag{5.5} \\end{equation}\\] This comparison reveals two important correspondences: The activation enthalpy \\(\\Delta H^{\\ddagger}\\) plays a similar role to the Arrhenius activation energy \\(E_\\mathrm{a}\\). The pre-exponential factor \\(A\\) corresponds to \\(\\frac{k^{\\ddagger}}{c^{\\circ}}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\). Like collision theory, transition state theory provides a molecular-level interpretation of the Arrhenius parameters. However, transition state theory offers additional insight by separating the activation barrier into enthalpic (\\(\\Delta H^{\\ddagger}\\)) and entropic (\\(\\Delta S^{\\ddagger}\\)) contributions, helping explain systematic variations in reactivity across related compounds. 6.5 Enthalpy of Activation The enthalpy of activation \\(\\Delta H^{\\ddagger}\\) represents the enthalpic contribution to forming the activated complex. For a simple reaction where C breaks an A–B bond to form B–C, examining what happens at the transition state reveals why this enthalpy change varies systematically between related reactions. In the activated complex, the original A–B bond is almost completely broken, while the new B–C bond has only started to form. This means \\(\\Delta H^{\\ddagger}\\) depends primarily on the strength of the bond being broken. The strength of the bond being formed has much less effect, since this bond is still weak in the transition state. This principle helps explain trends in activation energies for a family of related reactions. Consider these examples involving H and Br: \\[\\begin{align*} \\mathrm{H–H} + \\mathrm{H} &amp;\\longrightarrow \\mathrm{H} + \\mathrm{H–H} &amp; E_\\mathrm{a} &amp;= +39~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{H–H} + \\mathrm{Br} &amp;\\longrightarrow \\mathrm{H} + \\mathrm{H–Br} &amp; E_\\mathrm{a} &amp;= +82~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{Br–H} + \\mathrm{H} &amp;\\longrightarrow \\mathrm{Br} + \\mathrm{H–H} &amp; E_\\mathrm{a} &amp;= +12~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{Br–Br} + \\mathrm{H} &amp;\\longrightarrow \\mathrm{Br} + \\mathrm{Br–H} &amp; E_\\mathrm{a} &amp;= +4~\\mathrm{kJ~mol^{-1}} \\end{align*}\\] To understand these trends, we need to consider the bond dissociation energies: \\[\\begin{align*} \\mathrm{H–H}: &amp; ~E_\\mathrm{d} = +436~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{H–Br}: &amp; ~E_\\mathrm{d} = +366~\\mathrm{kJ~mol^{-1}} \\\\ \\mathrm{Br–Br}: &amp; ~E_\\mathrm{d} = +193~\\mathrm{kJ~mol^{-1}} \\end{align*}\\] The trends in activation energy can be explained by: The first two reactions involve breaking H–H bonds (highest \\(E_\\mathrm{d}\\)) → highest \\(E_\\mathrm{a}\\) values Between these two: H–H + H forms H–H (more favorable) H–H + Br forms H–Br (less favorable) Therefore \\(E_\\mathrm{a}\\) is lower for H–H + H The remaining reactions follow the trend in bond strength being broken: Breaking H–Br (\\(E_\\mathrm{a} = +12~\\mathrm{kJ~mol^{-1}}\\)) Breaking Br–Br (\\(E_\\mathrm{a} = +4~\\mathrm{kJ~mol^{-1}}\\)) 6.6 Reconciling Transition State Theory with Collision Theory At first glance, Collision theory and transition state theory can seem to give different pictures of activation energy. In collision theory, \\(E_\\mathrm{a}\\) represents a minimum kinetic energy molecules must have to react. In transition state theory, \\(\\Delta H^{\\ddagger}\\) represents the energy needed to distort and partially break bonds bonds in the activated complex. We can connect these views by following the energy through a reactive collision. Initially, the molecules approach with kinetic energy at least equal to \\(E_\\mathrm{a}\\). As they collide, this kinetic energy transforms into potential energy, with the molecular geometry distorting to form the activated complex. Here, the initial kinetic energy has become the energy stored in partially broken and formed bonds — our \\(\\Delta H^{\\ddagger}\\). By energy conservation, these energies must be approximately equal. The two theories thus describe the same process from different perspectives: collision theory focuses on the keinetic energy molecules must have before they collide, while transition state theory considers how this energy is used in making and breaking bonds. 6.7 Entropy of Activation We have seen that transition state theory provides a molecular interpretation of the Arrhenius pre-exponential factor \\(A\\) in terms of an entropy of activation \\(\\Delta S^{\\ddagger}\\). To understand what this entropy term means and what determines its magnitude, we need to think carefully about what entropy means at a molecular level. 6.7.1 Understanding Molecular Entropy While entropy is often simply described as a measure of “disorder”, this description can be misleading. For many chemical reactions, simple arguments based on relative “disorder” fail to predict even qualitative behaviour. This becomes particularly apparent when considering gas-phase reactions: both reactants and products exist as freely moving molecules, so which state is more “disordered”? A more useful framework considers entropy in terms of molecular freedom and statistical likelihood. Systems with greater freedom have higher entropy than more constrained systems, and molecular arrangements that are statistically more likely have higher entropy than less likely arrangements. The spontaneous expansion of an ideal gas illustrates these ideas. An ideal gas expands to fill its container despite no change in internal energy (\\(\\Delta U = 0\\)) or enthalpy (\\(\\Delta H = 0\\), since \\(pV = nRT\\)). This process occurs spontaneously because the expanded state has higher entropy: gas molecules have more freedom to move through a larger volume, and an even distribution throughout the available space is statistically more likely than having all molecules confined to a smaller region. 6.7.2 Entropy of Activation for Bimolecular Reactions For a gas-phase bimolecular reaction, forming the activated complex introduces new constraints on molecular motion: \\[\\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^{\\ddagger}\\] Each molecule in the gas phase has three translational degrees of freedom—the molecules are free to move along the \\(x\\), \\(y\\), and \\(z\\) axes, independently of the motion of the other molecules in the system. The reactants A and B therefore have six translational degrees of freedom between them. When these molecules combine to form the activated complex, however, we have just three translational degrees of freedom, since \\(\\mathrm{C}^{\\ddagger}\\) moves as a single unit through space. This loss of translational freedom corresponds to a decrease in entropy. For gas-phase bimolecular reactions, \\(\\Delta S^{\\ddagger}\\) is therefore always negative, reflecting the increased constraints imposed when forming the activated complex. In our treatment using 2D reaction coordinate diagrams, we represent the transition state as a single point at the peak of the energy barrier. In reality, for a molecular system with many degrees of freedom, the transition state is a dividing surface on the multidimensional potential energy surface. The “activated complex” comprises all molecular configurations on this dividing surface.↩︎ Many basic treatments of transition state theory omit \\(c^{\\circ}\\) since it equals 1 under standard conditions. Including it ensures that \\(K^\\ddagger\\) is correctly defined as dimensionless, and that \\(k\\) has the correct units for a second-order rate constant of dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\).↩︎ "],["lecture7.html", "Lecture 7 Molecular Freedom and Entropy of Activation 7.1 Qualitative Analysis: Atomic and Molecular Reactions 7.2 Thermodynamic Origin of the Steric Factor 7.3 Molecular Degrees of Freedom 7.4 A Simple Example: Atom-Atom Reaction 7.5 Energy Spacings and Entropy 7.6 Towards Quantitative Predictions", " Lecture 7 Molecular Freedom and Entropy of Activation In Lecture 6, we began thinking about the entropy of activation \\(\\Delta S^{\\ddagger}\\) in terms of changes in molecular freedom when forming the activated complex. We can develop this idea to understand systematic variations in the Arrhenius pre-exponential factor between different bimolecular reactions. We begin with a qualitative analysis before examining the molecular details more carefully. 7.1 Qualitative Analysis: Atomic and Molecular Reactions Consider first a bimolecular reaction between two atoms. As discussed in the previous lecture, forming the activated complex reduces the number of translational degrees of freedom from 6 (3 for each atom) to 3. This loss of translational freedom corresponds to a loss of translational entropy, making \\(\\Delta S^{\\ddagger}\\) negative. Now consider a reaction between two diatomic molecules. Each reactant molecule has 3 degrees of translational freedom and 2 degrees of rotational freedom. The activated complex has 3 translational degrees of freedom and 3 rotational degrees of freedom. Forming the activated complex now involves a decrease in the numbers of translational and rotational degrees of freedom. And we, therefore, might expect a larger, more negative, entropy of activation for this reaction than for the simpler case involving two atoms. Figure 7.1: Comparing entropy changes when forming the activated complex. Left: For atomic reactions, forming the activated complex involves only loss of translational entropy. Right: For molecular reactions, forming the activated complex involves loss of both translational and rotational entropy. This additional entropic cost makes \\(\\Delta S^{\\ddagger}\\) more negative for molecular reactions, leading to smaller pre-exponential factors. 7.2 Thermodynamic Origin of the Steric Factor In our analysis of collision theory in Lecture 5, we saw that reactions between more complex molecules typically have smaller steric factors. We interpreted this as reflecting the need for specific molecular orientations during collision. Transition state theory provides a thermodynamic perspective on this observation: in general, we can expect more complex reactant molecules to lose more molecular freedom when forming the activated complex, leading to a more negative \\(\\Delta S^{\\ddagger}\\) and consequently a smaller pre-exponential factor \\(A\\). While this idea, that degree to which we lose translational and rotational degrees of freedom on forming the activated complex, is broadly correct, it is incomplete: we have not considered vibrational degrees of freedom, and we do not have a framework that can predict differences in pre-exponential factor between two molecular reactions. To proceed towards a more quantitative treatment of entropy of activation, we need a more complete accounting of all molecular degrees of freedom in the reactants and activated complex. 7.3 Molecular Degrees of Freedom To analyse molecular freedom systematically, we begin by counting the degrees of freedom available to a molecule containing \\(N\\) atoms. Each atom has three degrees of freedom, corresponding to motion in three dimensions. The total number of atomic degrees of freedom is therefore \\(3N\\). These atomic motions can be combined to give \\(3N\\) molecular degrees of freedom that describe the collective motion of the molecule.4 Molecular degrees of freedom can be classified into three types: Translational motion of the entire molecule through space. Rotation of the molecule about its principal axes. Vibrational motion where atoms move relative to each other. A linear molecule has: 3 translational degrees of freedom. 2 rotational degrees of freedom. \\(3N-5\\) vibrational degrees of freedom. A non-linear molecule has: 3 translational degrees of freedom. 3 rotational degrees of freedom. \\(3N-6\\) vibrational degrees of freedom. 7.4 A Simple Example: Atom-Atom Reaction We can partition \\(\\Delta S^{\\ddagger}\\) into contributions from different degrees of freedom. Consider the simplest case: a reaction between two atoms, A + B, forming an activated complex C‡: \\[\\begin{equation} \\mathrm{A} + \\mathrm{B} \\longrightarrow \\mathrm{C}^{\\ddagger} \\end{equation}\\] Let us count the degrees of freedom for the reactants and activated complex. Reactants (two separate atoms): Each atom can move independently in three-dimensional space, giving 3 translational degrees of freedom per atom. Since we have two atoms, the total translational degrees of freedom is 3 + 3 = 6. Atoms are point masses, so they have no rotational degrees of freedom (rotation requires at least two atoms held at a fixed distance). Similarly, single atoms cannot vibrate. Therefore, the reactants have 6 translational degrees of freedom and nothing else. Activated complex (diatomic species): The activated complex C\\(^\\ddagger\\) is a diatomic species where the two atoms are connected. This single entity moves through space as a unit, giving 3 translational degrees of freedom for the centre of mass of the complex. The complex can rotate about axes perpendicular to the bond connecting the two atoms. For a linear molecule, there are 2 rotational degrees of freedom (rotation about the bond axis itself does not change the molecule’s orientation, so only the two perpendicular axes count). Finally, the two atoms in the complex can move relative to each other along the bond—stretching and compressing. This gives 1 vibrational degree of freedom, which corresponds to motion through the transition state along the reaction coordinate. The total is therefore 3 + 2 + 1 = 6 degrees of freedom. Figure 7.2: Counting degrees of freedom for the reaction A + B \\(\\longrightarrow\\) C\\(^{\\ddagger}\\). The total number of degrees of freedom (trans + rot + vib) is conserved: both reactants and activated complex have 6 degrees of freedom. However, the character of these degrees of freedom changes, with translational motion converted into rotational and vibrational motion. The total number of degrees of freedom is preserved: both the reactants and the activated complex have 6 degrees of freedom. So why is \\(\\Delta S^{\\ddagger} \\neq 0\\)? The answer lies in understanding that different types of molecular motion contribute very differently to entropy. 7.5 Energy Spacings and Entropy Quantum mechanics tells us that the energy levels for molecular motion are quantised. The spacing between these levels varies significantly with the type of motion: \\[\\begin{equation} \\Delta \\epsilon_\\mathrm{trans} \\ll \\Delta \\epsilon_\\mathrm{rot} &lt; \\Delta \\epsilon_\\mathrm{vib} \\end{equation}\\] To understand why this matters for entropy, we need the statistical mechanical foundation provided by Boltzmann’s equation: \\[\\begin{equation} S = k \\ln W \\end{equation}\\] where \\(W\\) represents the number of thermally accessible microstates—the different possible arrangements available to the system at a given energy. This equation tells us that entropy increases with the number of ways energy can be distributed across the available states. The hierarchy of energy spacings directly determines \\(W\\) for each type of motion. When energy levels are closely spaced, there are many thermally accessible states at typical temperatures—many different ways to distribute the available energy across the system, giving large \\(W\\) and hence high entropy. Conversely, when energy levels are widely spaced, only a few low-lying states can be populated, giving few ways to distribute the energy, small \\(W\\), and low entropy. Figure 7.3: Energy level diagrams for different types of molecular motion. Small energy spacing (left) gives many thermally accessible energy levels and many ways to distribute energy, corresponding to high entropy. Large energy spacing (right) gives few thermally accessible energy levels and few ways to distribute energy, corresponding to low entropy. For molecular motion, translational energy levels are narrowly spaced and appear almost continuous. At room temperature, an enormous number of translational states are accessible, giving very high entropy. Rotational energy levels are more widely spaced, with fewer accessible states. Vibrational energy levels are spaced more widely still, with only a few low-lying states thermally accessible at typical temperatures. This leads to the entropy hierarchy: \\[\\begin{equation} S^{\\ddagger}_\\mathrm{trans} \\gg S^{\\ddagger}_\\mathrm{rot} &gt; S^{\\ddagger}_\\mathrm{vib} \\end{equation}\\] Figure 7.4: The hierarchy of energy spacings for translational, rotational, and vibrational motion. The shaded region shows the thermally accessible states at typical temperatures. 7.6 Towards Quantitative Predictions The thermodynamic framework we have developed here provides us with a molecular perspective on the entropy of activation, \\(\\Delta S^{\\ddagger}\\). When reactants come together to form the activated complex, high-entropy molecular degrees of freedom (translation and rotation) are converted into low-entropy degrees of freedom (rotation and vibration), giving an overall negative \\(\\Delta S^{\\ddagger}\\). To make quantitative predictions about pre-exponential factors for specific reactions, we need to estimate these entropy changes numerically. Recall from Lecture 6 that the pre-exponential factor is: \\[\\begin{equation} A = \\frac{k^{\\ddagger}}{c^\\circ} \\exp\\left(\\frac{\\Delta S^{\\ddagger}}{R}\\right) \\end{equation}\\] In Lecture 8, we will estimate both components—the entropy change \\(\\Delta S^{\\ddagger}\\) and the rate constant \\(k^{\\ddagger}\\)—to calculate pre-exponential factors for real reactions. The \\(3N\\) molecular degrees of freedom are constructed as orthogonal linear combinations of the \\(3N\\) atomic degrees of freedom that are consistent with molecular symmetry. The details of this transformation from atomic to molecular degrees of freedom are part of the S2 Group Theory course↩︎ "],["lecture8.html", "Lecture 8 Estimating Pre-exponential Factors 8.1 From Molecular Freedom to Reaction Rates 8.2 The Rate of Barrier Crossing 8.3 Mathematical Development 8.4 Analysis of Molecular Systems 8.5 Applications and Predictive Power 8.6 Connection to Collision Theory 8.7 Limitations in Pre-exponential Factor Estimation", " Lecture 8 Estimating Pre-exponential Factors 8.1 From Molecular Freedom to Reaction Rates In Lecture 7, we examined how molecular degrees of freedom change when forming the activated complex, and how these changes determine the entropy of activation, \\(\\Delta S^\\ddagger\\). We saw that forming the activated complex typically transforms high-entropy translational and rotational degrees of freedom into more constrained rotational and vibrational modes. Let us now develop this molecular-level picture into a quantitative framework for predicting reaction rates. To understand how molecular motion leads to reaction, we must look more carefully at what the reaction coordinate means. Consider a simple atom-transfer reaction A + BC → AB + C. For simplicity, we assume the reaction proceeds through a collinear arrangement of the three atoms. We can then describe the molecular geometry using two key distances: the A–B distance (\\(r_\\mathrm{AB}\\)) and the B–C distance (\\(r_\\mathrm{BC}\\)). Figure 8.1: The reaction coordinate for a bimolecular exchange reaction A + BC → AB + C. Left: The two key bond distances that define the reaction coordinate. Right: The potential energy surface as a function of \\(r_{\\mathrm{AB}}\\) and \\(r_{\\mathrm{BC}}\\). Five key configurations are marked on the surface: reactants (top left), products (bottom right), transition state (centre saddle point), and two high-energy configurations at the remaining corners. The reaction coordinate (pink line) follows the minimum energy pathway connecting reactants, transition state, and products. Figure 8.1 shows the potential energy surface for this reaction. At the reactants (top left), \\(r_\\mathrm{AB}\\) is small (corresponding to a strong A–B bond) whilst \\(r_\\mathrm{BC}\\) is large (C is far from the AB molecule). Conversely, at the products (bottom right), \\(r_\\mathrm{AB}\\) is large (A has separated) whilst \\(r_\\mathrm{BC}\\) is small (a strong B–C bond has formed). Between these two stable configurations, the system must pass through the transition state—the dividing surface that separates reactant-like from product-like configurations. The lowest-energy point on this dividing surface is the saddle point (centre of the surface), where both \\(r_\\mathrm{AB}\\) and \\(r_\\mathrm{BC}\\) have intermediate values. The molecular arrangement at this saddle point, with the AB bond partially broken and the BC bond partially formed, is the activated complex. The remaining two corners represent high-energy configurations the system avoids: all atoms separated (top-right) or impossibly compressed together (bottom-left). The reaction coordinate (pink line) follows the minimum-energy pathway that connects reactants to products through the saddle point, avoiding these unfavourable regions. 8.2 The Rate of Barrier Crossing To describe how fast activated complexes convert to products (\\(k^\\ddagger\\)), we need to think about what happens at the transition state. Consider again our simple atom-transfer reaction A + BC → AB + C, shown in Figure 8.2. Figure 8.2: Motion across the transition state for the reaction A + BC \\(\\to\\) AB + C. Left: The molecular geometries along the reaction coordinate, showing reactants (top), the transition state activated complex [A⋯B⋯C]\\(^\\ddagger\\) with both bonds partially formed (centre), and products (bottom). Right: A zoomed-in view of the saddle point region from Figure 8.1, showing the transition state on the potential energy surface. Motion along the reaction coordinate (pink line) corresponds to vibration-like motion through the transition state, with frequency \\(\\nu^\\ddagger = k_\\mathrm{B}T/h\\). At the transition state (centre of the left panel), we have an activated complex [A⋯B⋯C]\\(^\\ddagger\\) where both bonds are partially formed. What happens if we move a small distance along the reaction coordinate? The right panel shows a zoomed-in view of the saddle point region from Figure 8.1. Motion along the pink line through this saddle point corresponds to changes in both bond distances simultaneously: moving towards reactants, \\(r_\\mathrm{AB}\\) decreases and \\(r_\\mathrm{BC}\\) increases; moving towards products, \\(r_\\mathrm{AB}\\) increases and \\(r_\\mathrm{BC}\\) decreases. This motion through the transition state resembles an asymmetric stretch of the activated complex—a vibration-like mode where the system oscillates along the reaction coordinate. By modelling this as a loose molecular vibration, we can derive the expression: \\[k^\\ddagger = \\frac{k_\\mathrm{B}T}{h}\\] where \\(k_\\mathrm{B}\\) is Boltzmann’s constant, \\(h\\) is Planck’s constant, and \\(T\\) is temperature.5 Because this expression accounts for motion along the reaction coordinate, we must take care when counting vibrational modes in the activated complex: we always count one fewer vibrational mode than the molecular geometry would normally possess (\\(3N-6\\) for a linear complex instead of \\(3N-5\\), or \\(3N-7\\) for a non-linear complex instead of \\(3N-6\\)), as the reaction coordinate “vibration” is already included in the \\(k^\\ddagger\\) term. 8.3 Mathematical Development Having established how to treat motion across the transition state, we can now develop the complete mathematical framework for estimating pre-exponential factors. We will combine our expression for \\(k^\\ddagger\\) with the entropy of activation to derive a working equation that connects molecular properties to reaction rates. The complete transition state theory rate equation can now be written as: \\[\\nu = \\frac{k^{\\ddagger}}{c^\\circ}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}[\\mathrm{A}][\\mathrm{B}]\\] Comparison with the Arrhenius equation: \\[\\nu = A\\mathrm{e}^{-E_\\mathrm{a}/RT}[\\mathrm{A}][\\mathrm{B}]\\] reveals that the pre-exponential factor corresponds to: \\[A \\approx \\frac{k^{\\ddagger}}{c^\\circ}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\] By separating the entropy of activation into contributions from different types of molecular motion, we arrive at the complete transition state theory expression: \\[A = \\frac{k_\\mathrm{B}T}{hc^\\circ}\\mathrm{e}^{\\Delta S^{\\ddagger}_\\mathrm{trans}/R}\\mathrm{e}^{\\Delta S^{\\ddagger}_\\mathrm{rot}/R}\\mathrm{e}^{\\Delta S^{\\ddagger,(n-1)}_\\mathrm{vib}/R}\\] where the superscript \\((n-1)\\) on the vibrational entropy term indicates that we consider one fewer vibrational mode than might be expected, because motion along the reaction coordinate is already accounted for in the frequency prefactor \\(\\frac{k_\\mathrm{B}T}{h}\\). This expression is particularly powerful because it allows us to make quantitative predictions of the Arrhenius pre-exponential factor if we can evaluate (or estimate) the changes in translational, rotational, and vibrational entropy when forming the activated complex. For gas-phase reactions, these contributions can be estimated using characteristic values: Translational motion: \\(S^{\\ddagger}_\\mathrm{trans} \\approx 195~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) Rotational modes: \\(S^{\\ddagger}_\\mathrm{rot} \\approx 20~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) Vibrational modes: \\(S^{\\ddagger}_\\mathrm{vib} \\approx 5~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) 8.4 Analysis of Molecular Systems 8.4.1 Atomic Reactions The simplest case to analyse is a reaction between two atoms, A + B. Initially, the system possesses: Three translational degrees of freedom for atom A Three translational degrees of freedom for atom B No rotational or vibrational modes When these atoms combine to form the activated complex [A⋯B]\\(^\\ddagger\\), this transforms into: Three translational degrees of freedom (describing motion of the complex as a whole) Two rotational degrees of freedom (the complex can rotate about two axes) One vibrational mode (3N−5 = 1 for the linear diatomic complex) From these changes in molecular freedom, we can calculate the entropy changes systematically. For translational motion, we lose three degrees of freedom when forming the complex, giving: \\[\\Delta S^\\ddagger_\\mathrm{trans} = -3 \\times 195 = -585~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] The activated complex gains two rotational degrees of freedom: \\[\\Delta S^\\ddagger_\\mathrm{rot} = +2 \\times 20 = +40~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] The activated complex has one vibrational mode, but we use N−1 = 0 modes in our entropy calculation since the reaction coordinate vibration is included in \\(k^\\ddagger\\). Thus: \\[\\Delta S^\\ddagger_\\mathrm{vib} = 0 \\times 5 = 0~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] With these entropy changes calculated, we can now determine the pre-exponential factor: \\[A = 10^{13} \\times \\mathrm{e}^{-3 \\times 195/8.314} \\times \\mathrm{e}^{2 \\times 20/8.314} \\times \\mathrm{e}^{0 \\times 5/8.314} \\times (N_\\mathrm{A} \\times 10^3)~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] \\[= 2 \\times 10^{11}~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] The factor of \\(N_\\mathrm{A}\\) (Avogadro’s number) converts from a per-molecule basis to a per-mole basis, since our rate constant needs to work with concentrations in mol dm\\(^{-3}\\). The factor of \\(10^3\\) converts volumes from m\\(^3\\) to dm\\(^3\\), ensuring our final rate constant has the correct units of dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\). Figure 8.3: Systematic accounting of degrees of freedom changes for the reaction between two atoms. The table format provides a template for organizing similar analyses: count initial degrees of freedom for each reactant, count final degrees of freedom in the activated complex, then calculate the change (Δ) for each type of motion. 8.4.2 Polyatomic Systems For a reaction between a diatomic molecule and a four-atom molecule, we must account for additional molecular freedom in both reactants and the activated complex. Let us examine the initial degrees of freedom systematically. For the diatomic molecule (N = 2), being linear, we have: Three translational modes (motion through space) Two rotational modes (rotation about axes perpendicular to the bond) One vibrational mode (3N − 5 = 1 for a linear molecule) The four-atom molecule (N = 4), being non-linear, possesses: Three translational modes Three rotational modes Six vibrational modes (3N − 6 = 6 for a non-linear molecule) When these molecules combine, they form a six-atom activated complex (N = 6) with: Three translational modes Three rotational modes (non-linear complex) Twelve vibrational modes (3N − 6 = 12 for the non-linear six-atom complex) From these molecular properties, we can determine the entropy changes systematically. For translational motion: Initially: six independent translational modes (three per molecule) Finally: three translational modes in the complex Net change: \\(\\Delta\\)ntrans = −3 \\[\\Delta S^\\ddagger_\\mathrm{trans} = -3 \\times 195 = -585~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] For rotational motion: Initially: five rotational modes (two from diatomic + three from four-atom molecule) Finally: three rotational modes in the complex Net change: \\(\\Delta\\)nrot = −2 \\[\\Delta S^\\ddagger_\\mathrm{rot} = -2 \\times 20 = -40~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] For vibrational motion: Initially: seven vibrational modes (one from diatomic + six from four-atom molecule) Finally: twelve vibrational modes in the complex Net change: Δnvib = 12 − 7 = +5 However, we must use n−1 modes in our entropy calculation to avoid double-counting motion along the reaction coordinate. Using eleven modes for the complex rather than twelve, the entropy change becomes: \\[\\Delta S^\\ddagger_\\mathrm{vib} = (11 - 7) \\times 5 = +4 \\times 5 = +20~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] With these entropy changes determined, we can calculate the pre-exponential factor: \\[A = 10^{13} \\times \\mathrm{e}^{-3 \\times 195/8.314} \\times \\mathrm{e}^{-2 \\times 20/8.314} \\times \\mathrm{e}^{4 \\times 5/8.314} \\times (N_\\mathrm{A} \\times 10^3)~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] \\[= 1 \\times 10^8~\\mathrm{dm^3~mol^{-1}~s^{-1}}\\] As in our atomic example, the factor of NA converts to a per-mole basis, while the factor of 103 handles the conversion from m3 to dm3 units. Figure 8.4: Degree of freedom accounting for a reaction between a diatomic molecule (N = 2) and a four-atom molecule (N = 4) forming a six-atom activated complex (N = 6). The activated complex has 12 vibrational modes (3N−6 for a non-linear molecule), but when calculating the pre-exponential factor, we use only 11 modes in the entropy expression because one vibrational mode—motion along the reaction coordinate—is already included in the \\(k^\\ddagger\\) term. This more complex example reveals a key feature of molecular reactions: as molecular complexity increases, we typically observe larger decreases in molecular freedom when forming the activated complex. This systematically leads to more negative values of \\(\\Delta S^\\ddagger\\) and correspondingly smaller pre-exponential factors. 8.5 Applications and Predictive Power We now have a complete quantitative theory for predicting pre-exponential factors from molecular structure. But how do the predictions from this theory compare to experimental data? Figure 8.5 compares our estimates with experimental values for three representative reactions spanning a wide range of molecular complexity. Our estimation method correctly predicts both the magnitude and ordering of these pre-exponential factors: the estimated values of 4 × 109, 1 × 108, and 2 × 107 dm3 mol−1 s-1 agree with experimental measurements within an order of magnitude. Figure 8.5: Comparison of experimental and estimated pre-exponential factors for representative bimolecular reactions. The systematic decrease in pre-exponential factors reflects increasing molecular complexity and greater loss of molecular freedom when forming the activated complex. The estimated entropy changes (\\(\\Delta S^\\ddagger_\\mathrm{rot+vib}\\)) become increasingly negative, leading to correspondingly smaller pre-exponential factors. Our simple estimation method successfully predicts both the magnitude and ordering of experimental values, with agreement typically within an order of magnitude. The systematic decrease in pre-exponential factors across these reactions reflects three key features: Increasing molecular complexity in the reactants Greater loss of molecular freedom in forming the activated complex Increasingly negative values of \\(\\Delta S^\\ddagger_\\mathrm{rot+vib}\\): +15, −20, and −35 J K−1 mol−1 respectively 8.6 Connection to Collision Theory This molecular freedom framework finally provides a quantitative explanation for an observation we made in Lecture 5: collision theory’s empirical steric factor \\(P\\) is systematically less than unity for reactions between complex molecules, and decreases as molecular complexity increases. We can now understand why. The steric factor \\(P\\) in collision theory appears as an empirical correction to account for the requirement that molecules must collide with appropriate orientation and alignment. From our transition state theory perspective, these geometric constraints manifest as losses of molecular freedom when forming the activated complex. Reactions between more complex molecules lose more translational and rotational freedom, leading to increasingly negative values of \\(\\Delta S^{\\ddagger}\\) and correspondingly smaller pre-exponential factors. The systematic trends in Figure 8.5 demonstrate this principle directly: as we move from simple to more complex reactions, the pre-exponential factors decrease by over three orders of magnitude. Collision theory’s “steric hindrance” is thus given a quantitative thermodynamic foundation: geometrically constrained transition states, which require significant loss of molecular freedom, are thermodynamically less favourable than less constrained transition states, leading to smaller pre-exponential factors. 8.7 Limitations in Pre-exponential Factor Estimation While our molecular freedom approach successfully predicts systematic trends in reaction rates, several important approximations underpin these calculations. Understanding these limitations helps us recognise both the power and constraints of our theoretical framework. 8.7.1 Statistical Entropy Approximations Our calculations employ characteristic entropy values for different types of molecular motion: Translational motion: 195 J K−1 mol−1 Rotational modes: 20 J K−1 mol−1 Vibrational modes: 5 J K−1 mol−1 These values represent statistical averages derived from typical molecular behaviour. For more precise predictions, we require detailed quantum mechanical calculations of molecular energy levels, which can determine specific values for \\(S^\\ddagger_\\mathrm{dof}\\) based on the actual energy spacing between quantum states. While such calculations provide greater accuracy, our simpler approach using characteristic values remains valuable for understanding trends in reactivity. 8.7.2 Effects of Molecular Symmetry Molecular symmetry introduces additional complexity beyond simple counting of degrees of freedom. Consider these parallel reactions: \\[\\mathrm{CH}_4 + \\mathrm{Br}^\\bullet \\longrightarrow \\mathrm{HBr} + \\mathrm{CH}_3^\\bullet\\] \\[\\mathrm{CD}_3\\mathrm{H} + \\mathrm{Br}^\\bullet \\longrightarrow \\mathrm{HBr} + \\mathrm{CD}_3^\\bullet\\] Our previous analysis, based purely on counting molecular degrees of freedom, predicts identical pre-exponential factors for both reactions. However, experimental measurements reveal that the CH4 reaction proceeds approximately four times faster than the CD3H reaction. Figure 8.6: Molecular symmetry affects pre-exponential factors through configurational entropy. Top: In CH\\(_4\\), all four hydrogen atoms (blue) are equivalent, so the bromine radical can abstract any hydrogen to form the same product, giving a statistical factor of \\(l = 4\\). Bottom: In CD\\(_3\\)H, only one hydrogen (blue) is available for abstraction whilst the three deuterium atoms (orange) are not, giving \\(l = 1\\). This symmetry difference results in the CH\\(_4\\) reaction being approximately four times faster than the CD\\(_3\\)H reaction, even though simple degree-of-freedom counting predicts identical rates. This difference arises from molecular symmetry. In CH4, all four hydrogen atoms are equivalent—the bromine radical can abstract any hydrogen to form the same product. In CD3H, only one hydrogen is available for abstraction. To understand the statistical factor more deeply, consider what happens if we artificially label the four hydrogen atoms in CH4 as shown in Figure 8.7. Figure 8.7: Understanding the statistical factor for CH\\(_4\\) through artificial labeling. When we label the four equivalent hydrogen atoms (1–4), we see that reaction at each site produces a distinct labeled product. Since the hydrogens are actually indistinguishable, these represent four equivalent pathways to the same physical product, giving a statistical factor of \\(l = 4\\). What we consider a single reaction is in fact four different reaction pathways—each pathway corresponds to the bromine radical extracting a different labelled hydrogen, which then gives a different labeled product. Since the hydrogen atoms in methane are actually indistinguishable, these four products, and the four reaction pathways that form them, are physically indistinguishable—all four produce the same products, CH3• + HBr. We account for this by introducing a statistical factor, \\(l\\), representing the number of equivalent pathways:6 \\[A = l\\frac{k_\\mathrm{B}T}{hc^\\circ}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\] For our example reactions: CH4 reaction: \\(l = 4\\) (four equivalent hydrogens) CD3H reaction: \\(l = 1\\) (single abstractable hydrogen) The rate constant ratio becomes: \\[\\frac{k_\\mathrm{CH_4}}{k_\\mathrm{CD_3H}} = \\frac{4}{1} = 4\\] explaining the observed fourfold difference in reaction rates. 8.7.3 Internal Molecular Motion The treatment of internal molecular motions reveals additional subtlety in our theoretical framework. Consider the ethane molecule (C2H6), which exhibits two distinct types of motion around its C–C bond: C–C stretching vibration: Involves direct compression and extension of the C–C bond Requires significant energy Shows widely spaced quantum energy levels Makes small contributions to vibrational entropy C–C torsional motion: Involves rotation of CH3 groups about the C–C axis Requires much less energy Shows more closely spaced energy levels Makes larger contributions to entropy Figure 8.8: Comparison of energy level spacings for different types of molecular motion in ethane-like molecules. Left: A normal C–C stretching vibration involves compression and extension of the bond, requiring significant energy. The resulting widely spaced quantum energy levels (gray) mean only a few low-lying states (green) are thermally accessible at room temperature, giving low entropy. Right: Internal rotation of CH\\(_3\\) groups about the C–C axis requires much less energy. The resulting closely spaced energy levels mean many states are thermally accessible, giving substantially higher entropy than a normal vibration. Figure 8.8 illustrates why internal rotation contributes more entropy than normal vibrations: the closely spaced energy levels mean many more states are thermally accessible. When molecules with internal rotations form activated complexes, two contrasting scenarios can arise: Restricted internal rotation: Occurs when the transition state requires specific molecular alignment Reduces freedom of internal motion Produces more negative \\(\\Delta S^\\ddagger\\) values Leads to lower pre-exponential factors than predicted by simple counting Enhanced internal rotation: Occurs when transition state formation weakens bonds that hinder rotation Increases freedom of internal motion Produces less negative (or positive) \\(\\Delta S^\\ddagger\\) values Leads to higher pre-exponential factors than predicted Figure 8.9: The effect of transition state formation on internal rotation determines the sign of entropy contributions. Left: When the transition state requires specific molecular alignment or constrains rotation (indicated by the red barrier), internal rotational freedom is reduced. This produces additional negative contributions to \\(\\Delta S^\\ddagger\\), leading to lower pre-exponential factors than predicted by simple degree-of-freedom counting. Right: When transition state formation weakens a bond, internal rotation becomes freer. The enhanced rotational freedom produces positive contributions to \\(\\Delta S^\\ddagger\\), leading to higher pre-exponential factors. This effect is not limited to simple molecules. Diels-Alder cycloadditions provide a clear example: our predictions typically overestimate the experimental pre-exponential factors for these reactions. This occurs because the transition state requires precise alignment of the diene and dienophile components. This geometric constraint introduces additional restrictions on molecular motion beyond those captured by simple counting of degrees of freedom, leading to more negative \\(\\Delta S^\\ddagger\\) values than predicted. Figure 8.10: The Diels-Alder cycloaddition transition state illustrates why geometric constraints can produce more negative \\(\\Delta S^\\ddagger\\) values than predicted by simple degree-of-freedom counting. Left: The diene reactant possesses internal rotational freedom (rotation arrow). Right: The transition state requires formation of a planar, cyclic six-membered ring structure (shown in red dashes). This geometric constraint restricts the internal rotational freedom present in the reactants, producing additional negative entropy contributions beyond those from simple translational and rotational degree-of-freedom changes. This explains why our estimated pre-exponential factor typically overestimates experimental values for Diels-Alder reactions. These examples demonstrate that pre-exponential factors depend not only on the changes in translational and rotational degrees of freedom, but also on how transition state formation affects internal molecular motions such as rotation around single bonds. The derivation of this expression for \\(k^\\ddagger\\) requires a statistical mechanical treatment of transition state theory. You will cover statistical mechanics in the third year of your course. A brief overview of the statistical formulation of transition state theory is given in Appendix D.↩︎ The statistical factor can equivalently be expressed as a configurational entropy contribution: \\(\\Delta S^\\ddagger_\\mathrm{conf} = R \\ln l\\). This reflects the increased number of microstates available to the activated complex when multiple equivalent reaction pathways exist.↩︎ "],["lecture9.html", "Lecture 9 Applications of Transition State Theory 9.1 Unimolecular Reactions 9.2 The Eyring Plot 9.3 Effect of Pressure on Rate Coefficients 9.4 Kinetic Isotope Effects", " Lecture 9 Applications of Transition State Theory Over the previous three lectures, we have developed transition state theory as a comprehensive framework for understanding how molecular properties govern reaction rates. Here we explore how this framework connects experimental measurements to transition state structure. We examine four applications: comparing experimental pre-exponential factors for unimolecular reactions to predictions from degree-of-freedom counting, extracting activation parameters from temperature-dependent rate data, understanding how pressure affects reaction rates, and using kinetic isotope effects to probe bond breaking at transition states. Each demonstrates how transition state theory provides a systematic way to interpret kinetic measurements in molecular terms. 9.1 Unimolecular Reactions In Lecture 8, we developed a scheme for estimating pre-exponential factors by systematically counting molecular degrees of freedom and using characteristic entropy values for translational, rotational, and vibrational motion. While our analysis focused on bimolecular reactions, we can apply the same approach to unimolecular processes of the form: \\[\\begin{equation} \\mathrm{A} \\rightleftharpoons \\mathrm{C}^{\\ddagger} \\longrightarrow \\mathrm{P} \\end{equation}\\] 9.1.1 The Baseline Estimate Consider a polyatomic molecule undergoing unimolecular rearrangement or decomposition. The activated complex is simply the reactant molecule distorted along the reaction coordinate, so both reactant and activated complex possess the same number of translational, rotational, and vibrational degrees of freedom—the total degrees of freedom are conserved. This simple picture suggests \\(\\Delta S^{\\ddagger} \\approx 0\\), leading to a predicted pre-exponential factor of:7 \\[\\begin{equation} A = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^{\\Delta S^{\\ddagger}/R} \\approx \\frac{k_\\mathrm{B}T}{h} \\approx 10^{13}~\\mathrm{s}^{-1} \\end{equation}\\] However, this picture glosses over an important detail about how we account for these degrees of freedom. If the reactant molecule has n vibrational modes, the transition state also has n vibrational degrees of freedom—but one of these now corresponds to motion along the reaction coordinate. In transition state theory, this reaction coordinate motion provides the \\(k_\\mathrm{B}T/h\\) prefactor rather than contributing to \\(\\Delta S^{\\ddagger}\\). When we count entropy contributions to \\(\\Delta S^{\\ddagger}\\), we therefore include only n−1 vibrational modes for the transition state but n vibrational modes for the reactant. We are effectively “losing” the entropy contribution of one vibrational mode—the one that becomes the reaction coordinate. For a typical vibrational mode at room temperature, \\(S_\\mathrm{vib} \\approx 5~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\). Losing this entropy contribution when forming the transition state gives: \\[\\Delta S^{\\ddagger} \\approx -5~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] The predicted pre-exponential factor is therefore: \\[A = \\frac{k_\\mathrm{B}T}{h} \\times \\exp\\left(\\frac{-5}{8.314}\\right) \\approx 10^{13} \\times 0.55 \\approx 5 \\times 10^{12}~\\mathrm{s}^{-1}\\] Even when we properly account for how the vibrational modes are treated, we still obtain \\(A \\approx 10^{13}~\\mathrm{s}^{-1}\\) to within the same order of magnitude. This baseline estimate holds provided the remaining n−1 vibrational modes have similar frequencies in the reactant and the transition state, such that their entropy contributions approximately cancel. 9.1.2 Using Pre-exponential Factors to Probe Transition State Structure The baseline estimate of \\(A \\approx 10^{13}~\\mathrm{s}^{-1}\\) provides a useful reference point. When experimental measurements of pre-exponential factors differ significantly from this baseline, those differences tell us about transition state structure. We can quantify this by calculating the entropy of activation from the experimental pre-exponential factor: \\[\\Delta S^{\\ddagger} = R \\ln\\left(\\frac{hA_\\mathrm{expt}}{k_\\mathrm{B}T}\\right)\\] Comparing this to our baseline prediction of \\(\\Delta S^{\\ddagger} \\approx -5~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\) reveals whether the transition state has more or less molecular freedom than expected: If \\(\\Delta S^{\\ddagger}\\) is more positive than the baseline: the transition state has enhanced molecular freedom—a “loose” transition state If \\(\\Delta S^{\\ddagger}\\) is more negative* than the baseline: the transition state has reduced molecular freedom—a “tight” transition state These deviations arise when the structure of the transition state causes the n−1 vibrational modes (those that are not the reaction coordinate) to change significantly in frequency between reactant and transition state. Two contrasting examples illustrate how experimental pre-exponential factors reveal transition state structure. 9.1.2.1 Ethane Decomposition: A Loose Transition State The thermal decomposition of ethane proceeds via C–C bond cleavage: \\[\\begin{equation} \\mathrm{C}_2\\mathrm{H}_6 \\longrightarrow 2\\mathrm{CH}_3^\\bullet \\end{equation}\\] The experimental pre-exponential factor is A = 2 × 1016 s−1. Using this to calculate the entropy of activation: \\[\\Delta S^{\\ddagger} = R \\ln\\left(\\frac{h \\times 2 \\times 10^{16}}{k_\\mathrm{B}T}\\right) \\approx +63~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] This is substantially more positive than our baseline prediction of −5 J K−1 mol−1. What does this tell us about the transition state structure? In this reaction, the C–C stretching mode becomes the reaction coordinate, contributing the expected baseline entropy loss. However, the large positive \\(\\Delta S^{\\ddagger}\\) indicates that the other vibrational modes gain significant entropy in the transition state. As the C–C bond weakens in forming the transition state, the activated complex becomes “looser” than the intact molecule. Internal rotation around the weakened C–C bond becomes much freer, and the CH3 groups can undergo enhanced rocking and torsional motions. These modes, which were relatively constrained in the reactant, become lower-frequency vibrations in the transition state. The experimental pre-exponential factor thus reveals a loose transition state with enhanced molecular freedom. 9.1.2.2 The Cope Rearrangement: A Tight Transition State A contrasting example is provided by the Cope rearrangement of 1,5-hexadiene. The experimental pre-exponential factor is A = 4 × 1010 s−1. Calculating the entropy of activation: \\[\\Delta S^{\\ddagger} = R \\ln\\left(\\frac{h \\times 4 \\times 10^{10}}{k_\\mathrm{B}T}\\right) \\approx -46~\\mathrm{J}~\\mathrm{K}^{-1}~\\mathrm{mol}^{-1}\\] This is substantially more negative than our baseline prediction. The experimental pre-exponential factor tells us that the transition state has significantly reduced molecular freedom compared to the reactant. Figure 9.1: The Cope rearrangement of 1,5-hexadiene proceeds through a constrained cyclic transition state. Left: The reactant possesses considerable internal rotational freedom around the three C–C single bonds (rotation arrows). Centre: The transition state requires a planar, cyclic six-membered ring geometry (red dashed ring) with specific orbital overlap for the [3,3]-sigmatropic shift. Right: The product, with the double bonds in new positions. The constraint of forming this cyclic transition state eliminates the internal rotational freedom present in the reactant. As shown in Figure 9.1, forming the cyclic transition state imposes geometric constraints on the molecule. The reaction requires precise alignment of the diene termini with specific orbital overlap for the [3,3]-sigmatropic shift, restricting internal rotations that were relatively free in the reactant. These constraints reduce the entropy contributions from the vibrational modes in the transition state. The experimental pre-exponential factor thus reveals a tight, constrained transition state. 9.1.3 The Power of the Comparison By comparing experimental pre-exponential factors to the baseline prediction from our degree-of-freedom counting scheme, we get insight into the transition state and the reaction mechanism. Deviations from \\(A \\approx 10^{13}~\\mathrm{s}^{-1}\\) tell us whether transition states are loose or tight, whether bonds are weakened or geometric constraints are imposed, and how molecular freedom changes along the reaction coordinate. This provides insight into fleeting transition states that we cannot observe directly. 9.2 The Eyring Plot We have seen how comparing experimental and predicted pre-exponential factors provides information about transition state structure. Another powerful application of transition state theory is extracting activation parameters directly from temperature-dependent rate measurements. In Lecture 6, we developed the transition state theory expression for the rate constant. This equation, known as the Eyring equation after Henry Eyring who developed transition state theory in the 1930s, connects the rate constant to the activation parameters \\(\\Delta H^{\\ddagger}\\) and \\(\\Delta S^{\\ddagger}\\): \\[k = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}\\] By measuring rate constants at different temperatures, we can extract these activation parameters and learn about the energetic and entropic requirements for reaching the transition state. The Eyring equation is non-linear in the parameters we want to determine. Modern computational analysis fits such equations directly using non-linear regression, which gives the most accurate parameter estimates. However, you will encounter linearised forms of the Eyring equation throughout textbooks and published literature—this approach became standard before computers were readily available and persists through historical inertia. More practically, you need to understand how to transform equations into linear forms because in examinations, you can plot linearised data and estimate parameters by drawing a line through the points and calculating its slope and intercept. The Eyring plot provides exactly this: a method for transforming the Eyring equation into a form where \\(\\ln(k/T)\\) versus \\(1/T\\) produces a straight line. 9.2.1 Deriving the Linear Form To transform the Eyring equation into a linear form, we first divide both sides by \\(T\\): \\[\\frac{k}{T} = \\frac{k_\\mathrm{B}}{h}\\mathrm{e}^{\\Delta S^{\\ddagger}/R}\\mathrm{e}^{-\\Delta H^{\\ddagger}/RT}\\] Taking the natural logarithm of both sides gives: \\[\\ln\\left(\\frac{k}{T}\\right) = \\ln\\left(\\frac{k_\\mathrm{B}}{h}\\right) + \\frac{\\Delta S^{\\ddagger}}{R} - \\frac{\\Delta H^{\\ddagger}}{RT}\\] Rearranging to separate the temperature-dependent term: \\[\\ln\\left(\\frac{k}{T}\\right) = \\ln\\left(\\frac{k_\\mathrm{B}}{h}\\right) + \\frac{\\Delta S^{\\ddagger}}{R} - \\frac{\\Delta H^{\\ddagger}}{R}\\left(\\frac{1}{T}\\right)\\] This has the form of a straight line: \\[y = c + mx\\] where \\(y = \\ln(k/T)\\), \\(x = 1/T\\), the intercept is \\(c = \\ln(k_\\mathrm{B}/h) + \\Delta S^{\\ddagger}/R\\), and the slope is \\(m = -\\Delta H^{\\ddagger}/R\\). 9.2.2 Extracting Activation Parameters A plot of \\(\\ln(k/T)\\) versus \\(1/T\\) is called an Eyring plot. If transition state theory correctly describes the temperature dependence of the rate constant, this plot should be approximately linear. The activation parameters can then be extracted from:8 Slope = \\(-\\Delta H^{\\ddagger}/R\\) → giving \\(\\Delta H^{\\ddagger} = -\\text{slope} \\times R\\) Intercept = \\(\\ln(k_\\mathrm{B}/h) + \\Delta S^{\\ddagger}/R\\) → giving \\(\\Delta S^{\\ddagger} = R \\times (\\text{intercept} - \\ln(k_\\mathrm{B}/h))\\) Figure 9.2: An Eyring plot for experimental rate constant data measured at different temperatures. The good linear fit through the data points confirms that transition state theory describes the temperature dependence well for this reaction. The activation parameters \\(\\Delta H^\\ddagger\\) and \\(\\Delta S^\\ddagger\\) can be extracted from the slope and intercept of the fitted line. Figure 9.2 shows an example Eyring plot. The fitted line has slope \\(-1485.8\\) K and intercept \\(7.6809\\). Using \\(R = 8.314~\\mathrm{J~K^{-1}~mol^{-1}}\\), we can calculate: \\[\\Delta H^{\\ddagger} = -(-1485.8~\\mathrm{K}) \\times 8.314~\\mathrm{J~K^{-1}~mol^{-1}} = 12.4~\\mathrm{kJ~mol^{-1}}\\] The intercept provides \\(\\Delta S^{\\ddagger}\\) once we account for the \\(\\ln(k_\\mathrm{B}/h)\\) term. 9.3 Effect of Pressure on Rate Coefficients So far, we have examined how temperature affects reaction rates through the Eyring equation. But reactions in solution or the solid state can also be influenced by pressure. How does pressure affect rate constants, and what can we learn about transition states from these pressure effects? 9.3.1 Volume of Activation Transition state theory provides a framework for understanding pressure effects. When reactants form the activated complex, there is typically a change in volume: \\[\\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^{\\ddagger} \\longrightarrow \\mathrm{products}\\] The volume of activation, \\(\\Delta V^{\\ddagger}\\), is defined as the difference in partial molar volume between the activated complex and the reactants. This volume change affects how pressure influences the reaction rate: If \\(\\Delta V^{\\ddagger} &lt; 0\\) (activated complex more compact than reactants): increasing pressure favours formation of the activated complex, increasing the reaction rate If \\(\\Delta V^{\\ddagger} &gt; 0\\) (activated complex more expanded than reactants): increasing pressure disfavours formation of the activated complex, decreasing the reaction rate The overall reaction rate is proportional to the concentration of the activated complex, \\([\\mathrm{C}^{\\ddagger}]\\), so any pressure-induced change in \\([\\mathrm{C}^{\\ddagger}]\\) directly affects the rate constant. 9.3.2 Quantitative Treatment We can develop this idea quantitatively by considering how pressure affects the enthalpy of activation. For reactions where volume changes occur, the enthalpy depends on pressure through: \\[\\Delta H^{\\ddagger} = \\Delta U^{\\ddagger} + p\\Delta V^{\\ddagger}\\] Substituting this into the Eyring equation and taking logarithms: \\[\\begin{equation} \\ln k = \\ln \\frac{k_\\mathrm{B}T}{h} + \\frac{\\Delta S^{\\ddagger}}{R} - \\frac{\\Delta U^{\\ddagger} + p\\Delta V^{\\ddagger}}{RT} \\tag{9.1} \\end{equation}\\] If we differentiate this expression with respect to pressure at constant temperature, we obtain: \\[\\left(\\frac{\\partial \\ln k}{\\partial p}\\right)_T = -\\frac{\\Delta V^{\\ddagger}}{RT}\\] This predicts that a plot of \\(\\ln k\\) versus pressure should be approximately linear, with slope \\(-\\Delta V^{\\ddagger}/RT\\). Rearranging this relationship allows us to determine the volume of activation from experimental measurements: \\[\\Delta V^{\\ddagger} = -RT\\left(\\frac{\\partial \\ln k}{\\partial p}\\right)_T\\] By measuring how the rate constant changes with pressure, we can extract information about the relative volumes of the reactants and the transition state. 9.3.3 Example: Decomposition of Dibutyl Peroxide Consider the thermal decomposition of dibutyl peroxide, shown in Figure 9.3. Figure 9.3: Decomposition of dibutyl peroxide to form two tert-butoxy radicals. The transition state (centre) shows the O–O bond partially broken (blue dashed line). This bond lengthening requires more volume than the intact O–O bond in the reactant, leading to a positive volume of activation. Experimental measurements of the pressure dependence give \\(\\Delta V^{\\ddagger}\\) = +5.24 × 10−6 m3 mol−1$. This positive volume of activation tells us that the transition state occupies more volume than the reactant. As shown in the figure, the O–O bond is partially broken at the transition state—the bond has lengthened compared to the reactant. This bond stretching increases the volume occupied by the molecule, explaining the positive \\(\\Delta V^{\\ddagger}\\). This demonstrates how the sign and magnitude of the volume of activation provide direct information about geometric changes at the transition state. A negative \\(\\Delta V^{\\ddagger}\\) would indicate bond formation or increased compactness, whilst a positive value reveals bond breaking or expansion, as we observe here for peroxide decomposition. 9.4 Kinetic Isotope Effects As discussed above, temperature and pressure measurements can provide thermodynamic and volumetric information about transition states. A third experimental technique—isotopic substitution—reveals which specific bonds are breaking during reaction. Many reactions proceed more slowly when hydrogen is replaced by deuterium. For example, consider this E2 elimination reaction (Figure 9.4): Figure 9.4: E2 elimination of phenylethyl bromide with sodium ethoxide. The hydrogen (orange, rate constant \\(k_\\mathrm{H}\\)) and deuterium (blue, rate constant \\(k_\\mathrm{D}\\)) at the \\(\\alpha\\)-position are removed during the elimination to form ethanol/deuterated ethanol. Experimentally, \\(k_\\mathrm{H}/k_\\mathrm{D}\\) = 7.8. Experimentally, we find \\(k_\\mathrm{H}/k_\\mathrm{D} = 7.8\\)—the deuterated compound reacts nearly eight times more slowly than its hydrogen analogue. Why should this be? The two molecules differ only in the mass of one nucleus—they have identical electronic structures and therefore experience the same potential energy surface during reaction. Our transition state theory analysis has focused on how forming the activated complex changes the number and type of molecular degrees of freedom (translational, rotational, vibrational), which determines \\(\\Delta S^{\\ddagger}\\). For these two very similar molecules, we would expect nearly identical \\(\\Delta S^{\\ddagger}\\) values and the same \\(\\Delta H^{\\ddagger}\\), giving similar rate constants. Yet we observe a substantial kinetic isotope effect. 9.4.1 Zero-Point Vibrational Energy The explanation lies in the zero-point vibrational energy. While both molecules move on the same potential energy surface, the vibrational energy levels on that surface depend on mass. This means the ground state energy—the energy of the \\(v=0\\) vibrational level—is different for C–H and C–D bonds. When we account for these zero-point energy differences, the activation barriers measured from the ground states differ even though the potential energy surface is identical for both molecules. To understand how mass affects vibrational energy, we can model the C–H and C–D bonds as harmonic oscillators. For a harmonic oscillator, the vibrational energy levels are given by: \\[\\begin{equation} E_v = \\left(v + \\frac{1}{2}\\right)\\sqrt{\\frac{k}{\\mu}} \\end{equation}\\] where \\(v\\) is the vibrational quantum number, \\(k\\) is the force constant (determined by the strength of the bond), and \\(\\mu\\) is the reduced mass: \\[\\begin{equation} \\mu = \\frac{m_1m_2}{m_1 + m_2} \\end{equation}\\] Even in the ground vibrational state (\\(v=0\\)), the system retains energy—the zero-point energy. For a C–H bond where carbon is much heavier than hydrogen, we can approximate \\(\\mu \\approx m_\\mathrm{H}\\), giving: \\[\\begin{equation} E_\\mathrm{ZPE}(\\mathrm{C{-}H}) \\approx \\frac{1}{2}\\sqrt{\\frac{k}{m_\\mathrm{H}}} \\end{equation}\\] When we substitute deuterium, where \\(m_\\mathrm{D} \\approx 2m_\\mathrm{H}\\), the reduced mass approximately doubles. This changes the zero-point energy: \\[\\begin{equation} E_\\mathrm{ZPE}(\\mathrm{C{-}D}) \\approx \\frac{1}{2}\\sqrt{\\frac{k}{2m_\\mathrm{H}}} = \\frac{1}{\\sqrt{2}} \\times E_\\mathrm{ZPE}(\\mathrm{C{-}H}) \\end{equation}\\] Figure 9.5: Comparison of vibrational energy levels for C–H and C–D bonds. Both bonds vibrate on identical potential energy curves (same force constant \\(k\\)). The heavier C–D bond (blue, right) has more closely spaced energy levels than the lighter C–H bond (orange, left), resulting in lower zero-point energy by a factor of \\(1/\\sqrt{2}\\). Figure 9.5 shows how this works. The potential energy curve—the surface on which the atoms move—is identical for both isotopes. What differs is the quantisation of motion on that surface: the heavier C–D bond has more closely spaced vibrational levels and therefore lower zero-point energy than the C–H bond. 9.4.2 From Zero-Point Energy to Activation Energy This difference in zero-point energy directly affects the activation barrier. In the reactants, the C–H and C–D bonds have different zero-point energies. At the transition state, if the C–H or C–D bond is essentially completely broken, the vibrational mode associated with that bond no longer exists—it has transformed into motion along the reaction coordinate. Under this assumption, both isotopes reach effectively the same transition state energy: the potential energy surface is identical, and the C–H/C–D vibrational mode that gave different zero-point energies in the reactants no longer contributes at the transition state. Figure 9.6: Reaction coordinate diagram showing how zero-point energy differences create the kinetic isotope effect. The orange and blue curves before the transition state show different energy profiles for the H and D substituted molecules, reflecting their different zero-point energies in the reactants. Assuming the C–H/C–D bond is completely broken at the transition state, both isotopes converge to the same transition state energy (black dot). After the transition state, where the C–H/C–D bond no longer exists, both follow the same energy profile (black curve). This produces \\(\\Delta E^\\ddagger_\\mathrm{D} &gt; \\Delta E^\\ddagger_\\mathrm{H}\\), causing the deuterated compound to react more slowly. As shown in Figure 9.6, the activation energy is the difference between the transition state and the ground vibrational state of the reactant. Because \\(E_\\mathrm{ZPE}(\\mathrm{C{-}D}) &lt; E_\\mathrm{ZPE}(\\mathrm{C{-}H})\\) in the reactants, and both reach the same transition state energy, the deuterated compound faces a larger activation barrier: \\[\\begin{equation} \\Delta E^\\ddagger_\\mathrm{D} - \\Delta E^\\ddagger_\\mathrm{H} = E_\\mathrm{ZPE}(\\mathrm{C{-}H}) - E_\\mathrm{ZPE}(\\mathrm{C{-}D}) \\end{equation}\\] We can quantify this effect. For a typical C–H stretching vibration: - \\(E_\\mathrm{ZPE}(\\mathrm{C{-}H}) = 18.0~\\mathrm{kJ~mol^{-1}}\\) - \\(E_\\mathrm{ZPE}(\\mathrm{C{-}D}) = 13.2~\\mathrm{kJ~mol^{-1}}\\) The difference in activation energies leads to different rate constants: \\[\\begin{equation} \\frac{k_\\mathrm{H}}{k_\\mathrm{D}} = \\mathrm{e}^{(\\Delta E^\\ddagger_\\mathrm{D} - \\Delta E^\\ddagger_\\mathrm{H})/RT} = \\mathrm{e}^{(E_\\mathrm{ZPE}(\\mathrm{H})-E_\\mathrm{ZPE}(\\mathrm{D}))/RT} \\end{equation}\\] At room temperature (298 K), this gives: \\[\\begin{equation} \\frac{k_\\mathrm{H}}{k_\\mathrm{D}} = \\mathrm{e}^{(18.0-13.2)\\times 10^3/(8.314 \\times 298)} = 6.9 \\end{equation}\\] This predicts \\(k_\\mathrm{H}/k_\\mathrm{D} \\approx 7\\) when the C–H bond is completely broken at the transition state—consistent with the experimental value of 7.8 observed in our E2 elimination example. If the bond is only partially broken, or if it remains intact during reaction, the observed isotope effect will be correspondingly smaller. 9.4.3 Using Kinetic Isotope Effects to Probe Reaction Mechanisms The magnitude of the kinetic isotope effect reveals how much a bond has broken at the transition state. Three scenarios are commonly observed: Complete bond breaking at the transition state: \\(k_\\mathrm{H}/k_\\mathrm{D} \\approx 7\\) (the full zero-point energy difference contributes to the activation barrier) Partial bond breaking: \\(1 &lt; k_\\mathrm{H}/k_\\mathrm{D} &lt; 7\\) (intermediate extent of bond cleavage) Bond remains intact: \\(k_\\mathrm{H}/k_\\mathrm{D} \\approx 1\\) (the bond does not participate in the rate-determining step) This makes kinetic isotope effects a powerful tool for investigating reaction mechanisms. Consider the contrasting E2 elimination reactions shown in Figure 9.7. Figure 9.7: Comparison of kinetic isotope effects in E2 eliminations. Top: When H/D is at the \\(\\alpha\\)-position (being removed during elimination), a large kinetic isotope effect is observed (\\(k_\\mathrm{H}/k_\\mathrm{D}\\) = 7.8), indicating the C–H bond is almost completely broken at the transition state. Bottom: When H/D is at the \\(\\beta\\)-position (not involved in the elimination), the kinetic isotope effect is negligible (\\(k_\\mathrm{H}/k_\\mathrm{D}\\) = 1.09), indicating these C–H bonds remain essentially intact at the transition state. When deuterium is substituted at the α-position—the site where the C–H bond is removed during elimination—we observe \\(k_\\mathrm{H}/k_\\mathrm{D} = 7.8\\). This large isotope effect tells us that the C–H bond at this position is almost completely broken at the transition state. The magnitude, close to our predicted value of ~7, indicates that the full zero-point energy difference between C–H and C–D bonds affects the activation barrier. In contrast, when deuterium is substituted at the β-position, the isotope effect is negligible: \\(k_\\mathrm{H}/k_\\mathrm{D} = 1.09\\). This small value shows that the C–H bonds at the β-position remain essentially intact throughout the reaction—they are spectators that do not participate in the rate-determining step. The C–H/C–D zero-point energy difference has virtually no effect on the activation barrier because these bonds are not breaking. These contrasting results demonstrate the mechanistic power of kinetic isotope effects. By measuring how the reaction rate changes upon isotopic substitution at different positions in the molecule, we can determine which bonds are breaking, which remain intact, and the extent of bond cleavage at the transition state. This provides detailed mechanistic information that would be difficult to obtain by other experimental techniques. Note the absence of the standard concentration factor \\(c^\\circ\\) in this expression, unlike the bimolecular case where \\(A = (k_\\mathrm{B}T/hc^\\circ)\\mathrm{e}^{\\Delta S^\\ddagger/R}\\). For unimolecular reactions, the rate constant has units of s\\(^{-1}\\) rather than dm\\(^3\\) mol\\(^{-1}\\) s\\(^{-1}\\), so no concentration term is needed for dimensional consistency.↩︎ Whilst the Eyring plot is widely used in literature and essential for examination purposes, modern kinetic analysis should use direct non-linear fitting of the Eyring equation to experimental data. If the errors in experimental rate constant measurements are normally distributed, then fitting the linearised form gives biased estimates of \\(\\Delta H^{\\ddagger}\\) and \\(\\Delta S^{\\ddagger}\\)—see McCluskey, J. Chem. Educ. 2023, 100, 4174–4176 (DOI: 10.1021/acs.jchemed.3c00466). Non-linear fitting gives unbiased parameter estimates, though it can be numerically unstable. A practical approach is to fit the linear form first, then use these values as starting points for non-linear fitting. When analysing your own kinetic data, use computational tools for non-linear fitting.↩︎ "],["integrating-factor.html", "A Integrating Factor Method for Consecutive Reactions", " A Integrating Factor Method for Consecutive Reactions In analyzing consecutive reactions, we encounter the following differential equation for the intermediate species B: \\[\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t} - k_2[\\mathrm{B}]\\] This is a first-order linear differential equation of the form: \\[\\frac{\\mathrm{d}y}{\\mathrm{d}t} + P(t)y = Q(t)\\] where \\(y = [\\mathrm{B}]\\), \\(P(t) = k_2\\), and \\(Q(t) = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t}\\). The integrating factor method involves multiplying both sides by \\(\\mathrm{e}^{\\int P(t)\\mathrm{d}t}\\). Here: \\[\\int P(t)\\mathrm{d}t = \\int k_2\\mathrm{d}t = k_2t\\] So our integrating factor is \\(\\mathrm{e}^{k_2t}\\). Multiplying both sides of our original equation: \\[\\mathrm{e}^{k_2t}\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} + k_2[\\mathrm{B}]\\mathrm{e}^{k_2t} = k_1[\\mathrm{A}]_0\\mathrm{e}^{-k_1t}\\mathrm{e}^{k_2t}\\] The left side is now the derivative of \\([\\mathrm{B}]\\mathrm{e}^{k_2t}\\): \\[\\frac{\\mathrm{d}}{\\mathrm{d}t}([\\mathrm{B}]\\mathrm{e}^{k_2t}) = k_1[\\mathrm{A}]_0\\mathrm{e}^{(k_2-k_1)t}\\] Integrating both sides: \\[[\\mathrm{B}]\\mathrm{e}^{k_2t} = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}\\mathrm{e}^{(k_2-k_1)t} + C\\] Solving for [B]: \\[[\\mathrm{B}] = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}\\mathrm{e}^{-k_1t} + C\\mathrm{e}^{-k_2t}\\] Using the initial condition [B]₀ = 0 at t = 0: \\[0 = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1} + C\\] Therefore: \\[C = -\\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}\\] And our final solution is: \\[[\\mathrm{B}] = \\frac{k_1[\\mathrm{A}]_0}{k_2-k_1}(\\mathrm{e}^{-k_1t} - \\mathrm{e}^{-k_2t})\\] This method of solution is generally applicable to first-order linear differential equations that arise in chemical kinetics. "],["appendix-energy.html", "B Derivation of the Exponential Energy Factor", " B Derivation of the Exponential Energy Factor In Lecture 5, we used the result that the fraction of collisions with relative kinetic energy greater than or equal to the activation energy \\(E_\\mathrm{a}\\) is given by: \\[P(E \\geq E_\\mathrm{a}) = \\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] This expression can be derived from the kinetic theory of gases. B.0.1 The Maxwell-Boltzmann Distribution The kinetic theory of gases tells us that the probability density for finding a collision with relative kinetic energy \\(E\\) is given by the Maxwell-Boltzmann distribution: \\[f(E) = \\frac{2\\pi}{(\\pi k_\\mathrm{B}T)^{3/2}}\\sqrt{E}\\,\\exp\\left(-\\frac{E}{k_\\mathrm{B}T}\\right)\\] where \\(k_\\mathrm{B}\\) is the Boltzmann constant and \\(T\\) is the absolute temperature. This distribution is normalised such that: \\[\\int_0^{\\infty} f(E)\\,\\mathrm{d}E = 1\\] B.0.2 Calculating the Fraction with E ≥ E_a The fraction of collisions with energy greater than or equal to \\(E_\\mathrm{a}\\) is obtained by integrating the distribution from \\(E_\\mathrm{a}\\) to infinity: \\[P(E \\geq E_\\mathrm{a}) = \\int_{E_\\mathrm{a}}^{\\infty} f(E)\\,\\mathrm{d}E\\] Substituting the Maxwell-Boltzmann distribution: \\[P(E \\geq E_\\mathrm{a}) = \\int_{E_\\mathrm{a}}^{\\infty} \\frac{2\\pi}{(\\pi k_\\mathrm{B}T)^{3/2}}\\sqrt{E}\\,\\exp\\left(-\\frac{E}{k_\\mathrm{B}T}\\right)\\,\\mathrm{d}E\\] To evaluate this integral, we make the substitution \\(u = E/(k_\\mathrm{B}T)\\), so that \\(E = uk_\\mathrm{B}T\\) and \\(\\mathrm{d}E = k_\\mathrm{B}T\\,\\mathrm{d}u\\). When \\(E = E_\\mathrm{a}\\), we have \\(u = E_\\mathrm{a}/(k_\\mathrm{B}T) \\equiv \\beta\\). The integral becomes: \\[P(E \\geq E_\\mathrm{a}) = \\frac{2\\pi}{(\\pi k_\\mathrm{B}T)^{3/2}}\\int_{\\beta}^{\\infty} \\sqrt{uk_\\mathrm{B}T}\\,\\mathrm{e}^{-u}\\,k_\\mathrm{B}T\\,\\mathrm{d}u\\] Simplifying: \\[P(E \\geq E_\\mathrm{a}) = \\frac{2}{\\sqrt{\\pi}}\\int_{\\beta}^{\\infty} \\sqrt{u}\\,\\mathrm{e}^{-u}\\,\\mathrm{d}u\\] This integral can be evaluated using integration by parts. Let \\(v = \\sqrt{u}\\) and \\(\\mathrm{d}w = \\mathrm{e}^{-u}\\,\\mathrm{d}u\\), so that \\(\\mathrm{d}v = \\frac{1}{2\\sqrt{u}}\\,\\mathrm{d}u\\) and \\(w = -\\mathrm{e}^{-u}\\): \\[\\begin{align} \\int_{\\beta}^{\\infty} \\sqrt{u}\\,\\mathrm{e}^{-u}\\,\\mathrm{d}u &amp;= \\left[-\\sqrt{u}\\,\\mathrm{e}^{-u}\\right]_{\\beta}^{\\infty} + \\int_{\\beta}^{\\infty} \\frac{\\mathrm{e}^{-u}}{2\\sqrt{u}}\\,\\mathrm{d}u\\\\ &amp;= \\sqrt{\\beta}\\,\\mathrm{e}^{-\\beta} + \\frac{1}{2}\\int_{\\beta}^{\\infty} \\frac{\\mathrm{e}^{-u}}{\\sqrt{u}}\\,\\mathrm{d}u \\end{align}\\] For large \\(\\beta\\) (which corresponds to \\(E_\\mathrm{a} \\gg k_\\mathrm{B}T\\), a condition typically satisfied for chemical reactions), the second term becomes negligible compared to the first. Therefore: \\[\\int_{\\beta}^{\\infty} \\sqrt{u}\\,\\mathrm{e}^{-u}\\,\\mathrm{d}u \\approx \\sqrt{\\beta}\\,\\mathrm{e}^{-\\beta}\\] Substituting back: \\[P(E \\geq E_\\mathrm{a}) \\approx \\frac{2}{\\sqrt{\\pi}}\\sqrt{\\beta}\\,\\mathrm{e}^{-\\beta} = \\frac{2}{\\sqrt{\\pi}}\\sqrt{\\frac{E_\\mathrm{a}}{k_\\mathrm{B}T}}\\exp\\left(-\\frac{E_\\mathrm{a}}{k_\\mathrm{B}T}\\right)\\] For typical activation energies in chemical reactions, \\(E_\\mathrm{a}/(k_\\mathrm{B}T) \\gg 1\\), which means the pre-exponential factor \\(\\sqrt{E_\\mathrm{a}/(k_\\mathrm{B}T)}\\) is much larger than unity but changes only slowly with temperature compared to the exponential term. To a good approximation, we can therefore write: \\[P(E \\geq E_\\mathrm{a}) \\approx \\exp\\left(-\\frac{E_\\mathrm{a}}{k_\\mathrm{B}T}\\right)\\] Finally, using the relationship \\(R = N_\\mathrm{A}k_\\mathrm{B}\\) (where \\(R\\) is the gas constant and \\(N_\\mathrm{A}\\) is Avogadro’s number), we can write this in the more familiar form: \\[P(E \\geq E_\\mathrm{a}) = \\exp\\left(-\\frac{E_\\mathrm{a}}{RT}\\right)\\] This derivation shows that the exponential dependence of reaction rates on temperature arises naturally from the Maxwell-Boltzmann distribution of molecular energies, and that the activation energy \\(E_\\mathrm{a}\\) represents a threshold that determines which fraction of collisions have sufficient energy to react. "],["appendix-activation.html", "C The Relationship Between \\(\\Delta H^\\ddagger\\) and the \\(E_\\mathrm{a}\\) C.1 Temperature Dependence of Rate Constants C.2 Effect of Reaction Molecularity", " C The Relationship Between \\(\\Delta H^\\ddagger\\) and the \\(E_\\mathrm{a}\\) In Section 6.4, we identified a correspondence between the transition state theory rate equation and the Arrhenius equation. The enthalpy of activation \\(\\Delta H^\\ddagger\\) and the Arrhenius activation energy \\(E_\\mathrm{a}\\) play similar roles in these equations, but they are not identical quantities. Here we examine their precise relationship. C.1 Temperature Dependence of Rate Constants The Arrhenius equation defines the temperature dependence of rate constants empirically: \\[\\begin{equation} k = A\\mathrm{e}^{-E_\\mathrm{a}/RT} \\tag{5.5} \\end{equation}\\] Taking logarithms: \\[\\begin{equation} \\ln k = \\ln A - \\frac{E_\\mathrm{a}}{RT} \\tag{C.1} \\end{equation}\\] Differentiating with respect to temperature9 \\[\\begin{equation} \\frac{\\mathrm{d}\\ln k}{\\mathrm{d}T} = \\frac{E_\\mathrm{a}}{RT^2} \\tag{C.2} \\end{equation}\\] This equation can be considered a formal definition of the Arrhenius activation energy. For a bimolecular reaction, the thermodynamic form of the transition state theory rate equation is: \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{hc^\\circ}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\mathrm{e}^{-\\Delta H^\\ddagger/RT} \\tag{C.3} \\end{equation}\\] Taking logarithms: \\[\\begin{equation} \\ln k = \\ln\\left(\\frac{k_\\mathrm{B}T}{hc^\\circ}\\right) + \\frac{\\Delta S^\\ddagger}{R} - \\frac{\\Delta H^\\ddagger}{RT} \\tag{C.4} \\end{equation}\\] For an ideal gas, \\(\\frac{1}{c^\\circ} = \\frac{V}{N} = \\frac{RT}{p}\\), and we can rewrite our equation as \\[\\begin{equation} \\ln k = \\ln\\left(\\frac{k_\\mathrm{B}T}{h}\\right) + \\ln\\left(\\frac{RT}{p}\\right) + \\frac{\\Delta S^\\ddagger}{R} - \\frac{\\Delta H^\\ddagger}{RT} \\tag{C.5} \\end{equation}\\] Differentiating with respect to temperature gives,10 \\[\\begin{equation} \\frac{\\mathrm{d}\\ln k}{\\mathrm{d}T} = \\frac{1}{T} + \\frac{1}{T} + \\frac{\\Delta H^\\ddagger}{RT^2} \\tag{C.6} \\end{equation}\\] Comparing equations (C.2) and (C.6) we find: \\[\\begin{equation} E_\\mathrm{a} = \\Delta H^\\ddagger + 2RT \\tag{C.7} \\end{equation}\\] C.2 Effect of Reaction Molecularity The derivation above is for a bimolecular reaction. For a unimolecular reaction, the same procedure gives a different relationship between \\(E_\\mathrm{a}\\) and \\(\\Delta H^\\ddagger\\): \\[\\begin{equation} E_\\mathrm{a} = \\Delta H^\\ddagger + RT \\tag{C.8} \\end{equation}\\] The difference arises because the unimolecular TST rate equation is \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\mathrm{e}^{-\\Delta H^\\ddagger/RT} \\tag{C.9} \\end{equation}\\] with no \\(1/c^\\circ\\) term in the prefactor, and we lose the corresponding factor of \\(RT\\) when we evaluate \\(\\mathrm{d} \\ln k / \\mathrm{T}\\). Similarly, the TST rate equation for a termolecular reaction is \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h{c^\\circ}^2}\\mathrm{e}^{\\Delta S^\\ddagger/R}\\mathrm{e}^{-\\Delta H^\\ddagger/RT} \\tag{C.10} \\end{equation}\\] and \\[\\begin{equation} E_\\mathrm{a} = \\Delta H^\\ddagger + 3RT \\tag{C.11} \\end{equation}\\] where \\(2RT\\) comes from the squared concentration factor in the rate equation. At room temperature, \\(RT \\approx 2.5\\) kJ mol\\(^{-1}\\). The difference between \\(E_\\mathrm{a}\\) and \\(\\Delta H^\\ddagger\\) therefore ranges from about 2.5 kJ mol\\(^{-1}\\) for unimolecular reactions to 7.5 kJ mol\\(^{-1}\\) for termolecular processes. While these differences are relatively small compared to typical activation energies, they become important when comparing activation parameters determined using different methods or analysing temperature-dependent kinetic data over wide temperature ranges. \\(\\frac{\\mathrm{d}}{\\mathrm{d}x}\\frac{a}{x} = -\\frac{a}{x^2}\\).↩︎ \\(\\frac{\\mathrm{d}}{\\mathrm{d}x}\\ln ax = \\frac{1}{x}\\).↩︎ "],["appendix-statistical-tst.html", "D Statistical Foundations of Transition State Theory D.1 The Boltzmann Factor and Probability Distributions D.2 Molecular Partition Functions D.3 System Partition Functions D.4 Connection to Chemical Equilibrium D.5 The Statistical Rate Equation D.6 Molecular Degrees of Freedom", " D Statistical Foundations of Transition State Theory D.1 The Boltzmann Factor and Probability Distributions Statistical mechanics connects molecular-level properties to measurable thermodynamic quantities. The foundation of this connection lies in understanding how energy and temperature determine the distribution of molecular states in thermal equilibrium. D.1.1 The Boltzmann Factor When a system is in thermal equilibrium at temperature \\(T\\), the probability of finding it in a particular microstate \\(i\\) with energy \\(E_i\\) follows a specific mathematical form: \\[P_i \\propto e^{-\\beta E_i}\\] where \\(\\beta = \\frac{1}{k_\\mathrm{B}T}\\), and \\(k_\\mathrm{B}\\) is Boltzmann’s constant. The Boltzmann factor determines the relative probabilities of molecular energy states in thermal equilibrium. At high temperatures, the exponential term becomes less sensitive to energy differences, resulting in more uniform probability distributions across energy states. As temperature decreases, the probability becomes more strongly concentrated in the lowest energy states. D.1.2 Properties of Probability Distributions The Boltzmann factor gives relative probabilities between states. To construct a complete probability distribution, we need three mathematical conditions: Non-negativity: Probabilities cannot be negative \\[P_i \\geq 0 \\quad \\text{for all } i\\] Normalization: Total probability must equal one \\[\\sum_i P_i = 1\\] Additivity: For independent events, probabilities add \\[P(i \\text{ or } j) = P_i + P_j\\] The exponential form of the Boltzmann factor ensures non-negativity and additivity. Meeting the normalization condition requires introducing an additional factor. D.1.3 The Partition Function Converting the Boltzmann factor proportionality into a proper probability distribution requires a normalization constant \\(Z\\), called the partition function: \\[P_i = \\frac{1}{Z}e^{-\\beta E_i}\\] The normalization condition determines \\(Z\\): \\[1 = \\sum_i P_i = \\sum_i \\frac{1}{Z}e^{-\\beta E_i}\\] Therefore: \\[Z = \\sum_i e^{-\\beta E_i}\\] This sum encompasses all system microstates, each weighted by its Boltzmann factor. The partition function contains the essential statistical information needed to calculate thermodynamic properties. D.1.4 Example: A Two-State System Consider a molecular system with two possible states: Ground state: \\(E_1 = 0\\) Excited state: \\(E_2 = \\epsilon\\) The partition function is: \\[Z = e^{-\\beta \\cdot 0} + e^{-\\beta \\epsilon} = 1 + e^{-\\beta \\epsilon}\\] The probability of the excited state becomes: \\[P_2 = \\frac{e^{-\\beta \\epsilon}}{1 + e^{-\\beta \\epsilon}}\\] This basic example illustrates key features that appear in transition state theory: molecules populate multiple energy states, with relative populations determined by energy differences and temperature. D.2 Molecular Partition Functions The partition function for a single molecule encompasses all possible quantum states available to that molecule. For a molecule with discrete energy levels \\(E_i\\), the molecular partition function \\(q\\) takes the form: \\[q = \\sum_i g_i e^{-\\beta E_i}\\] where \\(g_i\\) represents the degeneracy of state \\(i\\). For polyatomic molecules, the total energy can be separated into contributions from different types of molecular motion: \\[E = E_\\mathrm{trans} + E_\\mathrm{rot} + E_\\mathrm{vib} + E_\\mathrm{elec}\\] When these motions are independent, the molecular partition function factorises: \\[q = q_\\mathrm{trans}q_\\mathrm{rot}q_\\mathrm{vib}q_\\mathrm{elec}\\] D.3 System Partition Functions For a system containing \\(N\\) identical molecules, the total partition function \\(Q\\) must account for the indistinguishability of quantum particles. For a gas of non-interacting molecules: \\[Q = \\frac{q^N}{N!}\\] The factor \\(N!\\) prevents overcounting of states that differ only by exchanging identical particles. D.4 Connection to Chemical Equilibrium Consider a chemical equilibrium: \\[\\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}\\] The equilibrium constant \\(K\\) can be expressed in terms of partition functions. For an ideal gas mixture: \\[K = \\frac{Q_\\mathrm{C}}{Q_\\mathrm{A}Q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right)^{\\Delta n}\\] where \\(\\Delta n\\) represents the change in the number of gas molecules, and \\(p^{\\circ}\\) is the standard pressure. Substituting the system partition functions: \\[K = \\frac{q_\\mathrm{C}}{q_\\mathrm{A}q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right)^{\\Delta n}e^{-\\Delta E_0/k_\\mathrm{B}T}\\] where \\(\\Delta E_0\\) represents the energy difference between the ground states of products and reactants. This expression reveals how molecular properties determine equilibrium constants: The ratio of partition functions captures entropic contributions The exponential term accounts for energetic differences The pressure term ensures correct dimensionality for gas-phase reactions D.5 The Statistical Rate Equation D.5.1 Reaction Flux Through the Transition State Consider a reaction where reactants A and B combine to form products via an activated complex C\\(^\\ddagger\\): \\[\\begin{equation} \\mathrm{A} + \\mathrm{B} \\rightleftharpoons \\mathrm{C}^\\ddagger \\longrightarrow \\mathrm{P} \\end{equation}\\] The central assumption of transition state theory is that reactants and the activated complex maintain a state of pseudo-equilibrium. This equilibrium can be expressed using partition functions: \\[\\begin{equation} \\frac{[\\mathrm{C}^\\ddagger]c^\\circ}{[\\mathrm{A}][\\mathrm{B}]} = \\frac{Q_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right) \\end{equation}\\] D.5.2 Motion Along the Reaction Coordinate The partition function for the activated complex, \\(Q_{\\mathrm{C}^\\ddagger}\\), requires careful consideration. One degree of freedom corresponds to motion along the reaction coordinate—the path leading from reactants to products through the transition state. This motion differs fundamentally from typical molecular vibrations because it is unbounded: once the system passes through the transition state, it proceeds to products. We therefore separate the partition function for the activated complex into two parts: \\[\\begin{equation} Q_{\\mathrm{C}^\\ddagger} = Q^\\prime_{\\mathrm{C}^\\ddagger}q_\\mathrm{rc} \\end{equation}\\] where \\(Q^\\prime_{\\mathrm{C}^\\ddagger}\\) excludes the reaction coordinate and \\(q_\\mathrm{rc}\\) represents the contribution from motion along the reaction coordinate. D.5.3 Rate of Barrier Crossing Motion along the reaction coordinate at the transition state resembles a very loose vibrational mode. Consider a harmonic oscillator with frequency \\(\\nu\\). The quantum mechanical partition function for this oscillator is: \\[\\begin{equation} q_\\mathrm{vib} = \\frac{e^{-h\\nu/2k_\\mathrm{B}T}}{1 - e^{-h\\nu/k_\\mathrm{B}T}} \\end{equation}\\] As the frequency approaches zero, corresponding to free motion along the reaction coordinate, this becomes:11 \\[\\begin{equation} \\lim_{\\nu \\to 0} q_\\mathrm{vib} = \\lim_{\\nu \\to 0} \\frac{e^{-h\\nu/2k_\\mathrm{B}T}}{1 - e^{-h\\nu/k_\\mathrm{B}T}} = \\frac{k_\\mathrm{B}T}{h\\nu} \\end{equation}\\] The rate constant for passage through the transition state equals this frequency multiplied by the probability of finding the system at the transition state. The frequency factor \\(\\nu\\) cancels with the \\(1/\\nu\\) from the partition function, yielding the characteristic \\(k_\\mathrm{B}T/h\\) factor in the rate equation. D.5.4 The Statistical Rate Equation Combining these results gives the fundamental equation of transition state theory: \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h}\\frac{Q^\\prime_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}}\\left(\\frac{k_\\mathrm{B}T}{p^{\\circ}}\\right)e^{-\\Delta E_0/k_\\mathrm{B}T} \\end{equation}\\] or, equivalently \\[\\begin{equation} k = \\frac{k_\\mathrm{B}T}{h}\\frac{1}{c^\\circ}\\frac{Q^\\prime_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}}e^{-\\Delta E_0/k_\\mathrm{B}T} \\end{equation}\\] This equation shows how molecular properties—encoded in the partition functions—determine reaction rates. The pre-exponential factor \\(\\frac{k_\\mathrm{B}T}{h}\\) emerges naturally from treating the reaction coordinate as a very loose vibration. D.6 Molecular Degrees of Freedom For a polyatomic molecule, the partition function factorises into contributions from different types of motion: \\[\\begin{equation} q = q_\\mathrm{trans}q_\\mathrm{rot}q_\\mathrm{vib} \\end{equation}\\] The entropic contribution to the rate constant depends on the ratio of partition functions: \\[\\begin{equation} \\frac{Q^\\prime_{\\mathrm{C}^\\ddagger}}{Q_\\mathrm{A}Q_\\mathrm{B}} = \\exp(\\Delta S^\\ddagger/R) \\end{equation}\\] Changes in molecular freedom when forming the activated complex directly affect this ratio. For each type of motion: \\[\\begin{equation} q_\\mathrm{trans} \\approx \\left(\\frac{2\\pi mk_\\mathrm{B}T}{h^2}\\right)^{3/2}V \\end{equation}\\] \\[\\begin{equation} q_\\mathrm{rot} \\approx \\frac{8\\pi^2Ik_\\mathrm{B}T}{h^2} \\end{equation}\\] \\[\\begin{equation} q_\\mathrm{vib} \\approx \\exp(-h\\nu/2k_\\mathrm{B}T) \\end{equation}\\] Taking logarithms gives characteristic entropy contributions: Translation: \\(S_\\mathrm{trans} \\approx 195~\\mathrm{J~K^{-1}~mol^{-1}}\\) Rotation: \\(S_\\mathrm{rot} \\approx 20~\\mathrm{J~K^{-1}~mol^{-1}}\\) Vibration: \\(S_\\mathrm{vib} \\approx 5~\\mathrm{J~K^{-1}~mol^{-1}}\\) For a bimolecular reaction, forming the activated complex typically: Reduces translational degrees of freedom by 3 Reduces rotational degrees of freedom Increases vibrational degrees of freedom The total entropy change can be estimated by counting these changes: \\[\\begin{equation} \\Delta S^\\ddagger \\approx n_\\mathrm{t}\\Delta S_\\mathrm{trans} + n_\\mathrm{r}\\Delta S_\\mathrm{rot} + n_\\mathrm{v}\\Delta S_\\mathrm{vib} \\end{equation}\\] where \\(n_\\mathrm{t}\\), \\(n_\\mathrm{r}\\), and \\(n_\\mathrm{v}\\) represent the changes in the number of translational, rotational, and vibrational degrees of freedom. This statistical mechanical treatment provides the theoretical basis for the thermodynamic analysis of molecular freedom developed in the main lectures. To evaluate this limit, let \\(x = h\\nu/k_\\mathrm{B}T\\). As \\(\\nu \\to 0\\), \\(x \\to 0\\), and we can use the leading terms of the Taylor expansion \\(e^{-x} \\approx 1 - x\\). The numerator becomes \\(e^{-x/2} \\approx 1 - x/2\\) and the denominator becomes \\(1 - e^{-x} \\approx x\\). Thus \\(q_\\mathrm{vib} \\approx (1 - x/2)/x = 1/x - 1/2\\). As \\(x \\to 0\\), the \\(1/x\\) term dominates, giving \\(q_\\mathrm{vib} \\to k_\\mathrm{B}T/h\\nu\\).↩︎ "],["the-mathematical-origin-of-the-boltzmann-distribution.html", "E The Mathematical Origin of the Boltzmann Distribution E.1 Introduction E.2 Setting Up the Problem E.3 The Most Probable Distribution E.4 Finding the Maximum E.5 The Boltzmann Distribution E.6 Physical Interpretation", " E The Mathematical Origin of the Boltzmann Distribution E.1 Introduction The Boltzmann distribution is a cornerstone of statistical mechanics, describing how molecules distribute themselves among available energy states at thermal equilibrium. While we often simply quote the result that the probability of finding a molecule in a state with energy \\(\\epsilon\\) is proportional to \\(e^{-\\epsilon/k_\\mathrm{B}T}\\), understanding where this expression comes from provides deep insight into the connection between microscopic molecular behaviour and macroscopic thermodynamic properties. E.2 Setting Up the Problem Consider a large collection of \\(N\\) molecules that can exchange energy with a heat reservoir at temperature \\(T\\). Each molecule can occupy different energy states, where: \\(\\epsilon_i\\) is the energy of state \\(i\\) \\(n_i\\) is the number of molecules in state \\(i\\) Two fundamental constraints govern how these molecules can be distributed among the available states: Conservation of molecules (constant \\(N\\)): \\[\\begin{equation} N = \\sum_i n_i \\tag{E.1} \\end{equation}\\] Conservation of energy (constant \\(E\\)): \\[\\begin{equation} E = \\sum_i n_i\\epsilon_i \\tag{E.2} \\end{equation}\\] E.3 The Most Probable Distribution Many different arrangements of molecules could satisfy these constraints. However, some arrangements are more likely than others. To find the most probable distribution, we need to: Calculate how many different ways each distribution can be achieved Find the distribution that maximises this number while satisfying our constraints E.3.1 Counting Molecular Arrangements For a given set of occupation numbers \\({n_i}\\), the number of distinct ways to arrange \\(N\\) molecules among the available states is: \\[\\begin{equation} W = \\frac{N!}{\\prod_i n_i!} \\tag{E.3} \\end{equation}\\] This is analogous to the number of ways of dealing cards into piles, where \\(n_i\\) represents the number of cards in pile \\(i\\). E.3.2 Mathematical Treatment Working with \\(W\\) directly is challenging because factorials of large numbers are involved. Taking the natural logarithm simplifies our mathematics while preserving the maximum (since \\(\\ln\\) is a monotonic function): \\[\\begin{equation} \\ln W = \\ln N! - \\sum_i \\ln n_i! \\tag{E.4} \\end{equation}\\] For large numbers, we can use Stirling’s approximation: \\(\\ln n! \\approx n\\ln n - n\\). This gives: \\[\\begin{equation} \\ln W = N\\ln N - N - \\sum_i (n_i\\ln n_i - n_i) \\tag{E.5} \\end{equation}\\] E.4 Finding the Maximum To find the most probable distribution, we need to maximize \\(\\ln W\\) subject to our constraints on total number (Eqn. (E.1)) and energy (Eqn. (E.2)). This is a constrained optimization problem perfectly suited for the method of Lagrange multipliers. We introduce two Lagrange multipliers, \\(\\alpha\\) and \\(\\beta\\), and set up the variation: \\[\\begin{equation} \\delta\\left[\\ln W - \\alpha\\left(\\sum_i n_i - N\\right) - \\beta\\left(\\sum_i n_i\\epsilon_i - E\\right)\\right] = 0 \\tag{E.6} \\end{equation}\\] Taking the variation with respect to each \\(n_i\\) gives: \\[\\begin{equation} -\\ln n_i - 1 - \\alpha - \\beta\\epsilon_i = 0 \\tag{E.7} \\end{equation}\\] Solving for \\(n_i\\): \\[\\begin{equation} n_i = e^{-1-\\alpha}e^{-\\beta\\epsilon_i} \\tag{E.8} \\end{equation}\\] E.5 The Boltzmann Distribution Dividing by \\(N\\) gives the probability of finding a molecule in state \\(i\\): \\[\\begin{equation} P_i = \\frac{n_i}{N} = \\frac{1}{Z}e^{-\\beta\\epsilon_i} \\tag{E.9} \\end{equation}\\] where \\(Z = Ne^{1+\\alpha}\\) is called the partition function and ensures that probabilities sum to 1. E.6 Physical Interpretation The Lagrange multiplier \\(\\beta\\) acquires physical meaning by considering energy exchange with the heat reservoir. Detailed analysis shows that \\(\\beta = 1/k_\\mathrm{B}T\\), where \\(k_\\mathrm{B}\\) is Boltzmann’s constant and \\(T\\) is the temperature This gives us the familiar form of the Boltzmann distribution: \\[\\begin{equation} P_i = \\frac{1}{Z}e^{-\\epsilon_i/k_\\mathrm{B}T} \\tag{E.10} \\end{equation}\\] This remarkable result shows that the probability of finding a molecule in a particular energy state depends only on: The energy of that state The temperature of the system A normalisation factor (the partition function) The exponential form emerges naturally from maximising the number of possible molecular arrangements while maintaining constant energy—we didn’t need to assume it. This mathematical derivation reveals the deep connection between molecular-level disorder and macroscopic thermodynamic properties. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
